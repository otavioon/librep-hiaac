{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc64e80-f814-4eae-b75a-bc7d732d8f39",
   "metadata": {},
   "source": [
    "# Train without normalize\n",
    "\n",
    "This notebook will use the KuHar view (balanced_motionsense_equivalent_view) and will:\n",
    "\n",
    "1. Apply DFT over dataset windows\n",
    "2. Train three times with RF, SVM and KNN, and take the average accuracy and f1-score\n",
    "3. Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ee558-bb9f-4b19-b325-0481439c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2405ce97-68e6-4596-8121-89c89c775c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 19:48:06.525577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-05 19:48:06.525649: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from librep.datasets.har.loaders import KuHarResampledView20HZ\n",
    "from librep.datasets.multimodal import  PandasMultiModalDataset,TransformMultiModalDataset, WindowedTransform\n",
    "from librep.transforms.fft import FFT\n",
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier, SVC, KNeighborsClassifier\n",
    "from librep.metrics.report import ClassificationReport\n",
    "from librep.transforms.resampler import SimpleResampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cd4c3b-96a3-4bc1-8eeb-2d2631f0edda",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load KuHar, creating PandasMultiModalDatasets with the correct pre-defined windows\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mKuHarResampledView20HZ\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../../../data/views/KuHar/balanced_20Hz_motionsense_equivalent-v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard activity code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_val, test \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload(concat_train_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'label'"
     ]
    }
   ],
   "source": [
    "# Load KuHar, creating PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = KuHarResampledView20HZ(\"../../../../data/views/KuHar/balanced_20Hz_motionsense_equivalent-v1\")\n",
    "train_val, test = loader.load(concat_train_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4035c48-e903-466c-989d-a24c31e3e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.window_names, train_val.window_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3d33d-f632-4bee-b4b4-1ed6bfb6c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the whole data...\n",
    "train_val[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80c291-0249-40e4-9465-6c3aac9f8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2707bfa-140c-4561-adcf-18590c385747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Perform standard scaler in train dataset\n",
    "#train_scaler = StandardScaler()\n",
    "#train_scaler.fit(train_val[:][0])\n",
    "# OK Standard scaler was fit over train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f263834-32d6-4e6a-ad35-6f1f30cdb7b6",
   "metadata": {},
   "source": [
    "Let's create the transforms. In general (by default) transforms are applyied over each window of the dataset, separadetly. We can control how transform will be applyied using Wrapping the transform arround `WindowedTransform`. \n",
    "\n",
    "The `WindowedTransform` receives, as argument to the constructor:\n",
    "\n",
    "- The transform to be wrapped\n",
    "- `fit_on`: can be \"all\" (apply fit over the whole dataset), \"window\" (apply fit over each window) or None (does not do fit).\n",
    "- `transform_on`: can be \"all\" (apply transform over the whole dataset) or \"window\" (apply transform over each window)\n",
    "\n",
    "\n",
    "One transformers will be created:\n",
    "\n",
    "- `fft_transform`: Apply the transforms over windows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac76705-ef00-4097-a992-8aaf58cf38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the objects\n",
    "#scaler_transform = WindowedTransform(\n",
    "#    transform=train_scaler, fit_on=None, transform_on=\"all\")\n",
    "\n",
    "fft_transform = FFT()\n",
    "\n",
    "# Compose the transform\n",
    "# First apply the normalizer over whole dataset and then apply FFT over each window\n",
    "transformer = TransformMultiModalDataset(\n",
    "    transforms=[#scaler_transform,\n",
    "                fft_transform], new_window_name_prefix=\"scaled.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332caf7-dd47-4a02-b430-44f781c7d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform it and generate a new dataset!\n",
    "train_val_fft = transformer(train_val)\n",
    "test_fft = transformer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98324e-d947-4419-9856-0db55322b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the whole data...\n",
    "train_val_fft[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b086-9c88-406e-a209-bbf20a8a41fa",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's take the transformed datasets and train using RandomForest, SVM and KNN 3 times each. Then take the average accuracy and f1-score over the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a48a-2e43-4c22-ad7d-0d816872e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reporter will be the same\n",
    "\n",
    "reporter = ClassificationReport(\n",
    "    use_accuracy=True,\n",
    "    use_f1_score=True,\n",
    "    use_classification_report=True,\n",
    "    use_confusion_matrix=True,\n",
    "    plot_confusion_matrix=True,\n",
    "    normalize='true'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6d8a-f1a2-4da7-99ae-a3d6eedbd66b",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6e5cf-8e16-4ab0-a51a-0285fad98ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=10, debug=False)\n",
    "results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_acc = np.std(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_f1 = np.std(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (10 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")\n",
    "print(f\"Standard deviation accuracy (10 runs): {std_acc:.4f}. Standard deviation f1-score: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d156af-4b04-4764-88fb-cffb1e3d5ea3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242dd6b-68eb-4b12-beb4-82fbbe5c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)\n",
    "results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_acc = np.std(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_f1 = np.std(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (1 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")\n",
    "print(f\"Standard deviation accuracy (1 runs): {std_acc:.4f}. Standard deviation f1-score: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964332-8108-4ee2-b424-3d463780e24e",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382deb11-46f4-4067-ad12-bcce80dfbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)\n",
    "results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_acc = np.std(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_f1 = np.std(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (1 run): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")\n",
    "print(f\"Standard deviation accuracy (1 run): {std_acc:.4f}. Standard deviation f1-score: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d4e09-3446-45eb-8099-7a4130ce1cc8",
   "metadata": {},
   "source": [
    "## Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1490a-8a3d-41cd-91dd-31ae7a249863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, figsize: tuple = (12, 12), title: str = None, labels: dict = None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for label, group_df in df.groupby(\"label\"):\n",
    "        label = labels[label] if labels is not None else label\n",
    "        ax.scatter(group_df.x, group_df.y, label=label)\n",
    "    ax.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c2bb3-7223-4936-ad88-dda568893363",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: \"Stair-down\", 1: \"Stair-up\", 2: \"Sit\", 3: \"Stand\", 4: \"Walk\", 5: \"Run\"}\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53aff1-d4ad-43a9-b8d7-0de7b19fe328",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4370c0-3ef1-457c-b40a-c1a694d0ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UMAP(n_components=2)\n",
    "result = pd.DataFrame(model.fit_transform(train_val_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_val_fft[:][1]\n",
    "plot(result, figsize = (5, 5), title=\"UMAP on KuHar FFT data\", labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a037a09-188e-44a8-b9e7-da03d9f7a062",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16bbe-e637-4368-a499-bc7d3b48f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2)\n",
    "result = pd.DataFrame(model.fit_transform(train_val_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_val_fft[:][1]\n",
    "plot(result, figsize = (5, 5), title=\"T-SNE on KuHar FFT data\", labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485ad37-7a11-4e0a-85f1-741a10546576",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot UMAP and T-SNE with Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b47220-16e6-4b58-9606-b087c4e354d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id = np.array(['0']*len(train_val[:][0]))\n",
    "test_id = np.array(['1']*len(test[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c8c65-5887-4fa8-a254-9a0cd9463f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_dataset = np.concatenate([train_id, test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2dbae-3431-4fab-9622-9748cf9ba442",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"accel-x\",\n",
    "    \"accel-y\",\n",
    "    \"accel-z\",\n",
    "    \"gyro-x\",\n",
    "    \"gyro-y\",\n",
    "    \"gyro-z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05fcf7-c9bc-415e-9843-1f689726dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([train_val[:][0], test[:][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c346cf-2bbf-4044-a15a-e221c4008907",
   "metadata": {},
   "outputs": [],
   "source": [
    "kuhar_all = pd.DataFrame(data)\n",
    "kuhar_all['Id Dataset'] = id_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb13628-2b78-4c03-acfc-6fe8c31e33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'0': 'Train', \n",
    "          '1': 'Test'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172f676-8458-48b6-a756-65dc612d4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the datasets\n",
    "kuhar_all = PandasMultiModalDataset(\n",
    "    kuhar_all,\n",
    "    #feature_prefixes=features,\n",
    "    label_columns=\"Id Dataset\",\n",
    "    as_array=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818106b5-c2a5-4be7-ac51-90493def9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, figsize: tuple = (5, 5), title: str = None, labels: dict = None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for label, group_df in df.groupby(\"label\"):\n",
    "        label = labels[label] if labels is not None else label\n",
    "        ax.scatter(group_df.x, group_df.y, label=label)\n",
    "    ax.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05ad38-6942-47d2-8abc-4ec94ae2b4dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = UMAP(n_components=2, random_state=42)\n",
    "result = pd.DataFrame(model.fit_transform(kuhar_all[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = kuhar_all[:][1]\n",
    "plot(result, title=\"UMAP on kuhar dataset with FFT\", labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38631afc-98a3-40d3-b6f1-157be28887ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
