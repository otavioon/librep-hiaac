{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc64e80-f814-4eae-b75a-bc7d732d8f39",
   "metadata": {},
   "source": [
    "# Train without normalize\n",
    "\n",
    "This notebook will use the Extrasensory view and will:\n",
    "\n",
    "1. Apply DFT over dataset windows\n",
    "2. Train three times with RF, SVM and KNN, and take the average accuracy and f1-score\n",
    "3. Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ee558-bb9f-4b19-b325-0481439c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2405ce97-68e6-4596-8121-89c89c775c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from librep.datasets.har.loaders import ExtraSensorySenseUnbalancedResampledView20HZ\n",
    "from librep.datasets.multimodal import PandasMultiModalDataset,TransformMultiModalDataset, WindowedTransform\n",
    "from librep.transforms.fft import FFT\n",
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier, SVC, KNeighborsClassifier\n",
    "from librep.metrics.report import ClassificationReport\n",
    "from librep.transforms.resampler import SimpleResampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34cd4c3b-96a3-4bc1-8eeb-2d2631f0edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ExtraSensory, creating PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = ExtraSensorySenseUnbalancedResampledView20HZ(\"../../../data/views/ExtraSensory/unbalanced_20Hz_train-v1\", download=False)\n",
    "train = loader.load()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4035c48-e903-466c-989d-a24c31e3e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['accelerometer-x',\n",
       "  'accelerometer-y',\n",
       "  'accelerometer-z',\n",
       "  'gyroscope-x',\n",
       "  'gyroscope-y',\n",
       "  'gyroscope-z'],\n",
       " [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.window_names, train.window_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0a3d33d-f632-4bee-b4b4-1ed6bfb6c398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(25018, 0), dtype=float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the whole data...\n",
    "train[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c80c291-0249-40e4-9465-6c3aac9f8864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2707bfa-140c-4561-adcf-18590c385747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Perform standard scaler in train dataset\n",
    "#train_scaler = StandardScaler()\n",
    "#train_scaler.fit(train_val[:][0])\n",
    "# OK Standard scaler was fit over train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f263834-32d6-4e6a-ad35-6f1f30cdb7b6",
   "metadata": {},
   "source": [
    "Let's create the transforms. In general (by default) transforms are applyied over each window of the dataset, separadetly. We can control how transform will be applyied using Wrapping the transform arround `WindowedTransform`. \n",
    "\n",
    "The `WindowedTransform` receives, as argument to the constructor:\n",
    "\n",
    "- The transform to be wrapped\n",
    "- `fit_on`: can be \"all\" (apply fit over the whole dataset), \"window\" (apply fit over each window) or None (does not do fit).\n",
    "- `transform_on`: can be \"all\" (apply transform over the whole dataset) or \"window\" (apply transform over each window)\n",
    "\n",
    "\n",
    "One transformers will be created:\n",
    "\n",
    "- `fft_transform`: Apply the transforms over windows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ac76705-ef00-4097-a992-8aaf58cf38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the objects\n",
    "#scaler_transform = WindowedTransform(\n",
    "#    transform=train_scaler, fit_on=None, transform_on=\"all\")\n",
    "\n",
    "fft_transform = FFT(centered=True)\n",
    "\n",
    "# Compose the transform\n",
    "# First apply the normalizer over whole dataset and then apply FFT over each window\n",
    "transformer = TransformMultiModalDataset(\n",
    "    transforms=[#scaler_transform,\n",
    "                fft_transform], new_window_name_prefix=\"scaled.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c332caf7-dd47-4a02-b430-44f781c7d953",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid number of data points (0) specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transform it and generate a new dataset!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_fft \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Intra_datasets/UMAP_train_test/../../../librep/datasets/multimodal/transformer.py:92\u001b[0m, in \u001b[0;36mTransformMultiModalDataset.__call__\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m window_transform\u001b[38;5;241m.\u001b[39mtransform_on \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# fit_on=None, transform_on=window *\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# fit_on=all, transform_on=window *\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# fit_on=window, transform_on=window *\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     new_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__transform_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_transform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthe_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_slices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_transform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     new_y \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Calculate new slices\u001b[39;00m\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Intra_datasets/UMAP_train_test/../../../librep/datasets/multimodal/transformer.py:62\u001b[0m, in \u001b[0;36mTransformMultiModalDataset.__transform_sample\u001b[0;34m(self, transform, X, y, slices, do_fit)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     58\u001b[0m         transform\u001b[38;5;241m.\u001b[39mfit_transform(X[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, start:end], y)\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m slices\n\u001b[1;32m     60\u001b[0m     ]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     63\u001b[0m         transform\u001b[38;5;241m.\u001b[39mtransform(X[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, start:end]) \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m slices\n\u001b[1;32m     64\u001b[0m     ]\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Intra_datasets/UMAP_train_test/../../../librep/datasets/multimodal/transformer.py:63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     58\u001b[0m         transform\u001b[38;5;241m.\u001b[39mfit_transform(X[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, start:end], y)\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m slices\n\u001b[1;32m     60\u001b[0m     ]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m---> 63\u001b[0m         \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m slices\n\u001b[1;32m     64\u001b[0m     ]\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Intra_datasets/UMAP_train_test/../../../librep/transforms/fft.py:61\u001b[0m, in \u001b[0;36mFFT.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     59\u001b[0m datas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[0;32m---> 61\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfftpack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabsolute:\n\u001b[1;32m     63\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/fftpack/_basic.py:87\u001b[0m, in \u001b[0;36mfft\u001b[0;34m(x, n, axis, overwrite_x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfft\u001b[39m(x, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Return discrete Fourier transform of real or complex sequence.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pocketfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/fft/_pocketfft/basic.py:26\u001b[0m, in \u001b[0;36mc2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     24\u001b[0m     overwrite_x \u001b[38;5;241m=\u001b[39m overwrite_x \u001b[38;5;129;01mor\u001b[39;00m copied\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tmp\u001b[38;5;241m.\u001b[39mshape[axis] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid number of data points (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m) specified\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(tmp\u001b[38;5;241m.\u001b[39mshape[axis]))\n\u001b[1;32m     29\u001b[0m out \u001b[38;5;241m=\u001b[39m (tmp \u001b[38;5;28;01mif\u001b[39;00m overwrite_x \u001b[38;5;129;01mand\u001b[39;00m tmp\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pfft\u001b[38;5;241m.\u001b[39mc2c(tmp, (axis,), forward, norm, out, workers)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid number of data points (0) specified"
     ]
    }
   ],
   "source": [
    "# Transform it and generate a new dataset!\n",
    "train_fft = transformer(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98324e-d947-4419-9856-0db55322b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the whole data...\n",
    "train_fft[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b086-9c88-406e-a209-bbf20a8a41fa",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's take the transformed datasets and train using RandomForest, SVM and KNN 3 times each. Then take the average accuracy and f1-score over the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a48a-2e43-4c22-ad7d-0d816872e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reporter will be the same\n",
    "\n",
    "reporter = ClassificationReport(\n",
    "    use_accuracy=True,\n",
    "    use_f1_score=True,\n",
    "    use_classification_report=True,\n",
    "    use_confusion_matrix=True,\n",
    "    plot_confusion_matrix=True,\n",
    "    normalize='true'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6d8a-f1a2-4da7-99ae-a3d6eedbd66b",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6e5cf-8e16-4ab0-a51a-0285fad98ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "results = multi_run_experiment(train_fft, [test_fft])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d156af-4b04-4764-88fb-cffb1e3d5ea3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242dd6b-68eb-4b12-beb4-82fbbe5c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964332-8108-4ee2-b424-3d463780e24e",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382deb11-46f4-4067-ad12-bcce80dfbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d4e09-3446-45eb-8099-7a4130ce1cc8",
   "metadata": {},
   "source": [
    "## Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1490a-8a3d-41cd-91dd-31ae7a249863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, figsize: tuple = (5, 5), title: str = None, labels: dict = None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for label, group_df in df.groupby(\"label\"):\n",
    "        label = labels[label] if labels is not None else label\n",
    "        ax.scatter(group_df.x, group_df.y, label=label)\n",
    "    ax.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bbe1c-7b3d-4d9c-b508-f72779f0338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: \"SITTING\", 1: \"OR_standing\", 2: \"FIX_walking\", 3: \"FIX_running\"}\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53aff1-d4ad-43a9-b8d7-0de7b19fe328",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4370c0-3ef1-457c-b40a-c1a694d0ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UMAP(n_components=2)\n",
    "result = pd.DataFrame(model.fit_transform(train_val_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_val_fft[:][1]\n",
    "plot(result, title=\"UMAP on ExtraSensory FFT data\", labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a037a09-188e-44a8-b9e7-da03d9f7a062",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16bbe-e637-4368-a499-bc7d3b48f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2)\n",
    "result = pd.DataFrame(model.fit_transform(train_val_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_val_fft[:][1]\n",
    "plot(result, title=\"T-SNE on ExtraSensory FFT data\",  labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97482e3-001a-4f81-b18a-016543b8d262",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot UMAP and T-SNE with Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca840b18-27b9-4400-a2e4-b5c90fc368a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id = np.array(['0']*len(train_val[:][0]))\n",
    "test_id = np.array(['1']*len(test[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2a943-e8df-4a3e-9525-c5643af1b49b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_dataset = np.concatenate([train_id, test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ba0a2-618e-4587-913f-823a2c5039f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"accel-x\",\n",
    "    \"accel-y\",\n",
    "    \"accel-z\",\n",
    "    \"gyro-x\",\n",
    "    \"gyro-y\",\n",
    "    \"gyro-z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbca261-1d29-4a86-bb88-977c8217ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([train_val[:][0], test[:][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ed617-1b4e-454f-8fad-477b16a820a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrasensory_all = pd.DataFrame(data)\n",
    "extrasensory_all['Id Dataset'] = id_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b27ab-a320-4f6a-8894-ec3742abee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'0': 'Train', \n",
    "          '1': 'Test'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63cc37-08f8-45d3-a8ee-634e2e3a865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the datasets\n",
    "extrasensory_all = PandasMultiModalDataset(\n",
    "    extrasensory_all,\n",
    "    #feature_prefixes=features,\n",
    "    label_columns=\"Id Dataset\",\n",
    "    as_array=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a098ca-1fc0-4d51-932e-8cd686857c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, figsize: tuple = (5, 5), title: str = None, labels: dict = None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for label, group_df in df.groupby(\"label\"):\n",
    "        label = labels[label] if labels is not None else label\n",
    "        ax.scatter(group_df.x, group_df.y, label=label)\n",
    "    ax.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3472253-29fb-4ac7-aeb7-eece5ec8f712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = UMAP(n_components=2, random_state=42)\n",
    "result = pd.DataFrame(model.fit_transform(extrasensory_all[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = extrasensory_all[:][1]\n",
    "plot(result, title=\"UMAP on extrasensory dataset with FFT\", labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
