{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc64e80-f814-4eae-b75a-bc7d732d8f39",
   "metadata": {},
   "source": [
    "# Normalize and train\n",
    "\n",
    "This notebook will use the KuHar view (KuHar-balanced_motionsense_equivalent_view-v1) and will:\n",
    "\n",
    "1. Fit the standard scaler (normalizer) over train dataset\n",
    "2. Normalize the train and test datasets\n",
    "3. Apply DFT over dataset windows\n",
    "4. Train three times with RF, SVM and KNN, and take the average accuracy and f1-score\n",
    "5. Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ee558-bb9f-4b19-b325-0481439c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2405ce97-68e6-4596-8121-89c89c775c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 19:51:40.269151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-23 19:51:40.269172: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibrep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhar\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KuHarResampledView20HZ\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibrep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultimodal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformMultiModalDataset, WindowedTransform\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibrep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FFT\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librep'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from librep.datasets.har.loaders import KuHarResampledView20HZ\n",
    "from librep.datasets.multimodal import TransformMultiModalDataset, WindowedTransform\n",
    "from librep.transforms.fft import FFT\n",
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier, SVC, KNeighborsClassifier\n",
    "from librep.metrics.report import ClassificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd4c3b-96a3-4bc1-8eeb-2d2631f0edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KuHar, creating PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = KuHarResampledView20HZ(\"../data/views/KuHar/KuHar-balanced_motionsense_equivalent_view-v1\", download=False)\n",
    "train_val, test = loader.load(concat_train_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4035c48-e903-466c-989d-a24c31e3e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.window_names, train_val.window_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3d33d-f632-4bee-b4b4-1ed6bfb6c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the whole data...\n",
    "train_val[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2707bfa-140c-4561-adcf-18590c385747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Perform standard scaler in train dataset\n",
    "train_scaler = StandardScaler()\n",
    "train_scaler.fit(train_val[:][0])\n",
    "# OK Standard scaler was fit over train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f263834-32d6-4e6a-ad35-6f1f30cdb7b6",
   "metadata": {},
   "source": [
    "Let's create the transforms. In general (by default) transforms are applyied over each window of the dataset, separadetly. We can control how transform will be applyied using Wrapping the transform arround `WindowedTransform`. \n",
    "\n",
    "The `WindowedTransform` receives, as argument to the constructor:\n",
    "\n",
    "- The transform to be wrapped\n",
    "- `fit_on`: can be \"all\" (apply fit over the whole dataset), \"window\" (apply fit over each window) or None (does not do fit).\n",
    "- `transform_on`: can be \"all\" (apply transform over the whole dataset) or \"window\" (apply transform over each window)\n",
    "\n",
    "\n",
    "Two transformers will be created:\n",
    "\n",
    "- `scaler_transform`: First apply the scaler over the whole data (not on windows). \n",
    "- `fft_transform`: Apply the transforms over windows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac76705-ef00-4097-a992-8aaf58cf38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the objects\n",
    "scaler_transform = WindowedTransform(\n",
    "    transform=train_scaler, fit_on=None, transform_on=\"all\"\n",
    ")\n",
    "fft_transform = FFT()\n",
    "\n",
    "# Compose the transform\n",
    "# First apply the normalizer over whole dataset and then apply FFT over each window\n",
    "transformer = TransformMultiModalDataset(\n",
    "    transforms=[scaler_transform, fft_transform], new_window_name_prefix=\"scaled.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332caf7-dd47-4a02-b430-44f781c7d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform it and generate a new dataset!\n",
    "train_val_fft_scaled = transformer(train_val)\n",
    "test_fft_scaled = transformer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98324e-d947-4419-9856-0db55322b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the whole data...\n",
    "train_val_fft_scaled[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b086-9c88-406e-a209-bbf20a8a41fa",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's take the transformed datasets and train using RandomForest, SVM and KNN 3 times each. Then take the average accuracy and f1-score over the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a48a-2e43-4c22-ad7d-0d816872e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reporter will be the same\n",
    "\n",
    "reporter = ClassificationReport(\n",
    "    use_accuracy=True,\n",
    "    use_f1_score=True,\n",
    "    use_classification_report=True,\n",
    "    use_confusion_matrix=True,\n",
    "    plot_confusion_matrix=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6d8a-f1a2-4da7-99ae-a3d6eedbd66b",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6e5cf-8e16-4ab0-a51a-0285fad98ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "results = multi_run_experiment(train_val_fft_scaled, [test_fft_scaled])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d156af-4b04-4764-88fb-cffb1e3d5ea3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242dd6b-68eb-4b12-beb4-82fbbe5c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "results = multi_run_experiment(train_val_fft_scaled, [test_fft_scaled])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964332-8108-4ee2-b424-3d463780e24e",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382deb11-46f4-4067-ad12-bcce80dfbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "results = multi_run_experiment(train_val_fft_scaled, [test_fft_scaled])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d4e09-3446-45eb-8099-7a4130ce1cc8",
   "metadata": {},
   "source": [
    "## Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1490a-8a3d-41cd-91dd-31ae7a249863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, figsize: tuple = (12, 12), title: str = None, labels: dict = None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for label, group_df in df.groupby(\"label\"):\n",
    "        label = labels[label] if labels is not None else label\n",
    "        ax.scatter(group_df.x, group_df.y, label=label)\n",
    "    ax.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53aff1-d4ad-43a9-b8d7-0de7b19fe328",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4370c0-3ef1-457c-b40a-c1a694d0ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UMAP(n_components=2)\n",
    "result = pd.DataFrame(model.fit_transform(train_val_fft_scaled[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_val_fft_scaled[:][1]\n",
    "plot(result, title=\"UMAP on KuHar normalization+FFT data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a037a09-188e-44a8-b9e7-da03d9f7a062",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16bbe-e637-4368-a499-bc7d3b48f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2)\n",
    "result = pd.DataFrame(model.fit_transform(train_val_fft_scaled[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_val_fft_scaled[:][1]\n",
    "plot(result, title=\"T-SNE on KuHar normalization+FFT data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
