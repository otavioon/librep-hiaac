{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc64e80-f814-4eae-b75a-bc7d732d8f39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train without normalize\n",
    "# Train with datasets: CHARM\n",
    "# Test with dataset: CHARM\n",
    "\n",
    "1. Apply DFT over dataset windows and universal UMAP\n",
    "2. Train three times with RF, SVM and KNN, and take the average accuracy and f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd34244-97be-4c14-806d-778d8182eabe",
   "metadata": {},
   "source": [
    "# Crossvalidation experiments with CHARM as base and CHARM as target\n",
    "\n",
    "This notebook will perform crossvalidation experiments using the CHARM dataset at 20 Hz as training dataset. It will contain the following steps:\n",
    "\n",
    "1. Quick load train, test and validation CSV subsets from the balanced CHARM dataset at 20 Hz using `PandasDatasetsIO` helper\n",
    "2. Quick load train, test and validation CSV subsets from other relevant datasets using `PandasDatasetsIO` helper\n",
    "3. Subclassing the `Dataset` interface using `PandasMultiModalDataset`\n",
    "4. Apply the fourier transform on Charm\n",
    "5. Apply UMAP\n",
    "6. Train SVM, KNN and Random Forest classification models on the CHARM dataset in the frequency domain with dimensionality reduction\n",
    "7. Evaluate SVM, KNN and Random Forest classification models on CHARM in the frequency domain with dimensionality reduction\n",
    "\n",
    "The experiments will evaluate the performance of SVM, KNN and RF models trained on a balanced CHARM dataset and tested on CHARM in the frequency domain with dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ee558-bb9f-4b19-b325-0481439c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # For defining dataset Paths\n",
    "import sys\n",
    "sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2405ce97-68e6-4596-8121-89c89c775c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 02:28:02.319146: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-04 02:28:02.319166: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Librep imports\n",
    "from librep.utils.dataset import PandasDatasetsIO          # For quick load train, test and validation CSVs\n",
    "from librep.datasets.har.loaders import CHARMUnbalancedView\n",
    "\n",
    "from librep.datasets.multimodal import PandasMultiModalDataset, TransformMultiModalDataset, WindowedTransform\n",
    "from librep.transforms.fft import FFT\n",
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier, SVC, KNeighborsClassifier\n",
    "from librep.metrics.report import ClassificationReport\n",
    "from librep.transforms.resampler import SimpleResampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3de491-58ff-4120-8d43-1cff78bffb69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets to train the manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee617d6-45f2-4288-b817-b2ff87984b8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load CHARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d136cf-c08a-4151-ba6f-409eb8526661",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CHARMUnbalancedView(\"../../../../data/views/CHARM/unbalanced_view_train_test-v1\", download=False)\n",
    "train_val_charm, test_charm = loader.load(concat_train_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a56ba32-3fae-452a-b402-0348617124fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accel-x', 'accel-y', 'accel-z', 'gyro-x', 'gyro-y', 'gyro-z']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(train_val_charm.data.iloc[:,:].columns)\n",
    "train_val_charm.window_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddba057-e10d-400d-95f6-4bd33a892a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set\n",
    "charm_train_X = np.array(train_val_charm.data.iloc[:,:-2])\n",
    "charm_train_Y = np.array(train_val_charm.data.iloc[:,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50a6832-d482-43d1-864d-6badefa9aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "charm_test_X = np.array(train_val_charm.data.iloc[:,:-2])\n",
    "charm_test_Y = np.array(train_val_charm.data.iloc[:,-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e145a-34c0-4637-9494-a48436edcd0c",
   "metadata": {},
   "source": [
    "## Prepare train and test datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f128ab45-25b6-45c2-a2fe-ed68df870b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate([charm_train_X])\n",
    "train_Y = np.concatenate([charm_train_Y])\n",
    "\n",
    "test_X = np.concatenate([charm_test_X])\n",
    "test_Y = np.concatenate([charm_test_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f687537c-feb0-4c0b-9f1d-3b427f8281e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train set to classifiers\n",
    "train = pd.DataFrame(train_X, columns=columns[:-2])\n",
    "train['normalized activity code'] = train_Y\n",
    "\n",
    "# Test set to classifiers\n",
    "test = pd.DataFrame(test_X, columns=columns[:-2])\n",
    "test['normalized activity code'] = test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f48f6-aaa1-4ad6-a821-15a342d456d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7984ee-ba01-4bcf-aec1-9acb67423b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>UMAP(n_components=10, random_state=42, tqdm_kwds={&#x27;bar_format&#x27;: &#x27;{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]&#x27;, &#x27;desc&#x27;: &#x27;Epochs completed&#x27;, &#x27;disable&#x27;: True})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">UMAP</label><div class=\"sk-toggleable__content\"><pre>UMAP(n_components=10, random_state=42, tqdm_kwds={&#x27;bar_format&#x27;: &#x27;{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]&#x27;, &#x27;desc&#x27;: &#x27;Epochs completed&#x27;, &#x27;disable&#x27;: True})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "UMAP(n_components=10, random_state=42, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_transform = FFT()\n",
    "\n",
    "# Compose the transform\n",
    "# First apply the normalizer over whole dataset and then apply FFT over each window\n",
    "transformer = TransformMultiModalDataset(\n",
    "    transforms=[#scaler_transform,\n",
    "                fft_transform], new_window_name_prefix=\"no-scaling.\"\n",
    ")\n",
    "\n",
    "# Transform it and generate a new dataset!\n",
    "train_fft = transformer(train_val_charm)\n",
    "test_fft = transformer(test_charm)\n",
    "\n",
    "umap = UMAP(n_components=10, random_state=42)\n",
    "umap.fit(train_fft[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d57caf4-5134-4f56-b026-cbeff31fea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fft_umap = umap.transform(train_fft[:][0])\n",
    "test_fft_umap = umap.transform(test_fft[:][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cacb30-ae3c-457d-bc3e-2414e2426507",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets to evaluate the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a3d33d-f632-4bee-b4b4-1ed6bfb6c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set to classifiers\n",
    "train = pd.DataFrame(train_fft_umap)\n",
    "train['normalized activity code'] = train_fft.y\n",
    "\n",
    "# Test set to classifiers\n",
    "test = pd.DataFrame(test_fft_umap)\n",
    "test['normalized activity code'] = test_fft.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd42cbef-6d6d-4172-9b78-745b6db99e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the datasets\n",
    "\n",
    "# Train\n",
    "train = PandasMultiModalDataset(\n",
    "    train,\n",
    "    label_columns=\"normalized activity code\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "# Test\n",
    "test = PandasMultiModalDataset(\n",
    "    test,\n",
    "    label_columns=\"normalized activity code\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcb350-1f52-441e-a51d-ad6fd21f602a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate the manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b086-9c88-406e-a209-bbf20a8a41fa",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's take the transformed datasets and train using RandomForest, SVM and KNN 3 times each. Then take the average accuracy and f1-score over the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f6a48a-2e43-4c22-ad7d-0d816872e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reporter will be the same\n",
    "\n",
    "reporter = ClassificationReport(\n",
    "    use_accuracy=True,\n",
    "    use_f1_score=True,\n",
    "    use_classification_report=True,\n",
    "    use_confusion_matrix=True,\n",
    "    plot_confusion_matrix=True,\n",
    "    # normalize='true'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6d8a-f1a2-4da7-99ae-a3d6eedbd66b",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ea6e5cf-8e16-4ab0-a51a-0285fad98ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment \u001b[38;5;241m=\u001b[39m SimpleTrainEvalWorkflow(\n\u001b[1;32m      2\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mRandomForestClassifier,\n\u001b[1;32m      3\u001b[0m     do_not_instantiate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     do_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mreporter,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m multi_run_experiment \u001b[38;5;241m=\u001b[39m MultiRunWorkflow(workflow\u001b[38;5;241m=\u001b[39mexperiment, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_run_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m mean_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\n\u001b[1;32m     12\u001b[0m     [res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m std_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(\n\u001b[1;32m     16\u001b[0m     [res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Crossvalidation_experiments/UMAP/Without Normalization/../../../../librep/utils/workflow.py:125\u001b[0m, in \u001b[0;36mMultiRunWorkflow.__call__\u001b[0;34m(self, train_dataset, test_datasets)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----- Starting run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_runs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 125\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_datasets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Crossvalidation_experiments/UMAP/Without Normalization/../../../../librep/utils/workflow.py:79\u001b[0m, in \u001b[0;36mSimpleTrainEvalWorkflow.__call__\u001b[0;34m(self, train_dataset, test_datasets)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_fit:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_supervised:\n\u001b[0;32m---> 79\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(train_dataset[:][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:371\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of y is not strictly positive which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis necessary for Poisson regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m         )\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 371\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m    374\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:758\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m--> 758\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[1;32m    761\u001b[0m     expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m ]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=10, debug=False)\n",
    "results = multi_run_experiment(train, [test])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "std_acc = np.std(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_f1 = np.std(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "print(f\"Mean accuracy (10 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}.Std accuracy (10 runs): {std_acc:.4f}. Std f1-score: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d156af-4b04-4764-88fb-cffb1e3d5ea3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242dd6b-68eb-4b12-beb4-82fbbe5c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)\n",
    "results = multi_run_experiment(train, [test])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "std_acc = np.std(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_f1 = np.std(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "print(f\"Mean accuracy (1 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}.Std accuracy (1 runs): {std_acc:.4f}. Std f1-score: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964332-8108-4ee2-b424-3d463780e24e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382deb11-46f4-4067-ad12-bcce80dfbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter,\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)\n",
    "results = multi_run_experiment(train, [test])\n",
    "\n",
    "mean_acc = np.average(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "std_acc = np.std(\n",
    "    [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "mean_f1 = np.average(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "std_f1 = np.std(\n",
    "    [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    ")\n",
    "\n",
    "print(f\"Mean accuracy (1 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}.Std accuracy (1 runs): {std_acc:.4f}. Std f1-score: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d4e09-3446-45eb-8099-7a4130ce1cc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1490a-8a3d-41cd-91dd-31ae7a249863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot(df, figsize: tuple = (5, 5), title: str = None, labels: dict = None):\n",
    "#     fig, ax = plt.subplots(figsize=figsize)\n",
    "#     for label, group_df in df.groupby(\"label\"):\n",
    "#         label = labels[label] if labels is not None else label\n",
    "#         ax.scatter(group_df.x, group_df.y, label=label)\n",
    "#     ax.legend()\n",
    "#     plt.title(title)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c2bb3-7223-4936-ad88-dda568893363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {0: \"Sitting in a Chair\", 1: \"Sitting in a Couch\", 2: \"Standing\", 3: \"Lying up\", 4: \"Lying side\", 5: \"Device on surface\",\n",
    "# 6: \"Walking\", 7: \"Running\", 8: \"Walking Upstairs\", 9: \"Walking Downstairs\"}\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0719f-db90-4055-9c36-c39317e2df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {'K': 'KuHar', \n",
    "#           'M': 'MotionSense',\n",
    "#           'C': 'CHARM',\n",
    "#           'E': 'ExtraSensory',\n",
    "#           'W': 'WISDM',\n",
    "#           'U': 'UCI',\n",
    "#          }\n",
    "\n",
    "# # KuHAR\tK\n",
    "# # MotionSense\tM\n",
    "# # CHARM\tC\n",
    "# # ExtraSensory\tE\n",
    "# # WISDM\tW\n",
    "# # UCI\tU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53aff1-d4ad-43a9-b8d7-0de7b19fe328",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4370c0-3ef1-457c-b40a-c1a694d0ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UMAP(n_components=2, random_state=42)\n",
    "# result = pd.DataFrame(model.fit_transform(train_universal_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "# result[\"label\"] = train_universal_fft[:][1]\n",
    "# plot(result, title=\"UMAP on ExtraSensory, UCI-HAR, and WISDM FFT data\", labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7ecf3-157e-49fe-b57c-f32030636c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = UMAP(n_components=2)\n",
    "# result = pd.DataFrame(model.transform(test_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "# result[\"label\"] = test_fft[:][1]\n",
    "# plot(result, title=\"UMAP projection on KuHar, MotionSense, and CHARM FFT data\", labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a037a09-188e-44a8-b9e7-da03d9f7a062",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16bbe-e637-4368-a499-bc7d3b48f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TSNE(n_components=2, random_state=42)\n",
    "# result = pd.DataFrame(model.fit_transform(train_universal[:][0]), columns=[\"x\", \"y\"])\n",
    "# result[\"label\"] = train_universal[:][1]\n",
    "# plot(result, title=\"T-SNE on ExtraSensory, UCI-HAR, and WISDM FFT data\", labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fc2d8-c3b2-471c-9d8b-830a51f0309a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
