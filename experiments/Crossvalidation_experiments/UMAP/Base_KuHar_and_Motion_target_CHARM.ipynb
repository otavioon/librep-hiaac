{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fe56ec-8b0e-4e5a-82eb-bfbd27510bb6",
   "metadata": {},
   "source": [
    "# Crossvalidation experiments with KuHar as base and Charm as target\n",
    "\n",
    "This notebook will perform crossvalidation experiments using the KuHar and MotionSense datasets at 20 Hz as training dataset. It will contain the following steps:\n",
    "\n",
    "1. Quick load train, test and validation CSV subsets from the balanced KuHar and MotionSense datasets at 20 Hz using `PandasDatasetsIO` helper\n",
    "2. Quick load train, test and validation CSV subsets from other relevant datasets using `PandasDatasetsIO` helper\n",
    "3. Subclassing the `Dataset` interface using `PandasMultiModalDataset`\n",
    "4. Apply the fourier transform on Charm\n",
    "5. Apply universal UMAP\n",
    "6. Train SVM, KNN and Random Forest classification models on the KuHar and MotionSense dataset in the frequency domain with dimensionality reduction\n",
    "7. Evaluate SVM, KNN and Random Forest classification models on Charm in the frequency domain with dimensionality reduction\n",
    "\n",
    "The experiments will evaluate the performance of SVM, KNN and RF models trained on a balanced KuHar and MotionSense datasets and tested on Charm in the frequency domain with dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ee558-bb9f-4b19-b325-0481439c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # For defining dataset Paths\n",
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405ce97-68e6-4596-8121-89c89c775c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 13:00:57.055249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-03 13:00:57.240078: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Librep imports\n",
    "from librep.utils.dataset import PandasDatasetsIO          # For quick load train, test and validation CSVs\n",
    "from librep.datasets.har.loaders import ExtraSensoryBalancedResampledView20HZ, UCIHARUnbalancedView, WISDMInterpolatedUnbalancedView, CHARMUnbalancedView\n",
    "\n",
    "from librep.datasets.multimodal import PandasMultiModalDataset, TransformMultiModalDataset, WindowedTransform\n",
    "from librep.transforms.fft import FFT\n",
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier, SVC, KNeighborsClassifier\n",
    "from librep.metrics.report import ClassificationReport\n",
    "from librep.transforms.resampler import SimpleResampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3de491-58ff-4120-8d43-1cff78bffb69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets to train the manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa0ec6-0204-459e-a3a7-3ba0294c1a46",
   "metadata": {},
   "source": [
    "## Load ExtraSensory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add566a-32ef-43b6-893f-01d727432559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ExtraSensory, creating PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = ExtraSensoryBalancedResampledView20HZ(\"../../../data/views/ExtraSensory/balanced_view_resampled_20hz\", download=False)\n",
    "train_val_es, test_es = loader.load(concat_train_validation=True)\n",
    "# X_ es = train_val_es.data.iloc\n",
    "# X_es = train_val_es.data.iloc[:,1:-6]\n",
    "\n",
    "\n",
    "train_val_es.data.iloc[:,1:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4c5ef-f8cc-473c-a808-37aa9c48c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrasensory_X = np.array(train_val_es.data.iloc[:,1:-6])\n",
    "extrasensory_Y = np.array(train_val_es.data['activity code'])\n",
    "tam = len(extrasensory_Y)\n",
    "extrasensory_id_dataset = np.array(['E']*tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ece3-0724-4d2d-b929-c56d1e8673ec",
   "metadata": {},
   "source": [
    "## Load UCI-HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed490e0-2b9c-4ab2-9f50-3ebb91ec29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UCI-HAR, creating PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = UCIHARUnbalancedView(\"../../../data/views/UCI-HAR/unbalanced_view_train_test-v1\", download=False)\n",
    "train_val_uci, test_uci = loader.load(concat_train_validation=True)\n",
    "\n",
    "train_val_uci.data['activity code'] = train_val_uci.data['activity code'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae0678-1734-4e52-8c72-723a76828f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the dataset to 20 Hz\n",
    "resampler = SimpleResampler(new_sample_size=60)\n",
    "transformer = TransformMultiModalDataset(\n",
    "    transforms=[resampler], new_window_name_prefix=\"resampled.\"\n",
    ")\n",
    "train_val_uci = transformer(train_val_uci)\n",
    "test_uci = transformer(test_uci)\n",
    "# train_uci = pd.DataFrame(train_val_uci.X)\n",
    "uci_X = train_val_uci.X\n",
    "uci_Y = train_val_uci.y\n",
    "\n",
    "tam = len(uci_Y)\n",
    "uci_id_dataset = np.array(['U']*tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794fa0a-3102-497f-88af-76af6668faa1",
   "metadata": {},
   "source": [
    "## Load WISDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df3535-f000-4a54-a6ba-74d41c395fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WISDM and create PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = WISDMInterpolatedUnbalancedView(\"../../../data/views/WISDM/interpolated_unbalanced_view_train_test-v1\", download=False)\n",
    "train_val_wisdm, test_wisdm = loader.load(concat_train_validation=True)\n",
    "\n",
    "#rename \"activity\" with \"activity code\"\n",
    "train_val_wisdm.data.rename(columns = {'activity':'activity code'}, inplace = True)\n",
    "#test.data.rename(columns = {'activity':'activity code'}, inplace = True)\n",
    "\n",
    "train_val_wisdm.data['activity code'] = train_val_wisdm.data['activity code'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416facd-93a0-4928-a62e-22dcf7167214",
   "metadata": {},
   "outputs": [],
   "source": [
    "wisdm_X = np.array(train_val_wisdm.data.iloc[:,:-2])\n",
    "wisdm_Y = np.array(train_val_wisdm.data['activity code'])\n",
    "\n",
    "tam = len(wisdm_Y)\n",
    "wisdm_id_dataset = np.array(['W']*tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4feb2a-79ad-4b98-8a8d-7b069c918e03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189ee5a-526b-41f9-b3d3-b7076b26d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_val_wisdm.data.iloc[:,:-2].columns)\n",
    "train_val_es.window_names, train_val_uci.window_names, train_val_wisdm.window_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96a656-8227-4a93-b422-4d5c241395bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate([wisdm_X, uci_X, extrasensory_X])\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6fa6d-0c0e-43ef-8f64-8d527b95ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.concatenate([wisdm_Y, uci_Y, extrasensory_Y])\n",
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d08814-3d39-4f81-a173-c8f7523f220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_dataset = np.concatenate([wisdm_id_dataset, uci_id_dataset, extrasensory_id_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8577b0c-40b1-4671-9189-a80e18ca1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_universal = pd.DataFrame(train_X, columns=columns)\n",
    "\n",
    "train_universal['Id Dataset'] = train_id_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cacb30-ae3c-457d-bc3e-2414e2426507",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets to evaluate the manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be9f0f-be78-463c-88fe-2fd0a3933e0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load KuHar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d4c60-7c00-46f1-bba1-6e80ed58cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for KuHar resampled to 20Hz view with the same activities (and labels numbers)\n",
    "# It is assumed that the directory will contain (train.csv, test.csv and validation.csv)\n",
    "#dataset_path = Path(\"../../../../data/views/KuHar/resampled_view_20Hz\")\n",
    "dataset_path = Path(\"../../../../data/views/KuHar/resampled_view_20Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b7bd7-ef26-4b81-9484-ee7714695cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kh, validation_kh, test_kh = PandasDatasetsIO(dataset_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95425c25-1f87-4262-b3b1-88f7365a7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuhar features to select\n",
    "features = [\n",
    "    \"accel-x\",\n",
    "    \"accel-y\",\n",
    "    \"accel-z\",\n",
    "    \"gyro-x\",\n",
    "    \"gyro-y\",\n",
    "    \"gyro-z\"\n",
    "]\n",
    "\n",
    "train_kh = train_kh.query(\"`normalized activity code` == 0 or `normalized activity code` == 1 or `normalized activity code` == 2 or `normalized activity code` == 3  or `normalized activity code` == 4 or `normalized activity code` == 5\")\n",
    "validation_kh = validation_kh.query(\"`normalized activity code` == 0 or `normalized activity code` == 1 or `normalized activity code` == 2 or `normalized activity code` == 3  or `normalized activity code` == 4 or `normalized activity code` == 5\")\n",
    "test_kh = test_kh.query(\"`normalized activity code` == 0 or `normalized activity code` == 1 or `normalized activity code` == 2 or `normalized activity code` == 3  or `normalized activity code` == 4 or `normalized activity code` == 5\")\n",
    "\n",
    "test_kh\n",
    "\n",
    "# Creating the target dataset\n",
    "\n",
    "# combined_target_dset_kh = PandasMultiModalDataset(\n",
    "#     pd.concat([train_kh, validation_kh, test_kh], ignore_index=True),\n",
    "#     feature_prefixes=features,\n",
    "#     label_columns=\"normalized activity code\",\n",
    "#     as_array=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589a7b5-cfe6-4659-bc07-5808f7353b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kh.iloc[:,1:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6388c7-ce1f-4538-8295-78301695d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kuhar_X = np.array(test_kh.iloc[:,1:-10])\n",
    "kuhar_Y = np.array(test_kh['normalized activity code'])\n",
    "tam = len(kuhar_Y)\n",
    "kuhar_id_dataset = np.array(['K']*tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de434c32-d785-42c2-a869-bffd0dc7e853",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load MotionSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9908d-509b-497a-a9b2-be30c02f1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../../../../data/views/MotionSense/resampled_view_20Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508d191-f705-4eb9-9576-302a455d8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motionsense dataframe\n",
    "train_motion, validation_motion, test_motion = PandasDatasetsIO(dataset_path).load()\n",
    "test_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6904f-289d-4559-91ec-86b18b4ff30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_motion.iloc[:,1:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b501d31-4078-47ba-9441-0938e11671f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_X = np.array(test_motion.iloc[:,1:-6])\n",
    "motion_Y = np.array(test_motion['normalized activity code'])\n",
    "tam = len(motion_Y)\n",
    "motion_id_dataset = np.array(['M']*tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0d52c-b853-41c7-9ca4-f24b569290d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load CHARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd4c3b-96a3-4bc1-8eeb-2d2631f0edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CHARM, creating PandasMultiModalDatasets with the correct pre-defined windows\n",
    "loader = CHARMUnbalancedView(\"../../../data/views/CHARM/unbalanced_view_train_test-v1\", download=False)\n",
    "train_val_charm, test_charm = loader.load(concat_train_validation=True)\n",
    "\n",
    "#rename \"activity\" with \"activity code\"\n",
    "#train_val.data.rename(columns = {'activity':'activity code'}, inplace = True)\n",
    "#test.data.rename(columns = {'activity':'activity code'}, inplace = True)\n",
    "\n",
    "train_val_charm.data['activity code'] = train_val_charm.data['activity code'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42543b48-bea9-492d-b488-e5cee158d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only classes of interest\n",
    "\n",
    "test_charm.data = test_charm.data[test_charm.data['activity code'].isin([0, 2, 6, 7, 8, 9])]\n",
    "\n",
    "# 0: \"Sitting in a Chair\", \n",
    "# 2: \"Standing\", \n",
    "# 6: \"Walking\", \n",
    "# 7: \"Running\", \n",
    "# 8: \"Walking Upstairs\", \n",
    "# 9: \"Walking Downstairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86632399-4197-4b12-9add-75a2191c08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_charm.data.loc[test_charm.data['activity code'] == 0, 'activity code'] = 0\n",
    "test_charm.data.loc[test_charm.data['activity code'] == 2, 'activity code'] = 1\n",
    "test_charm.data.loc[test_charm.data['activity code'] == 6, 'activity code'] = 2\n",
    "test_charm.data.loc[test_charm.data['activity code'] == 7, 'activity code'] = 5\n",
    "test_charm.data.loc[test_charm.data['activity code'] == 8, 'activity code'] = 3\n",
    "test_charm.data.loc[test_charm.data['activity code'] == 9, 'activity code'] = 4\n",
    "\n",
    "# 0 - Sit\n",
    "# 1 - Stand\n",
    "# 2 - Walk \n",
    "# 3 - Upstairs \n",
    "# 4 - Downstairs\n",
    "# 5 - Run/Jogging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972764b-fed7-44da-a4e3-aa602fc0c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_charm.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03b938-8aae-4c16-b1c9-6976c391c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_charm.data.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e8ef9-efa6-4664-87ba-dc80f9ac979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "charm_X = np.array(test_charm.data.iloc[:,:-2])\n",
    "charm_Y = np.array(test_charm.data['activity code'])\n",
    "tam = len(charm_Y)\n",
    "charm_id_dataset = np.array(['C']*tam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4035c48-e903-466c-989d-a24c31e3e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_charm.window_names, test_charm.window_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a197b-444c-477f-a7da-319ea501eb9f",
   "metadata": {},
   "source": [
    "## Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eeab3e-73f5-4fda-a154-e088a52827f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.concatenate([charm_X, motion_X, kuhar_X])\n",
    "test_Y = np.concatenate([charm_Y, motion_Y, kuhar_Y])\n",
    "test_id_dataset = np.concatenate([charm_id_dataset, motion_id_dataset, kuhar_id_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3d33d-f632-4bee-b4b4-1ed6bfb6c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_X, columns=columns)\n",
    "test['normalized activity code'] = test_Y\n",
    "test['Id Dataset'] = test_id_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc43d29-60c4-4595-be02-fadd834ea0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42cbef-6d6d-4172-9b78-745b6db99e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuhar features to select\n",
    "features = [\n",
    "    \"accel-x\",\n",
    "    \"accel-y\",\n",
    "    \"accel-z\",\n",
    "    \"gyro-x\",\n",
    "    \"gyro-y\",\n",
    "    \"gyro-z\"\n",
    "]\n",
    "\n",
    "# Creating the datasets\n",
    "\n",
    "# Train\n",
    "train_universal = PandasMultiModalDataset(\n",
    "    train_universal,\n",
    "    feature_prefixes=features,\n",
    "    label_columns=\"Id Dataset\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "# Test\n",
    "test = PandasMultiModalDataset(\n",
    "    test,\n",
    "    feature_prefixes=features,\n",
    "    label_columns=\"Id Dataset\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcb350-1f52-441e-a51d-ad6fd21f602a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2707bfa-140c-4561-adcf-18590c385747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Perform standard scaler in train dataset\n",
    "#train_scaler = StandardScaler()\n",
    "#train_scaler.fit(train_val[:][0])\n",
    "# OK Standard scaler was fit over train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f263834-32d6-4e6a-ad35-6f1f30cdb7b6",
   "metadata": {},
   "source": [
    "Let's create the transforms. In general (by default) transforms are applyied over each window of the dataset, separadetly. We can control how transform will be applyied using Wrapping the transform arround `WindowedTransform`. \n",
    "\n",
    "The `WindowedTransform` receives, as argument to the constructor:\n",
    "\n",
    "- The transform to be wrapped\n",
    "- `fit_on`: can be \"all\" (apply fit over the whole dataset), \"window\" (apply fit over each window) or None (does not do fit).\n",
    "- `transform_on`: can be \"all\" (apply transform over the whole dataset) or \"window\" (apply transform over each window)\n",
    "\n",
    "\n",
    "One transformers will be created:\n",
    "\n",
    "- `fft_transform`: Apply the transforms over windows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac76705-ef00-4097-a992-8aaf58cf38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the objects\n",
    "#scaler_transform = WindowedTransform(\n",
    "#    transform=train_scaler, fit_on=None, transform_on=\"all\")\n",
    "\n",
    "fft_transform = FFT()\n",
    "\n",
    "# Compose the transform\n",
    "# First apply the normalizer over whole dataset and then apply FFT over each window\n",
    "transformer = TransformMultiModalDataset(\n",
    "    transforms=[#scaler_transform,\n",
    "                fft_transform], new_window_name_prefix=\"scaled.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332caf7-dd47-4a02-b430-44f781c7d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform it and generate a new dataset!\n",
    "train_universal_fft = transformer(train_universal)\n",
    "test_fft = transformer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98324e-d947-4419-9856-0db55322b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the whole data...\n",
    "train_universal[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3b086-9c88-406e-a209-bbf20a8a41fa",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's take the transformed datasets and train using RandomForest, SVM and KNN 3 times each. Then take the average accuracy and f1-score over the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a48a-2e43-4c22-ad7d-0d816872e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The reporter will be the same\n",
    "\n",
    "# reporter = ClassificationReport(\n",
    "#     use_accuracy=True,\n",
    "#     use_f1_score=True,\n",
    "#     use_classification_report=True,\n",
    "#     use_confusion_matrix=True,\n",
    "#     plot_confusion_matrix=True,\n",
    "#     normalize='true'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6d8a-f1a2-4da7-99ae-a3d6eedbd66b",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6e5cf-8e16-4ab0-a51a-0285fad98ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = SimpleTrainEvalWorkflow(\n",
    "#     estimator=RandomForestClassifier,\n",
    "#     do_not_instantiate=False,\n",
    "#     do_fit=True,\n",
    "#     evaluator=reporter,\n",
    "# )\n",
    "\n",
    "# multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "# results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "# mean_acc = np.average(\n",
    "#     [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    "# )\n",
    "# mean_f1 = np.average(\n",
    "#     [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    "# )\n",
    "# print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d156af-4b04-4764-88fb-cffb1e3d5ea3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242dd6b-68eb-4b12-beb4-82fbbe5c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = SimpleTrainEvalWorkflow(\n",
    "#     estimator=SVC,\n",
    "#     do_not_instantiate=False,\n",
    "#     do_fit=True,\n",
    "#     evaluator=reporter,\n",
    "# )\n",
    "\n",
    "# multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "# results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "# mean_acc = np.average(\n",
    "#     [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    "# )\n",
    "# mean_f1 = np.average(\n",
    "#     [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    "# )\n",
    "# print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964332-8108-4ee2-b424-3d463780e24e",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382deb11-46f4-4067-ad12-bcce80dfbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = SimpleTrainEvalWorkflow(\n",
    "#     estimator=KNeighborsClassifier,\n",
    "#     do_not_instantiate=False,\n",
    "#     do_fit=True,\n",
    "#     evaluator=reporter,\n",
    "# )\n",
    "\n",
    "# multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)\n",
    "# results = multi_run_experiment(train_val_fft, [test_fft])\n",
    "\n",
    "# mean_acc = np.average(\n",
    "#     [res[\"result\"][0][\"accuracy\"] for res in results[\"runs\"]]\n",
    "# )\n",
    "# mean_f1 = np.average(\n",
    "#     [res[\"result\"][0][\"f1 score (weighted)\"] for res in results[\"runs\"]]\n",
    "# )\n",
    "# print(f\"Mean accuracy (3 runs): {mean_acc:.4f}. Mean f1-score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d4e09-3446-45eb-8099-7a4130ce1cc8",
   "metadata": {},
   "source": [
    "## Plot UMAP and T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1490a-8a3d-41cd-91dd-31ae7a249863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, figsize: tuple = (5, 5), title: str = None, labels: dict = None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for label, group_df in df.groupby(\"label\"):\n",
    "        label = labels[label] if labels is not None else label\n",
    "        ax.scatter(group_df.x, group_df.y, label=label)\n",
    "    ax.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c2bb3-7223-4936-ad88-dda568893363",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: \"Sitting in a Chair\", 1: \"Sitting in a Couch\", 2: \"Standing\", 3: \"Lying up\", 4: \"Lying side\", 5: \"Device on surface\",\n",
    "6: \"Walking\", 7: \"Running\", 8: \"Walking Upstairs\", 9: \"Walking Downstairs\"}\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0719f-db90-4055-9c36-c39317e2df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'K': 'KuHar', \n",
    "          'M': 'MotionSense',\n",
    "          'C': 'CHARM',\n",
    "          'E': 'ExtraSensory',\n",
    "          'W': 'WISDM',\n",
    "          'U': 'UCI',\n",
    "         }\n",
    "\n",
    "# KuHAR\tK\n",
    "# MotionSense\tM\n",
    "# CHARM\tC\n",
    "# ExtraSensory\tE\n",
    "# WISDM\tW\n",
    "# UCI\tU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53aff1-d4ad-43a9-b8d7-0de7b19fe328",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4370c0-3ef1-457c-b40a-c1a694d0ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UMAP(n_components=2, random_state=42)\n",
    "result = pd.DataFrame(model.fit_transform(train_universal_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_universal_fft[:][1]\n",
    "plot(result, title=\"UMAP on ExtraSensory, UCI-HAR, and WISDM FFT data\", labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7ecf3-157e-49fe-b57c-f32030636c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UMAP(n_components=2)\n",
    "result = pd.DataFrame(model.transform(test_fft[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = test_fft[:][1]\n",
    "plot(result, title=\"UMAP projection on KuHar, MotionSense, and CHARM FFT data\", labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a037a09-188e-44a8-b9e7-da03d9f7a062",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b16bbe-e637-4368-a499-bc7d3b48f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, random_state=42)\n",
    "result = pd.DataFrame(model.fit_transform(train_universal[:][0]), columns=[\"x\", \"y\"])\n",
    "result[\"label\"] = train_universal[:][1]\n",
    "plot(result, title=\"T-SNE on ExtraSensory, UCI-HAR, and WISDM FFT data\", labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fc2d8-c3b2-471c-9d8b-830a51f0309a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
