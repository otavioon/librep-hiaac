{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40df6f11-a295-4bb3-8ad7-c167a0adb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4fb8f2-0dc0-4673-813c-885f3c91dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ae4be2-202a-476a-85fa-478520f4a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0610c100-8395-4d7d-9c42-e666a4100e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 01:32:10.791850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-25 01:32:10.791880: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from librep.datasets.har.loaders import MotionSense_BalancedView20HZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760926cb-890f-44a1-8cb4-df665c8ae570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.topo_ae import TopologicalDimensionalityReduction\n",
    "from librep.metrics.dimred_evaluator import DimensionalityReductionQualityReport\n",
    "from Experiments_topoae_KuHar20Hz_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a423355-2d96-48a5-918f-e29e4777de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "# from librep.metrics.report import ClassificationReport\n",
    "# from librep.estimators import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# from librep.transforms.topo_ae import TopologicalDimensionalityReduction\n",
    "# from librep.estimators.ae.torch.models.topological_ae.topological_ae import TopologicallyRegularizedAutoencoder\n",
    "\n",
    "\n",
    "# from librep.transforms import UMAP\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c608afd1-657c-403d-b497-1a27a6a8d480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Balanced MotionSense View Resampled to 20Hz with Gravity - Multiplied acc by 9.81m/sÂ²\n",
       "\n",
       "This is a view from [MotionSense] that was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). \n",
       "\n",
       "The data was first splitted in three sets: train, validation and test. Each one with the following proportions:\n",
       "- Train: 70% of samples\n",
       "- Validation: 10% of samples\n",
       "- Test: 20% of samples\n",
       "\n",
       "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
       "\n",
       "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
       "\n",
       "## Activity codes\n",
       "- 0: downstairs (569 train, 101 validation, 170 test) \n",
       "- 1: upstairs (569 train, 101 validation, 170 test) \n",
       "- 2: sitting (569 train, 101 validation, 170 test) \n",
       "- 3: standing (569 train, 101 validation, 170 test) \n",
       "- 4: walking (569 train, 101 validation, 170 test) \n",
       "- 5: jogging (569 train, 101 validation, 170 test) \n",
       " \n",
       "\n",
       "## Standartized activity codes\n",
       "- 0: sit (569 train, 101 validation, 170 test) \n",
       "- 1: stand (569 train, 101 validation, 170 test) \n",
       "- 2: walk (569 train, 101 validation, 170 test) \n",
       "- 3: stair up (569 train, 101 validation, 170 test) \n",
       "- 4: stair down (569 train, 101 validation, 170 test) \n",
       "- 5: run (569 train, 101 validation, 170 test) \n",
       "      \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MotionSense Loader\n",
    "loader = MotionSense_BalancedView20HZ(\n",
    "    root_dir=\"../../../data/views/MotionSense/balanced_view_20Hz_with_gravity_9.81_acc_standard\", \n",
    "    download=False\n",
    ")\n",
    "\n",
    "# Print the readme (optional)\n",
    "loader.print_readme()\n",
    "# kuhar_data = obtainKuHar20Hz()\n",
    "# train_HD = kuhar_data['train_HD']\n",
    "# train_LD = kuhar_data['train_LD']\n",
    "# train_Y = kuhar_data['train_Y']\n",
    "# test_HD = kuhar_data['test_HD']\n",
    "# test_LD = kuhar_data['test_LD']\n",
    "# test_Y = kuhar_data['test_Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7a12c-ed5b-4424-bdf2-0635e4393c6a",
   "metadata": {},
   "source": [
    "# Preparing Table\n",
    "\n",
    "Columns:\n",
    "* RF (Accuracy, F1)\n",
    "* SVC (Accuracy, F1)\n",
    "* KNN (Accuracy, F1)\n",
    "* Trustworthiness\n",
    "* Continuity\n",
    "* Co-k-nearest-neighbor-size\n",
    "\n",
    "Rows:\n",
    "* UMAP (2 dim)\n",
    "* Generic Autoencoders\n",
    "* Topological autoencoders (L=1)\n",
    "* Topological autoencoders (L=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4c4d9e-dcbe-4ab1-90d2-d9d5df30229c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PandasMultiModalDataset: samples=4020, features=360, no. window=6, label_columns='standard activity code',\n",
       " PandasMultiModalDataset: samples=1020, features=360, no. window=6, label_columns='standard activity code')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# If concat_train_validation is true, return a tuple (train+validation, test)\n",
    "train_val, test = loader.load(concat_train_validation=True, label=loader.standard_label)\n",
    "train_val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054979cd-4aa7-43c6-9247-5ab0bdfb56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HD = np.array(train_val[:][0])\n",
    "train_Y = np.array(train_val[:][1])\n",
    "test_HD = np.array(test[:][0])\n",
    "test_Y = np.array(test[:][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3c1d5-1e3c-4bf2-b4cb-86dabeb01b2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41934c11-dbd6-4ac2-956d-d6a103e1a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(X, Y, filtered=None, xlim=None, ylim=None):\n",
    "    data_grouped = list(zip(X, Y))\n",
    "    uniques = filtered\n",
    "    if filtered is None:\n",
    "        uniques = np.unique(Y)\n",
    "    \n",
    "    for uval in uniques:\n",
    "        data = [pair[0] for pair in data_grouped if pair[1]==uval]\n",
    "        data_x = [unit[0] for unit in data]\n",
    "        data_y = [unit[1] for unit in data]\n",
    "        plt.scatter(data_x, data_y, label = uval)\n",
    "    # print(data)\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71409f92-8cd5-434b-919f-d068996dbc66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Applying Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9b17e-f585-4143-942f-b9138a69c24e",
   "metadata": {},
   "source": [
    "MinMaxScaler, MaxAbsScaler and StandardScaler apply the scaling PER FEATURE, which means the distance between points would actually be modified, and so, the ranking as well.\n",
    "Because of this, a new Scaler is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fac6c23-05f3-4008-99ab-8c67e46242b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.fftpack\n",
    "\n",
    "# # Number of samplepoints\n",
    "# N = 600\n",
    "# # sample spacing\n",
    "# T = 1.0 / 800.0\n",
    "# x = np.linspace(0.0, N*T, N)\n",
    "# y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n",
    "# yf = scipy.fftpack.fft(y)\n",
    "# xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "\n",
    "# # print(x)\n",
    "# # print(xf)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# # ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "# ax.plot(x,y)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "# # ax.plot(x,y)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b229f79-777c-42dd-9e8e-fc0f0e82c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.fftpack\n",
    "\n",
    "# # Number of samplepoints\n",
    "# N = 600\n",
    "# # sample spacing\n",
    "# T = 1.0 / 800.0\n",
    "# x = np.linspace(0.0, N*T, N)\n",
    "# y = 2*(np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x))\n",
    "# yf = scipy.fftpack.fft(y)\n",
    "# xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "\n",
    "# # print(x)\n",
    "# # print(xf)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# # ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "# ax.plot(x,y)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "# # ax.plot(x,y)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46248f1a-e532-4c3a-8f3d-5ce8f97a95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7743e300-d869-4128-a490-f6eac79155fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_HD = scaler.fit_transform(train_dataset_fft.X)\n",
    "# train_LD = None\n",
    "# # train_Y = train_dataset_fft.y\n",
    "# test_HD = scaler.fit_transform(test_dataset_fft.X)\n",
    "# test_LD = None\n",
    "# # test_Y = test_dataset_fft.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a74dc-f5b0-4bcb-9027-8f301cd4fc9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517c120c-b28a-4940-a6e6-278ab9bd98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = ClassificationReport(\n",
    "    use_accuracy=True, \n",
    "    use_f1_score=True,\n",
    "    use_classification_report=False,\n",
    "    use_confusion_matrix=False,\n",
    "    plot_confusion_matrix=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0f3ee-9908-4f24-90a7-f1f26bcedbd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **SECTION:** Exploring Topological AE (lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16134b93-4594-498e-9acf-e9feb00bc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_to_explore = [1, 10, 100, 1000, 5000, 10000]\n",
    "# lambdas_to_explore = [10, 100]\n",
    "executions_per_model = 10\n",
    "# executions_per_model = 2\n",
    "\n",
    "def explore_lambda(train_HD, train_Y, test_HD, test_Y, topoae_lambda, times_to_execute=10):\n",
    "    result_object = {\n",
    "        'RF-ACC': [],\n",
    "        'RF-F1': [],\n",
    "        'SVC-ACC': [],\n",
    "        'SVC-F1': [],\n",
    "        'KNN-ACC': [],\n",
    "        'KNN-F1': [],\n",
    "        'Trustworthiness': [],\n",
    "        'Continuity': [],\n",
    "        'Co-k-NNs': []   \n",
    "    }\n",
    "    for _ in range(times_to_execute):\n",
    "        kwargs = {'input_dims':360, 'custom_dim':2}\n",
    "        input_shape = (-1, 1, 360)\n",
    "        topo_reducer = TopologicalDimensionalityReduction(\n",
    "            ae_model='DeepAEforKuhar180ver2',\n",
    "            lam=topoae_lambda,\n",
    "            ae_kwargs=kwargs,\n",
    "            input_shape=input_shape,\n",
    "            patience=10\n",
    "        )\n",
    "        title_plot = \"MotionSense 20Hz\\nTopoAE lambda \" + str(topoae_lambda)\n",
    "        topo_reducer.fit(train_HD, train_Y, title_plot=title_plot)\n",
    "        train_LD = np.reshape(topo_reducer.transform(train_HD), (-1,2))\n",
    "        test_LD = np.reshape(topo_reducer.transform(test_HD), (-1,2))\n",
    "        experiments_result = run_experiments(train_HD, train_LD, train_Y, test_HD, test_LD, test_Y)\n",
    "        metrics_reporter = DimensionalityReductionQualityReport()\n",
    "        metrics_report = metrics_reporter.evaluate([test_HD, test_LD])\n",
    "        \n",
    "        result_object['RF-ACC'].append(experiments_result['RF-ACC'])\n",
    "        result_object['RF-F1'].append(experiments_result['RF-F1'])\n",
    "        result_object['SVC-ACC'].append(experiments_result['SVC-ACC'])\n",
    "        result_object['SVC-F1'].append(experiments_result['SVC-F1'])\n",
    "        result_object['KNN-ACC'].append(experiments_result['KNN-ACC'])\n",
    "        result_object['KNN-F1'].append(experiments_result['KNN-F1'])\n",
    "        \n",
    "        result_object['Trustworthiness'].append(metrics_report['trustworthiness'])\n",
    "        result_object['Continuity'].append(metrics_report['continuity'])\n",
    "        result_object['Co-k-NNs'].append(metrics_report['co k nearest neighbor size'])\n",
    "    return result_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "048b3fb3-798a-4999-baa4-2bb29ab10f33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topologically Regularized DeepAEforKuhar180ver2\n",
      "Using python to compute signatures\n",
      "DeepAEforKuhar180ver2, Input: 360 Inner dim: 2\n",
      "Epoch:1, P:10, Loss:17.2680, Loss-ae:17.1023, Loss-topo:0.1657\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_object \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF-ACC\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF-F1\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCo-k-NNs\u001b[39m\u001b[38;5;124m'\u001b[39m: []   \n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lambda_val \u001b[38;5;129;01min\u001b[39;00m lambdas_to_explore:\n\u001b[0;32m---> 14\u001b[0m     lambda_exploration \u001b[38;5;241m=\u001b[39m \u001b[43mexplore_lambda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_HD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_HD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimes_to_execute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutions_per_model\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# print(lambda_val, lambda_exploration)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj_property \u001b[38;5;129;01min\u001b[39;00m plot_object:\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mexplore_lambda\u001b[0;34m(train_HD, train_Y, test_HD, test_Y, topoae_lambda, times_to_execute)\u001b[0m\n\u001b[1;32m     21\u001b[0m topo_reducer \u001b[38;5;241m=\u001b[39m TopologicalDimensionalityReduction(\n\u001b[1;32m     22\u001b[0m     ae_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepAEforKuhar180ver2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m     lam\u001b[38;5;241m=\u001b[39mtopoae_lambda,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m title_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMotionSense 20Hz\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTopoAE lambda \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(topoae_lambda)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtopo_reducer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_HD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle_plot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m train_LD \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(topo_reducer\u001b[38;5;241m.\u001b[39mtransform(train_HD), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     31\u001b[0m test_LD \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(topo_reducer\u001b[38;5;241m.\u001b[39mtransform(test_HD), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/librep-hiaac/experiments/Topological_ae/MotionSense20Hz/../../../librep/transforms/topo_ae.py:58\u001b[0m, in \u001b[0;36mTopologicalDimensionalityReduction.fit\u001b[0;34m(self, X, y, title_plot)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     57\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m epoch_train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     60\u001b[0m epoch_train_ae_loss\u001b[38;5;241m.\u001b[39mappend(loss_components[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss.autoencoder\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:127\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:162\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    160\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:220\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 220\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:324\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    322\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    326\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_object = {\n",
    "    'RF-ACC': [],\n",
    "    'RF-F1': [],\n",
    "    'SVC-ACC': [],\n",
    "    'SVC-F1': [],\n",
    "    'KNN-ACC': [],\n",
    "    'KNN-F1': [],\n",
    "    'Trustworthiness': [],\n",
    "    'Continuity': [],\n",
    "    'Co-k-NNs': []   \n",
    "}\n",
    "\n",
    "for lambda_val in lambdas_to_explore:\n",
    "    lambda_exploration = explore_lambda(\n",
    "        train_HD, train_Y,\n",
    "        test_HD, test_Y,\n",
    "        lambda_val,\n",
    "        times_to_execute=executions_per_model\n",
    "    )\n",
    "    # print(lambda_val, lambda_exploration)\n",
    "    for obj_property in plot_object:\n",
    "        plot_object[obj_property].append(lambda_exploration[obj_property])\n",
    "    \n",
    "# print(plot_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef0ac1-32bc-47a4-a1ca-84e6857a310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d4f38-de7f-462e-b504-a60c13c21397",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_object_saved = {'RF-ACC': [[0.5095098039215686, 0.5008823529411764], [0.4161764705882353, 0.42176470588235293]], 'RF-F1': [[0.49179524749560927, 0.4825998620752542], [0.40408103491063885, 0.4071600380974815]], 'SVC-ACC': [[0.47352941176470587, 0.48627450980392156], [0.4176470588235294, 0.4117647058823529]], 'SVC-F1': [[0.4538097485723428, 0.4705534070174303], [0.4152887024635492, 0.41499434939058094]], 'KNN-ACC': [[0.4666666666666667, 0.4803921568627451], [0.3862745098039216, 0.396078431372549]], 'KNN-F1': [[0.4452147079162524, 0.45839529688826636], [0.371054456612864, 0.37736989134266463]], 'Trustworthiness': [[0.7719692370386387, 0.7781493595758358], [0.7561429426147466, 0.7599074709140489]], 'Continuity': [[0.9078381880854003, 0.9064790417755566], [0.902133332583212, 0.9145900742326505]], 'Co-k-NNs': [[0.27796859666339546, 0.28336604514229635], [0.2615922473012758, 0.28361138370951916]]}\n",
    "plot_object_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebdb669-ed1d-4177-9cd6-f8bf7c4d0226",
   "metadata": {},
   "source": [
    "## Plot ALL means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4effdcb6-4b5e-4c66-b054-00a200b76c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = range(len(lambdas_to_explore))\n",
    "plt.xticks(data_x, [str(val) for val in lambdas_to_explore])\n",
    "for obj_property in plot_object:\n",
    "    data_y = [val[1] for val in plot_object[obj_property]]\n",
    "    plt.plot(data_x, data_y, label=obj_property)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('Metrics values over lambdas\\nKuHar20Hz TopoAE-2dim')\n",
    "plt.xlabel('Lambda value')\n",
    "plt.ylabel('Metric value')\n",
    "plt.grid()\n",
    "plt.ylim((0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12d3a6-7da2-4cce-bd64-7723ebc9b632",
   "metadata": {},
   "source": [
    "## Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea6741-8952-48f6-8365-19b6fc0b6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_properties(plot_object, lambdas_to_explore, properties_to_plot):\n",
    "    fig, ax = plt.subplots()\n",
    "    data_x = range(len(lambdas_to_explore))\n",
    "    plt.xticks(data_x, [str(val) for val in lambdas_to_explore])\n",
    "    for obj_property in properties_to_plot:\n",
    "        mean_y = [val[1] for val in plot_object[obj_property]]\n",
    "        min_y = [val[0] for val in plot_object[obj_property]]\n",
    "        max_y = [val[2] for val in plot_object[obj_property]]\n",
    "        ax.plot(data_x, mean_y, label=obj_property)\n",
    "        ax.fill_between(data_x, min_y, max_y, alpha=0.2)\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.title('Metrics values over lambdas\\nKuHar20Hz TopoAE-2dim')\n",
    "    plt.xlabel('Lambda value')\n",
    "    plt.ylabel('Metric value')\n",
    "    plt.grid()\n",
    "    plt.ylim((0, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab0726-3be7-487c-a050-9dbe7462b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_to_plot = [\n",
    "    'RF-ACC', 'RF-F1',\n",
    "    'SVC-ACC', 'SVC-F1',\n",
    "    'KNN-ACC', 'KNN-F1',\n",
    "    'Trustworthiness',\n",
    "    'Continuity',\n",
    "    'Co-k-NNs'\n",
    "]\n",
    "plot_properties(plot_object, lambdas_to_explore, properties_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8764170-bac4-4c61-aa51-76acf9e4faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_to_plot = [\n",
    "    'RF-ACC',\n",
    "    'SVC-ACC',\n",
    "    'KNN-ACC'\n",
    "]\n",
    "plot_properties(plot_object, lambdas_to_explore, properties_to_plot)\n",
    "properties_to_plot = [\n",
    "    'Trustworthiness',\n",
    "    'Continuity',\n",
    "    'Co-k-NNs'\n",
    "]\n",
    "plot_properties(plot_object, lambdas_to_explore, properties_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d85cd-08de-413c-8151-2224a322e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 ==0\n",
    "asda = {'asd': [2, 3], 'asdasd': [3,4,5]}\n",
    "for i in asda:\n",
    "    asda[i] = np.mean(asda[i])\n",
    "print(asda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc9045-2091-43dd-8eaf-ae4891ba87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.topo_ae import TopologicalDimensionalityReduction\n",
    "from librep.estimators.ae.torch.models.topological_ae.topological_ae import TopologicallyRegularizedAutoencoder\n",
    "kwargs = {'input_dims':180, 'custom_dim':2}\n",
    "input_shape = (-1, 1, 180)\n",
    "topoae_lambda = 10000\n",
    "topo_reducer = TopologicalDimensionalityReduction(ae_model='DeepAEforKuhar180ver2', lam=topoae_lambda,\n",
    "                                                      ae_kwargs=kwargs, input_shape=input_shape, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0d951-16b3-4993-9132-01d3b4c32c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_plot = \"KUHAR 20Hz\\nTopoAE lambda \" + str(topoae_lambda)\n",
    "topo_reducer.fit(train_HD, train_Y, title_plot=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca5d04-aef6-4e79-a72d-134274a0f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(topo_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(topo_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d27153-d050-4169-9298-5b3e99b21d5f",
   "metadata": {},
   "source": [
    "## Obtain classification metrics (RF, SVC, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e400093-fd1b-4032-8e92-f40c69d38603",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_result = run_experiments(train_HD, train_LD, train_Y, test_HD, test_LD, test_Y)\n",
    "experiments_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1102a-cf26-4023-923a-c4eb92727bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['Topo-AEv2 (L=10000)'][0] = experiments_result['RF-ACC']\n",
    "table_info['Topo-AEv2 (L=10000)'][1] = experiments_result['RF-F1']\n",
    "table_info['Topo-AEv2 (L=10000)'][2] = experiments_result['SVC-ACC']\n",
    "table_info['Topo-AEv2 (L=10000)'][3] = experiments_result['SVC-F1']\n",
    "table_info['Topo-AEv2 (L=10000)'][4] = experiments_result['KNN-ACC']\n",
    "table_info['Topo-AEv2 (L=10000)'][5] = experiments_result['KNN-F1']\n",
    "\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ffac9-b486-441d-9e40-bee70f6fd362",
   "metadata": {},
   "source": [
    "## Obtain quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4a69e-d7e7-4559-a107-9c59c26ba551",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reporter = DimensionalityReductionQualityReport()\n",
    "metrics_report = metrics_reporter.evaluate([test_HD, test_LD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389d291-7c0f-4556-9379-fdeb99990e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916d886-dfc5-4b1b-9f8a-1518678a50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['Topo-AEv2 (L=10000)'][6] = metrics_report['trustworthiness']\n",
    "table_info['Topo-AEv2 (L=10000)'][7] = metrics_report['continuity']\n",
    "table_info['Topo-AEv2 (L=10000)'][8] = metrics_report['co k nearest neighbor size']\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7ddc1-2e9d-49eb-bc9a-448be0cfc094",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26da82-33dc-40e6-b592-37ea06fcf1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_to_use = [0,1,2,3,4,5]\n",
    "visualize(test_LD, test_Y)\n",
    "# visualize(test_LD, test_Y, filtered=filter_to_use, xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "visualize(test_LD, test_Y, filtered=filter_to_use)\n",
    "# for f in filter_to_use:\n",
    "    # visualize(test_LD, test_Y, filtered=[f], xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "    # visualize(test_LD, test_Y, filtered=[f])\n",
    "# 0 sit\n",
    "# 1 stand\n",
    "# 2 walk\n",
    "# 3 stair up\n",
    "# 4 stair down\n",
    "# 5 run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e715bc-7cd6-4661-8d33-29248bc2b631",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **SECTION:** UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e4f34-2a18-4ae4-b9a9-253c1468f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_reducer = UMAP()\n",
    "umap_reducer.fit(train_HD, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2cc99-8e29-40a8-8328-0fd601be73ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_LD = np.reshape(umap_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(umap_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052ee4a-7226-44b7-9895-023c3cf93143",
   "metadata": {},
   "source": [
    "## Obtain classification metrics (RF, SVC, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b242093-b472-4040-9e3f-be936ac65a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_result = run_experiments(train_HD, train_LD, train_Y, test_HD, test_LD, test_Y)\n",
    "experiments_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151bcbc-9f78-45ed-929b-891bd5048d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['UMAP'][0] = experiments_result['RF-ACC']\n",
    "table_info['UMAP'][1] = experiments_result['RF-F1']\n",
    "table_info['UMAP'][2] = experiments_result['SVC-ACC']\n",
    "table_info['UMAP'][3] = experiments_result['SVC-F1']\n",
    "table_info['UMAP'][4] = experiments_result['KNN-ACC']\n",
    "table_info['UMAP'][5] = experiments_result['KNN-F1']\n",
    "\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3fce7-df2b-48a4-932e-bf16f56ea68b",
   "metadata": {},
   "source": [
    "## Obtain quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc64e8-c11b-4a5e-b0e6-87c19847b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reporter = DimensionalityReductionQualityReport()\n",
    "metrics_report = metrics_reporter.evaluate([test_HD, test_LD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86993c52-d5cc-45f4-b20a-6ad90a718483",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492b6cd-e2b7-42ac-80d0-5e207569c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['UMAP'][6] = metrics_report['trustworthiness']\n",
    "table_info['UMAP'][7] = metrics_report['continuity']\n",
    "table_info['UMAP'][8] = metrics_report['co k nearest neighbor size']\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9f81c-a758-4212-9f03-76418eca1e63",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3cecd-e2d0-4b2a-ba31-b6c29a96fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_use = [0,1,2,3,4,5]\n",
    "visualize(test_LD, test_Y)\n",
    "# visualize(test_LD, test_Y, filtered=filter_to_use, xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "visualize(test_LD, test_Y, filtered=filter_to_use)\n",
    "# for f in filter_to_use:\n",
    "    # visualize(test_LD, test_Y, filtered=[f], xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "    # visualize(test_LD, test_Y, filtered=[f])\n",
    "# 0 sit\n",
    "# 1 stand\n",
    "# 2 walk\n",
    "# 3 stair up\n",
    "# 4 stair down\n",
    "# 5 run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2e616-e1ba-4abd-9bb8-9c4a126e11bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **SECTION:** Metrics AE (metric=coknns, lambda=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d8755-894d-4be6-a7c6-b3dbc9568e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.adapted_ae import AdaptedAEDimensionalityReduction\n",
    "from librep.estimators.ae.torch.models.topological_ae.topological_ae import MetricsRegularizedAutoencoder\n",
    "kwargs = {'input_dims':180, 'custom_dim':2}\n",
    "input_shape = (-1, 1, 180)\n",
    "mae_lambda = 1000\n",
    "mae_reducer = AdaptedAEDimensionalityReduction(\n",
    "    ae_model='DeepAEforKuhar180ver2',\n",
    "    lam=mae_lambda,\n",
    "    metric='coknns',\n",
    "    ae_kwargs=kwargs,\n",
    "    input_shape=input_shape,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156ecc2-557b-459a-a704-7fc247b88c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_plot = \"KUHAR 20Hz\\nAdaptedAE lambda \" + str(mae_lambda)\n",
    "mae_reducer.fit(train_HD, train_Y, title_plot=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380ae9f-853f-48af-aac2-414095c1ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(mae_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(mae_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b026581-1b00-4546-b072-505e2a93b3c8",
   "metadata": {},
   "source": [
    "## Obtain classification metrics (RF, SVC, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483bd37-71b2-48f8-a564-f35da920e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_result = run_experiments(train_HD, train_LD, train_Y, test_HD, test_LD, test_Y)\n",
    "experiments_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f494d-2d80-434b-8d60-ef20a0244c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['M-AE (L=1000)'][0] = experiments_result['RF-ACC']\n",
    "table_info['M-AE (L=1000)'][1] = experiments_result['RF-F1']\n",
    "table_info['M-AE (L=1000)'][2] = experiments_result['SVC-ACC']\n",
    "table_info['M-AE (L=1000)'][3] = experiments_result['SVC-F1']\n",
    "table_info['M-AE (L=1000)'][4] = experiments_result['KNN-ACC']\n",
    "table_info['M-AE (L=1000)'][5] = experiments_result['KNN-F1']\n",
    "\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93f5ca-8253-4f40-9190-9fccda38615c",
   "metadata": {},
   "source": [
    "## Obtain quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081aab0f-d66c-4692-a3d3-e3d5788698b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reporter = DimensionalityReductionQualityReport()\n",
    "metrics_report = metrics_reporter.evaluate([test_HD, test_LD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e745248-6ea6-4bab-ad84-7df9096a2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3cd63a-8d19-4c05-acd3-60b7cb7d76c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['M-AE (L=1000)'][6] = metrics_report['trustworthiness']\n",
    "table_info['M-AE (L=1000)'][7] = metrics_report['continuity']\n",
    "table_info['M-AE (L=1000)'][8] = metrics_report['co k nearest neighbor size']\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787528ea-293f-4a60-929d-60290946dcc0",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c34a59-e88a-49b7-9c97-6401f081760f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_to_use = [0,1,2,3,4,5]\n",
    "visualize(test_LD, test_Y)\n",
    "# visualize(test_LD, test_Y, filtered=filter_to_use, xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "visualize(test_LD, test_Y, filtered=filter_to_use)\n",
    "# for f in filter_to_use:\n",
    "    # visualize(test_LD, test_Y, filtered=[f], xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "    # visualize(test_LD, test_Y, filtered=[f])\n",
    "# 0 sit\n",
    "# 1 stand\n",
    "# 2 walk\n",
    "# 3 stair up\n",
    "# 4 stair down\n",
    "# 5 run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663f939-2dd5-4b98-87f8-c6e78467716c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **SECTION:** Metrics AE (metric=coknns, lambda=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17a672-37ef-420a-8c6f-9491facc050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.adapted_ae import AdaptedAEDimensionalityReduction\n",
    "from librep.estimators.ae.torch.models.topological_ae.topological_ae import MetricsRegularizedAutoencoder\n",
    "kwargs = {'input_dims':180, 'custom_dim':2}\n",
    "input_shape = (-1, 1, 180)\n",
    "mae_lambda = 10000\n",
    "mae_reducer = AdaptedAEDimensionalityReduction(\n",
    "    ae_model='DeepAEforKuhar180ver2',\n",
    "    lam=mae_lambda,\n",
    "    metric='coknns',\n",
    "    ae_kwargs=kwargs,\n",
    "    input_shape=input_shape,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e01f8-3db9-46dd-8a89-f614752c0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_plot = \"KUHAR 20Hz\\nAdaptedAE lambda \" + str(mae_lambda)\n",
    "mae_reducer.fit(train_HD, train_Y, title_plot=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acfa185-e4ae-4182-b522-41a2b3db3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(mae_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(mae_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b895a-ef55-4613-b546-64c54c3a5aaf",
   "metadata": {},
   "source": [
    "## Obtain classification metrics (RF, SVC, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5e743-e008-4a22-be18-603de6b31df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_result = run_experiments(train_HD, train_LD, train_Y, test_HD, test_LD, test_Y)\n",
    "experiments_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5358b-e18e-4e47-942e-6f2577d17481",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['M-AE (L=10000)'][0] = experiments_result['RF-ACC']\n",
    "table_info['M-AE (L=10000)'][1] = experiments_result['RF-F1']\n",
    "table_info['M-AE (L=10000)'][2] = experiments_result['SVC-ACC']\n",
    "table_info['M-AE (L=10000)'][3] = experiments_result['SVC-F1']\n",
    "table_info['M-AE (L=10000)'][4] = experiments_result['KNN-ACC']\n",
    "table_info['M-AE (L=10000)'][5] = experiments_result['KNN-F1']\n",
    "\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153dd8fb-e980-43b1-8300-84213c1115e7",
   "metadata": {},
   "source": [
    "## Obtain quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1bff6-6849-4223-8bf7-e1448a908c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reporter = DimensionalityReductionQualityReport()\n",
    "metrics_report = metrics_reporter.evaluate([test_HD, test_LD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15850a2-881e-4901-8ee7-1ef4e00ec8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064282f-e1aa-4eff-a80b-12cb68542f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info['M-AE (L=10000)'][6] = metrics_report['trustworthiness']\n",
    "table_info['M-AE (L=10000)'][7] = metrics_report['continuity']\n",
    "table_info['M-AE (L=10000)'][8] = metrics_report['co k nearest neighbor size']\n",
    "print_table(table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d89d7a-e70a-42bd-8ab5-8d48b7268f18",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854ed23-f741-4907-aa61-0b2634b1c5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_to_use = [0,1,2,3,4,5]\n",
    "visualize(test_LD, test_Y)\n",
    "# visualize(test_LD, test_Y, filtered=filter_to_use, xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "visualize(test_LD, test_Y, filtered=filter_to_use)\n",
    "# for f in filter_to_use:\n",
    "    # visualize(test_LD, test_Y, filtered=[f], xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "    # visualize(test_LD, test_Y, filtered=[f])\n",
    "# 0 sit\n",
    "# 1 stand\n",
    "# 2 walk\n",
    "# 3 stair up\n",
    "# 4 stair down\n",
    "# 5 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd7a5e-e570-4976-a119-60417b64053d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
