{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40df6f11-a295-4bb3-8ad7-c167a0adb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ae4be2-202a-476a-85fa-478520f4a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 11:54:24.248761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-18 11:54:24.248783: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  # For defining dataset Paths\n",
    "import sys                # For include librep package\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librep imports\n",
    "from librep.utils.dataset import PandasDatasetsIO          # For quick load train, test and validation CSVs\n",
    "from librep.datasets.multimodal import PandasMultiModalDataset # Wrap CSVs to librep's `Dataset` interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a423355-2d96-48a5-918f-e29e4777de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from librep.metrics.report import ClassificationReport\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42894747-02af-43dc-a7de-82a40fc37f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for KuHar resampled to 20Hz view with the same activities (and labels numbers)\n",
    "# It is assumed that the directory will contain (train.csv, test.csv and validation.csv)\n",
    "dataset_path = Path(\"../../data/old-views/KuHar/resampled_view_20Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de491788-8150-4578-a248-996c054c21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuhar dataframes\n",
    "train, validation, test = PandasDatasetsIO(dataset_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017e09b2-e292-4e2a-80a4-0e506c9a4311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accel-x-0</th>\n",
       "      <th>accel-x-1</th>\n",
       "      <th>accel-x-2</th>\n",
       "      <th>accel-x-3</th>\n",
       "      <th>accel-x-4</th>\n",
       "      <th>accel-x-5</th>\n",
       "      <th>accel-x-6</th>\n",
       "      <th>accel-x-7</th>\n",
       "      <th>accel-x-8</th>\n",
       "      <th>...</th>\n",
       "      <th>accel-start-time</th>\n",
       "      <th>gyro-start-time</th>\n",
       "      <th>accel-end-time</th>\n",
       "      <th>gyro-end-time</th>\n",
       "      <th>activity code</th>\n",
       "      <th>length</th>\n",
       "      <th>serial</th>\n",
       "      <th>index</th>\n",
       "      <th>user</th>\n",
       "      <th>normalized activity code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>-0.014972</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>-0.014827</td>\n",
       "      <td>...</td>\n",
       "      <td>23.235</td>\n",
       "      <td>23.223</td>\n",
       "      <td>26.260</td>\n",
       "      <td>26.249</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2100</td>\n",
       "      <td>1051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>-0.003186</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>-0.032074</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>...</td>\n",
       "      <td>56.292</td>\n",
       "      <td>56.292</td>\n",
       "      <td>59.245</td>\n",
       "      <td>59.245</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>5700</td>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>-0.021763</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.004968</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>...</td>\n",
       "      <td>27.268</td>\n",
       "      <td>27.267</td>\n",
       "      <td>30.290</td>\n",
       "      <td>30.291</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2700</td>\n",
       "      <td>1075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.009241</td>\n",
       "      <td>-0.004666</td>\n",
       "      <td>0.021606</td>\n",
       "      <td>-0.007200</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>-0.008149</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>...</td>\n",
       "      <td>39.421</td>\n",
       "      <td>39.420</td>\n",
       "      <td>42.441</td>\n",
       "      <td>42.440</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>3900</td>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>-0.005612</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>-0.004159</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>...</td>\n",
       "      <td>23.703</td>\n",
       "      <td>23.703</td>\n",
       "      <td>26.656</td>\n",
       "      <td>26.656</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2400</td>\n",
       "      <td>1038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  accel-x-0  accel-x-1  accel-x-2  accel-x-3  accel-x-4  \\\n",
       "0           0   0.001911  -0.014536   0.005845   0.003675  -0.014972   \n",
       "1           1   0.004114  -0.003186   0.000759   0.012450  -0.032074   \n",
       "2           2  -0.011282  -0.002432  -0.003199   0.008152  -0.021763   \n",
       "3           3  -0.009241  -0.004666   0.021606  -0.007200   0.003091   \n",
       "4           4  -0.013083  -0.005612   0.001645   0.006823  -0.004159   \n",
       "\n",
       "   accel-x-5  accel-x-6  accel-x-7  accel-x-8  ...  accel-start-time  \\\n",
       "0   0.025607   0.000478  -0.031141  -0.014827  ...            23.235   \n",
       "1   0.007270  -0.000470   0.006980   0.021400  ...            56.292   \n",
       "2   0.000309  -0.004968  -0.009551   0.001497  ...            27.268   \n",
       "3   0.001630   0.005057  -0.008149   0.013167  ...            39.421   \n",
       "4   0.000415   0.008178   0.002637  -0.000827  ...            23.703   \n",
       "\n",
       "   gyro-start-time  accel-end-time  gyro-end-time  activity code  length  \\\n",
       "0           23.223          26.260         26.249              0     300   \n",
       "1           56.292          59.245         59.245              0     300   \n",
       "2           27.267          30.290         30.291              0     300   \n",
       "3           39.420          42.441         42.440              0     300   \n",
       "4           23.703          26.656         26.656              0     300   \n",
       "\n",
       "   serial  index  user  normalized activity code  \n",
       "0       1   2100  1051                         1  \n",
       "1       1   5700  1037                         1  \n",
       "2       1   2700  1075                         1  \n",
       "3       6   3900  1008                         1  \n",
       "4       1   2400  1038                         1  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb43522-3bbf-4369-af25-6aba6bbe7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuhar features to select\n",
    "features = [\n",
    "    \"accel-x\",\n",
    "    \"accel-y\",\n",
    "    \"accel-z\",\n",
    "    \"gyro-x\",\n",
    "    \"gyro-y\",\n",
    "    \"gyro-z\"\n",
    "]\n",
    "\n",
    "# Creating the datasets\n",
    "\n",
    "# Train\n",
    "train_dataset = PandasMultiModalDataset(\n",
    "    train,\n",
    "    feature_prefixes=features,\n",
    "    label_columns=\"activity code\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "# Validation\n",
    "validation_dataset = PandasMultiModalDataset(\n",
    "    validation,\n",
    "    feature_prefixes=features,\n",
    "    label_columns=\"activity code\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "# Test\n",
    "test_dataset = PandasMultiModalDataset(\n",
    "    test,\n",
    "    feature_prefixes=features,\n",
    "    label_columns=\"activity code\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8966bf11-2c32-4901-9a9f-c7f40735a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.datasets.multimodal import TransformMultiModalDataset\n",
    "from librep.transforms.fft import FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9a59e3-f891-4479-84cf-ef32e543dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_transform = FFT(centered = True)\n",
    "transformer = TransformMultiModalDataset(transforms=[fft_transform], new_window_name_prefix=\"fft.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ac2abb-b3f6-4729-ab08-e87a5d279343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_fft = transformer(train_dataset)\n",
    "validation_dataset_fft = transformer(validation_dataset)\n",
    "test_dataset_fft = transformer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b81d10b-7ac8-41b5-8a18-453954828edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3330, 180)\n",
      "(108, 180)\n",
      "(378, 180)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_fft.X.shape)\n",
    "print(validation_dataset_fft.X.shape)\n",
    "print(test_dataset_fft.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66de95c-9631-4a7e-8465-ef7df0de2b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182.4630044066\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_dataset_fft.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373929cf-94f3-400c-9f16-6b9846f6bbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.08923330e-02, 1.12081089e-01, 6.03699767e-02, ...,\n",
       "        6.86907330e-03, 1.25349286e-02, 1.69158661e-02],\n",
       "       [1.53802877e-02, 8.24343989e-02, 4.18766153e-02, ...,\n",
       "        3.72912157e-03, 3.98584265e-03, 1.71193131e-02],\n",
       "       [5.21272671e-02, 4.82816195e-02, 8.93573044e-02, ...,\n",
       "        9.75422945e-03, 2.66463902e-02, 7.84359780e-03],\n",
       "       ...,\n",
       "       [2.46594280e+00, 2.97792077e+01, 2.58438841e+01, ...,\n",
       "        1.43625028e+00, 7.98405975e-01, 2.66617405e-01],\n",
       "       [3.12703194e+00, 2.12859482e+01, 9.31637610e+00, ...,\n",
       "        4.71804217e-01, 9.06413206e-01, 6.75740676e-01],\n",
       "       [1.48890233e+01, 6.63385820e+00, 8.58902995e+00, ...,\n",
       "        3.19953749e-01, 1.27100790e-01, 3.83110579e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_fft.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ace16e-1d84-447c-a3fb-0014b93e8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HD = train_dataset_fft.X\n",
    "train_LD = None\n",
    "train_Y = train_dataset_fft.y\n",
    "test_HD = test_dataset_fft.X\n",
    "test_LD = None\n",
    "test_Y = test_dataset_fft.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71409f92-8cd5-434b-919f-d068996dbc66",
   "metadata": {},
   "source": [
    "# Applying Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9b17e-f585-4143-942f-b9138a69c24e",
   "metadata": {},
   "source": [
    "MinMaxScaler, MaxAbsScaler and StandardScaler apply the scaling PER FEATURE, which means the distance between points would actually be modified, and so, the ranking as well.\n",
    "Because of this, a new Scaler is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aef63d19-395c-478e-867e-7a7947351220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.994482399996557e-05, 1182.4630044066)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = np.min(train_HD)\n",
    "max_val = np.max(train_HD)\n",
    "min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd644b31-3e3c-4a92-a2ee-3f61be6f8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HD = (train_HD - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acffa246-3c1b-4b61-afde-3b8e1999a0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = np.min(train_HD)\n",
    "max_val = np.max(train_HD)\n",
    "min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46248f1a-e532-4c3a-8f3d-5ce8f97a95b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n\u001b[1;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mMinMaxScaler()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==0\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "# train_scaled = scaler.fit_transform(train_dataset_fft.X)\n",
    "# test_scaled = scaler.fit_transform(test_dataset_fft.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea5136-59dd-4e00-8037-8545ad3a3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(train_scaled), np.max(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743e300-d869-4128-a490-f6eac79155fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HD = scaler.fit_transform(train_dataset_fft.X)\n",
    "train_LD = None\n",
    "# train_Y = train_dataset_fft.y\n",
    "test_HD = scaler.fit_transform(test_dataset_fft.X)\n",
    "test_LD = None\n",
    "# test_Y = test_dataset_fft.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e96a7c-825d-490f-81a2-7a380c801507",
   "metadata": {},
   "source": [
    "## Computing accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096e2e2-6baf-409a-841c-712936394f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6cdf66-a7b4-4a22-84a6-6f77036da576",
   "metadata": {},
   "source": [
    "# Reducing with Generic AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ddffca-de30-4ed9-b052-3db59efceaa0",
   "metadata": {},
   "source": [
    "The topological autoencoder can be used as a generic one by applying a lambda value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb2e0e-c9b3-4c3a-9b4e-4301a75a19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.topo_ae import TopologicalDimensionalityReduction\n",
    "from librep.estimators.ae.torch.models.topological_ae.topological_ae import TopologicallyRegularizedAutoencoder\n",
    "\n",
    "kwargs = {'input_dims':180, 'custom_dim':2}\n",
    "input_shape = (-1, 1, 180)\n",
    "topoae_lambda = 0\n",
    "topo_reducer = TopologicalDimensionalityReduction(\n",
    "    ae_model='DeepAEforKuhar180ver2',\n",
    "    lam = topoae_lambda,\n",
    "    ae_kwargs = kwargs,\n",
    "    input_shape = input_shape,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596dfb0-fa46-483b-81d7-7d033a279b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_plot = \"KUHAR 20Hz\\nTopoAE lambda \" + str(topoae_lambda)\n",
    "topo_reducer.fit(train_HD, train_Y, title_plot=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27674f22-3729-4a48-9a63-0f0dd50ae167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(topo_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(topo_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0a5df-871a-4588-8707-06bf3560e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD_pd = pd.DataFrame(train_LD)\n",
    "train_LD_pd['y'] = train_Y\n",
    "train_pmd = PandasMultiModalDataset(\n",
    "    train_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "test_LD_pd = pd.DataFrame(test_LD)\n",
    "test_LD_pd['y'] = test_Y\n",
    "\n",
    "test_pmd = PandasMultiModalDataset(\n",
    "    test_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e987e8-c0c1-4a26-a35d-51c96cbae2b0",
   "metadata": {},
   "source": [
    "## Set Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c120c-b28a-4940-a6e6-278ab9bd98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = ClassificationReport(\n",
    "    use_accuracy=True, \n",
    "    use_f1_score=True,\n",
    "    use_classification_report=False,\n",
    "    use_confusion_matrix=False,\n",
    "    plot_confusion_matrix=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b236bf-4685-4f0a-b02b-89693d92e4da",
   "metadata": {},
   "source": [
    "## Experiment for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57049b28-13f9-439a-a15b-20612cf669b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    estimator_creation_kwags ={'n_estimators':100} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ca0d2-a4c1-4a3e-af14-af6fcae0281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48431342-4f0c-44e7-a3d0-30278feb6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7f5b5-3d3a-4c3e-8ce1-ee9148cf9896",
   "metadata": {},
   "source": [
    "## Experiment for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c907340-e8a5-4ced-9e97-250790b9bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC, \n",
    "    estimator_creation_kwags ={'C':3.0, 'kernel':\"rbf\"} ,\n",
    "    do_not_instantiate=False, \n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefbfdb-af98-4a0e-8d97-604ecb2170fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9d7f8-0d72-46e2-9431-a1cffade5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47acae-1816-45a5-9ec3-875db801b050",
   "metadata": {},
   "source": [
    "## Experiment for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb7520-ef7e-4a47-a482-2367ee13787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    estimator_creation_kwags ={'n_neighbors' :1} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d5e52-9588-48b0-bc05-b35897bc1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20aa509-fe30-4ec4-852a-8eb7bebc6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0f3ee-9908-4f24-90a7-f1f26bcedbd3",
   "metadata": {},
   "source": [
    "# Topological AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c084e-15e1-4b90-bdf2-7b48897f76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.topo_ae import TopologicalDimensionalityReduction\n",
    "from librep.estimators.ae.torch.models.topological_ae.topological_ae import TopologicallyRegularizedAutoencoder\n",
    "kwargs = {'input_dims':180, 'custom_dim':2}\n",
    "input_shape = (-1, 1, 180)\n",
    "topoae_lambda = 100\n",
    "topo_reducer = TopologicalDimensionalityReduction(ae_model='DeepAEforKuhar180ver2', lam=topoae_lambda,\n",
    "                                                      ae_kwargs=kwargs, input_shape=input_shape, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09d3ab-4b11-4a44-a3ae-b07826b2e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_plot = \"KUHAR 20Hz\\nTopoAE lambda \" + str(topoae_lambda)\n",
    "topo_reducer.fit(train_HD, train_Y, title_plot=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc9d19-306e-49d2-8a67-c9befbff6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(topo_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(topo_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac996e-7e64-4015-b672-a0e275ed896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD_pd = pd.DataFrame(train_LD)\n",
    "train_LD_pd['y'] = train_Y\n",
    "train_pmd = PandasMultiModalDataset(\n",
    "    train_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "test_LD_pd = pd.DataFrame(test_LD)\n",
    "test_LD_pd['y'] = test_Y\n",
    "\n",
    "test_pmd = PandasMultiModalDataset(\n",
    "    test_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073670c2-7335-41a4-92d9-875a2bd702b1",
   "metadata": {},
   "source": [
    "## Experiment for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6727ab-ad90-4e5c-9b88-21cdb04b9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    estimator_creation_kwags ={'n_estimators':100} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97498a09-3e27-4229-9052-89e8cb9dee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7eb9c-fad3-4a02-ad45-e6b7d60be348",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d0fa4-f56a-4d96-810f-280945458e75",
   "metadata": {},
   "source": [
    "## Experiment for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953fc45-b815-4183-81c5-a4fd5dbb48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC, \n",
    "    estimator_creation_kwags ={'C':3.0, 'kernel':\"rbf\"} ,\n",
    "    do_not_instantiate=False, \n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd551f4c-d2e3-43cf-804d-bbb68df390f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f82e5-a336-4433-8b22-00b69ac2d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0448bb0b-3dc6-4d03-92ea-5db5fe33bc32",
   "metadata": {},
   "source": [
    "## Experiment for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165505c2-0da4-4a4c-93a6-9006d7ec2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    estimator_creation_kwags ={'n_neighbors' :1} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98613c7e-3413-48a8-a431-1c1f0ed5ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141a45d-c365-4da0-90c9-f64dade9e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9008ea4-8d3b-4d5d-bbeb-f66bf68be2d9",
   "metadata": {},
   "source": [
    "# Topological AE - Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdde78-bf53-4dd0-9a85-34515fff755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms.topo_ae import TopologicalDimensionalityReduction\n",
    "from librep.estimators.ae.torch.models.topological_ae.topological_ae import TopologicallyRegularizedAutoencoder\n",
    "kwargs = {'input_dims':180, 'custom_dim':2}\n",
    "input_shape = (-1, 1, 180)\n",
    "topoae_lambda = 100\n",
    "topo_reducer = TopologicalDimensionalityReduction(ae_model='DeepAEforKuhar180ver3', lam=topoae_lambda,\n",
    "                                                      ae_kwargs=kwargs, input_shape=input_shape, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa9ca2-b710-4040-bfee-842ee04cf813",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_plot = \"KUHAR 20Hz\\nTopoAE lambda \" + str(topoae_lambda)\n",
    "topo_reducer.fit(train_HD, train_Y, title_plot=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd27b0-cfb2-453f-98d1-72d7aa4bb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(topo_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(topo_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff6e22-ba7a-452a-be76-f3bc5cb193a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD_pd = pd.DataFrame(train_LD)\n",
    "train_LD_pd['y'] = train_Y\n",
    "train_pmd = PandasMultiModalDataset(\n",
    "    train_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "test_LD_pd = pd.DataFrame(test_LD)\n",
    "test_LD_pd['y'] = test_Y\n",
    "\n",
    "test_pmd = PandasMultiModalDataset(\n",
    "    test_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e759c9-fb95-4a4a-86c0-48404cc84e7d",
   "metadata": {},
   "source": [
    "## Experiment for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d26e06-ed33-411c-8355-ca2cc48657e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    estimator_creation_kwags ={'n_estimators':100} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e795243-190d-42d9-84bb-0d0ac2d64ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1044d2a-57c7-4e9a-b7fe-d08759011ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6edf550-17cf-4177-b831-5a9d4eace038",
   "metadata": {},
   "source": [
    "## Experiment for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91f613-d21a-4e54-9686-a6e416e5c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC, \n",
    "    estimator_creation_kwags ={'C':3.0, 'kernel':\"rbf\"} ,\n",
    "    do_not_instantiate=False, \n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414e362-cb3c-485c-8baf-6874f9d81ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29b3a2-1bcf-48bb-8bb9-bac0a33494a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6985e44-5daf-4204-9e2d-edadeaed26c9",
   "metadata": {},
   "source": [
    "## Experiment for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16e0ea-3ae6-416d-8576-c2781815e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    estimator_creation_kwags ={'n_neighbors' :1} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9473643-f004-4148-88a4-6534157e62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b833fc-1133-4374-a3a9-0a95bc47887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c3c06-8ebe-45fa-83df-bab8c977c345",
   "metadata": {},
   "source": [
    "# Reducing with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ddd57-133f-40c5-bec3-f60c235a0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms import UMAP\n",
    "umap_reducer = UMAP()\n",
    "umap_reducer.fit(train_HD, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c5bda-8460-40d5-bfc1-488f46b59301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD = np.reshape(umap_reducer.transform(train_HD), (-1,2))\n",
    "print('TRAIN LD RESHAPED', train_LD.shape)\n",
    "test_LD = np.reshape(umap_reducer.transform(test_HD), (-1,2))\n",
    "print('TEST LD RESHAPED', test_LD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a17ab8-966e-4628-b0a7-3b6ea7892931",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LD_pd = pd.DataFrame(train_LD)\n",
    "train_LD_pd['y'] = train_Y\n",
    "train_pmd = PandasMultiModalDataset(\n",
    "    train_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "test_LD_pd = pd.DataFrame(test_LD)\n",
    "test_LD_pd['y'] = test_Y\n",
    "\n",
    "test_pmd = PandasMultiModalDataset(\n",
    "    test_LD_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74677d64-769f-4bc1-aea3-306def565f88",
   "metadata": {},
   "source": [
    "## Experiment for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6f5ce-dac7-4081-bff1-95aaf0b3d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=RandomForestClassifier,\n",
    "    estimator_creation_kwags ={'n_estimators':100} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602245b2-4525-406c-9c23-1c9607a5339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687048e7-d5b4-4522-b289-52647c5c9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d87a1-55cd-4dae-be1b-dfc962e0c3f5",
   "metadata": {},
   "source": [
    "## Experiment for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5732244-fadd-48ff-a48d-b970c65dfe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=SVC, \n",
    "    estimator_creation_kwags ={'C':3.0, 'kernel':\"rbf\"} ,\n",
    "    do_not_instantiate=False, \n",
    "    do_fit=True,\n",
    "    evaluator=reporter)\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6670f85-2611-4372-ad98-c3ebe37b5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f125f6-7886-4985-a030-c1ce02482a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d5c04-637c-4a2b-ae81-594e121c22a1",
   "metadata": {},
   "source": [
    "## Experiment for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801daea-3931-44b5-9a45-e629de6b8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleTrainEvalWorkflow(\n",
    "    estimator=KNeighborsClassifier,\n",
    "    estimator_creation_kwags ={'n_neighbors' :1} ,\n",
    "    do_not_instantiate=False,\n",
    "    do_fit=True,\n",
    "    evaluator=reporter\n",
    ")\n",
    "\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addca2eb-1e07-4d46-bd7d-301f03f1da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multi_run_experiment(train_pmd, test_pmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e008b-8b08-4ac6-b6fd-942a4664175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean([run['result'][0]['accuracy'] for run in result['runs']])\n",
    "f1 = np.mean([run['result'][0]['f1 score (weighted)'] for run in result['runs']])\n",
    "print('ACCURACY', accuracy)\n",
    "print('F1', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec701e7-cbc5-4729-b876-d95bd3679b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da58db4-1b68-4ec1-abb8-9cbc7dd7b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e2353-2c32-4a36-8f8a-339fb854b52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de4175-6659-4ec4-98d2-95ec01f0d196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f757d-616a-4654-8ced-73dbd2677132",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_applied_topoae = transform_topoae.transform(test_dataset_fft.X)\n",
    "print('ORIGINAL', test_applied_topoae.shape)\n",
    "test_applied_topoae = np.reshape(test_applied_topoae, (-1,2))\n",
    "print('RESHAPED', test_applied_topoae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b950c-df3c-49d6-a670-43f7c57243f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_applied_topoae = transform_topoae.transform(train_dataset_fft.X)\n",
    "print('ORIGINAL', train_applied_topoae.shape)\n",
    "train_applied_topoae = np.reshape(train_applied_topoae, (-1,2))\n",
    "print('RESHAPED', train_applied_topoae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6642f6-7edc-42cd-8aad-a8c78d5d9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.transforms import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(X, Y, filtered=None, xlim=None, ylim=None):\n",
    "    data_grouped = list(zip(X, Y))\n",
    "    uniques = filtered\n",
    "    if filtered is None:\n",
    "        uniques = np.unique(Y)\n",
    "    \n",
    "    for uval in uniques:\n",
    "        data = [pair[0] for pair in data_grouped if pair[1]==uval]\n",
    "        data_x = [unit[0] for unit in data]\n",
    "        data_y = [unit[1] for unit in data]\n",
    "        plt.scatter(data_x, data_y, label = uval)\n",
    "    # print(data)\n",
    "    if xlim:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc11ca8-7adb-4c17-8534-502d39c0d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(test_applied_topoae, test_dataset_fft.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea4c42-9f33-4f2a-89ef-2df0deb8648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered\n",
    "filter_to_use = [0,1,2,3,4,5]\n",
    "visualize(test_applied_topoae, test_dataset_fft.y, filtered=filter_to_use, xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "for f in filter_to_use:\n",
    "    visualize(test_applied_topoae, test_dataset_fft.y, filtered=[f], xlim=(-1,0), ylim=(-0.5,1.75))\n",
    "# visualize(test_applied_topoae, test_dataset_fft.y, filtered=[1])\n",
    "# 0 sit\n",
    "# 1 stand\n",
    "# 2 walk\n",
    "# 3 stair up\n",
    "# 4 stair down\n",
    "# 5 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847cc400-a44b-4922-b86c-6d64fa240082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee60e08-dfaf-4eba-8e6d-435f07fe78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.metrics.dimred_evaluator import DimensionalityReductionQualityReport\n",
    "metrics_reporter = DimensionalityReductionQualityReport()\n",
    "metrics_train_applied_topoae = metrics_reporter.evaluate([test_dataset_fft.X, test_applied_topoae])\n",
    "print(metrics_train_applied_topoae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc088a1-967d-44c6-8e2b-7d91382676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librep.utils.workflow import SimpleTrainEvalWorkflow, MultiRunWorkflow\n",
    "from librep.estimators import RandomForestClassifier\n",
    "from librep.metrics.report import ClassificationReport\n",
    "import yaml\n",
    "\n",
    "reporter = ClassificationReport(use_accuracy=True, use_f1_score=True, use_classification_report=False, use_confusion_matrix=False, plot_confusion_matrix=False)\n",
    "experiment = SimpleTrainEvalWorkflow(estimator=RandomForestClassifier, estimator_creation_kwags ={'n_estimators':100} , do_not_instantiate=False, do_fit=True, evaluator=reporter)\n",
    "multi_run_experiment = MultiRunWorkflow(workflow=experiment, num_runs=3, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f3d78-2c1a-43e8-9175-7f0243a250bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_dset = PandasMultiModalDataset(\n",
    "    pd.concat([train, validation]),\n",
    "    feature_prefixes=features,\n",
    "    label_columns=\"activity code\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "\n",
    "result = multi_run_experiment(combined_train_dset, test_dataset)\n",
    "print(yaml.dump(result, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62169d9-001c-4df0-a37f-7141ba3e5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_dset_fft = transformer(combined_train_dset)\n",
    "\n",
    "result = multi_run_experiment(combined_train_dset_fft, test_dataset_fft)\n",
    "print(yaml.dump(result, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87bfdd-5ec9-4496-9094-2fd5dfc484f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_fft.y)\n",
    "\n",
    "print(combined_train_dset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921b2fd-63ff-4a69-9bb2-24bcba17e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Using the latent space\n",
    "train_applied_topoae = transform_topoae.transform(train_dataset_fft.X)\n",
    "print('ORIGINAL', train_applied_topoae.shape)\n",
    "train_applied_topoae = np.reshape(train_applied_topoae, (-1,2))\n",
    "print('RESHAPED', train_applied_topoae.shape)\n",
    "\n",
    "train_applied_topoae_pd = pd.DataFrame(train_applied_topoae)\n",
    "train_applied_topoae_pd['y'] = train_dataset_fft.y\n",
    "# print('FINAL', train_applied_topoae_pd)\n",
    "\n",
    "\n",
    "topoae_train_dset = PandasMultiModalDataset(\n",
    "    train_applied_topoae_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")\n",
    "\n",
    "test_applied_topoae_pd = pd.DataFrame(test_applied_topoae)\n",
    "test_applied_topoae_pd['y'] = test_dataset_fft.y\n",
    "# print('FINAL', test_applied_topoae_pd)\n",
    "\n",
    "topoae_test_dset = PandasMultiModalDataset(\n",
    "    test_applied_topoae_pd,\n",
    "    label_columns=\"y\",\n",
    "    as_array=True\n",
    ")\n",
    "result = multi_run_experiment(topoae_train_dset, topoae_test_dset)\n",
    "print(yaml.dump(result, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5fe55-1de7-46d8-af1c-33706ad018a2",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143808b8-6c0a-4dc3-88db-bf467f791eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = multi_run_experiment(topoae_train_dset, topoae_test_dset)\n",
    "print(yaml.dump(result, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156731c-43c8-4715-8735-c0ba3418609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = multi_run_experiment(topoae_train_dset, topoae_test_dset)\n",
    "print(yaml.dump(result, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bcba68-96fb-4b2e-8571-d4d3d2b423a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf20d5c-c5ca-41e4-99fc-082e97cf8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[-1, 2], [0, 2], [0, 3], [1, 4]]\n",
    "data = [[-1, 2, 0, 2, 0, 3, 1, 5], [-1, 2, 0, 2, 0, 3, 1, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ef098-b966-4935-a63a-2d76a0efb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler().fit(data)\n",
    "print(\"MINMAX\\n\", scaler.transform(data))\n",
    "scaler = MaxAbsScaler().fit(data)\n",
    "print(\"MAXABS\\n\", scaler.transform(data))\n",
    "scaler = StandardScaler().fit(data)\n",
    "print(\"STANDARD\\n\", scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6140b4c-6bc0-4aa6-a621-3eada87de695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "transformer = MaxAbsScaler().fit(X)\n",
    "transformer\n",
    "\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54f064-9981-466f-8c8a-1d28ea65f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "print(scaler.fit(data))\n",
    "\n",
    "print(scaler.mean_)\n",
    "\n",
    "print(scaler.transform(data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(scaler.transform([[2, 2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
