{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916bb3b8-d6b2-4f4a-ad6e-a57b35ce0738",
   "metadata": {},
   "source": [
    "# Padronizador de views de HAR\n",
    "\n",
    "Este notebook auxilia a padronizar as views dos datasets de HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a8fc9c-ebed-44ee-943a-14823e75f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7215239d-b7e1-4d8f-9d52-bb26997360e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_views_dir = Path(\"../data/old-views/\")    # Local onde as views de encontram (entrada)\n",
    "output_dir = Path(\"../data/views\")             # Local onde as views padronizadas serão colocadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b579c7eb-eb71-4928-9e10-af61d7de5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de atividades padronizado\n",
    "standartized_codes = {\n",
    "    0: \"sit\",\n",
    "    1: \"stand\",\n",
    "    2: \"walk\",\n",
    "    3: \"stair up\",\n",
    "    4: \"stair down\",\n",
    "    5: \"run\",\n",
    "    6: \"stair up and down\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77779a5-e5e9-4c4a-b87f-b59e12676e0e",
   "metadata": {},
   "source": [
    "## Descrição das views a serem processadas\n",
    "\n",
    "A variavel `views` é um dicionário, onde cada chave é o nome do dataset (nome da pasta do dataset raíz, onde possui as views dentro) e o valor é uma lista de dicionários com meta informações (pode ter várias meta-informações de processamento. Elas serão processadas em ordem).\n",
    "\n",
    "Cada meta-informação é um dicionário deve conter as seguintes informações:\n",
    "\n",
    "* **view**: nome da pasta com a view\n",
    "* **output**: nome da pasta de saída (será criada)\n",
    "* **train**: nome do arquivo csv de treino\n",
    "* **validation**: nome do arquivo csv de validação (None, se não houver)\n",
    "* **test**: nome do arquivo csv de teste (None, se não houver)\n",
    "* **activity code**: Dicionário com o mapeamento entre os nomes das atividades originais e seus respectivos códigos\n",
    "* **select activities**: Lista com quais serão as atividades selecionadas (em relação ao activity code)\n",
    "* **standard activity code map**: mapeamento do código das atividades originais (chave) para o código de atividade padronizado (valor) \n",
    "* **brief**: resumo para o README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eb9ff9-f9e7-4344-a5d2-b07d5de097c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "views = {\n",
    "    # Views a serem preprocessadas\n",
    "    \"KuHar\": [\n",
    "        {\n",
    "            \"view\": \"balanced_motionsense_equivalent_resampled_view_20Hz\",\n",
    "            \"output\": \"balanced_20Hz_motionsense_equivalent-v1\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": \"validation.csv\",\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                0: \"stair down\",\n",
    "                1: \"stair up\",\n",
    "                2: \"sit\",\n",
    "                3: \"stand\",\n",
    "                4: \"walk\",\n",
    "                5: \"run\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 4,\n",
    "                1: 3,\n",
    "                2: 0,\n",
    "                3: 1,\n",
    "                4: 2,\n",
    "                5: 5\n",
    "            },\n",
    "            \"brief\": \"\"\"# Balanced KuHar View Resampled to 20Hz\n",
    "\n",
    "This is a view from [KuHar v5](https://data.mendeley.com/datasets/45f952y38r/5) that was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). \n",
    "\n",
    "The data was first splitted in three sets: train, validation and test. Each one with the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "        }\n",
    "        # Podes adicionar outras views do KuHar aqui\n",
    "    ],\n",
    "\n",
    "    \"CHARM\": [\n",
    "        {\n",
    "            \"view\": \"balanced_view_train_test-v1\",\n",
    "            \"output\": \"balanced_20Hz_train_test-v1\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                0: \"sitting on a chair\",\n",
    "                1: \"sitting on a couch\",\n",
    "                2: \"standing\",\n",
    "                3: \"lying up\",\n",
    "                4: \"lying by side\",\n",
    "                5: \"device on surface\",\n",
    "                6: \"walking\",\n",
    "                7: \"running\",\n",
    "                8: \"walking upstairs\",\n",
    "                9: \"walking downstairs\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 6, 7, 8, 9\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 0,\n",
    "                1: 0,\n",
    "                2: 1,\n",
    "                6: 2,\n",
    "                7: 5,\n",
    "                8: 3,\n",
    "                9: 4\n",
    "            },\n",
    "            \"brief\": \"\"\"# Balanced CHARM View\n",
    "\n",
    "This is a view from [CHARM dataset](https://zenodo.org/record/4642560) that was spllited into 3s windows. The sample rate was 20Hz.\n",
    "\n",
    "The data was first splitted in two sets: train and test. Each one with the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Test: 30% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "        }\n",
    "        # Podes adicionar outras views do CHARM aqui\n",
    "    ],\n",
    "\n",
    "    \"ExtraSensory\": [\n",
    "        {\n",
    "            \"view\": \"unbalanced_train_only_resampled_20hz\",\n",
    "            \"output\": \"unbalanced_20Hz_train-v1\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": None,\n",
    "            \"activity code\": {\n",
    "                0: \"sitting\",\n",
    "                1: \"or_standing\",\n",
    "                2: \"fix_walking\",\n",
    "                3: \"fix_running\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 3\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 1,\n",
    "                1: 1,\n",
    "                2: 2,\n",
    "                3: 5\n",
    "            },\n",
    "            \"brief\": \"\"\"# Unbalanced ExtraSensory View Resampled to 20Hz\n",
    "\n",
    "This is a view from [ExtraSensory dataset](http://extrasensory.ucsd.edu/) that was spllited into 3s windows. The view contain only the train file resampled to 20Hz, interpolated using the cubic spline method due to non stable sampling. The gravity was already subtracted. \n",
    "\n",
    "\"\"\"\n",
    "        }\n",
    "        # Podes adicionar outras views do ExtraSensory aqui\n",
    "    ],\n",
    "\n",
    "    \"MotionSense\": [\n",
    "        {\n",
    "            \"view\": \"resampled_view_20Hz\",\n",
    "            \"output\": \"balanced_20Hz-v1\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": \"validation.csv\",\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                0: \"downstairs\",\n",
    "                1: \"upstairs\",\n",
    "                2: \"sitting\",\n",
    "                3: \"standing\",\n",
    "                4: \"walking\",\n",
    "                5: \"jogging\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 4,\n",
    "                1: 3,\n",
    "                2: 0,\n",
    "                3: 1,\n",
    "                4: 2,\n",
    "                5: 5\n",
    "            },\n",
    "            \"brief\": \"\"\"# Balanced MotionSense View Resampled to 20Hz\n",
    "\n",
    "This is a view from [KuHar v5](https://data.mendeley.com/datasets/45f952y38r/5) that was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). \n",
    "\n",
    "The data was first splitted in three sets: train, validation and test. Each one with the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "        },\n",
    "        # Podes adicionar outras views do MotionSense aqui\n",
    "    ],\n",
    "\n",
    "    \"UCI-HAR\": [\n",
    "        {\n",
    "            \"view\": \"unbalanced_view_train_test-resampled_20hz-v1\",\n",
    "            \"output\": \"unbalanced_20Hz_train_test-v1\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                1: \"walking\",\n",
    "                2: \"walking upstairs\",\n",
    "                3: \"walking downstairs\",\n",
    "                4: \"sitting\",\n",
    "                5: \"standing\",\n",
    "                6: \"laying\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                1: 2,\n",
    "                2: 3,\n",
    "                3: 4,\n",
    "                4: 0,\n",
    "                5: 1\n",
    "            },\n",
    "            \"brief\": \"\"\"# Unbalanced UCI-HAR View Resampled to 20Hz\n",
    "\n",
    "This view contain only the train and test files for [UCI-HAR dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones#) (70% samples train and 30% test). The data was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample).\n",
    "\n",
    "\"\"\"\n",
    "            \n",
    "        }\n",
    "        # Podes adicionar outras views do UCI-HAR aqui\n",
    "    ],\n",
    "\n",
    "    \"WISDM\": [\n",
    "        {\n",
    "            \"view\": \"interpolated_unbalanced_view_train_test-v1\",\n",
    "            \"output\": \"unbalanced_20Hz_train_test-v1\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                0: \"walking\",\n",
    "                1: \"jogging\",\n",
    "                2: \"stairs\",\n",
    "                3: \"sitting\",\n",
    "                4: \"standing\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 3, 4\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 2,\n",
    "                1: 5,\n",
    "                2: 6,\n",
    "                3: 0,\n",
    "                4: 1\n",
    "            },\n",
    "            \"brief\": \"\"\"# Unbalanced WISDM View Resampled to 20Hz\n",
    "\n",
    "This view contain only the train and test files for [WISDM dataset](https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset) (70% samples train and 30% test).\n",
    "The dataset was sampled at 20Hz and interpolated using the cubic spline method due to non stable sampling.\n",
    "\n",
    "\"\"\"\n",
    "        }\n",
    "        # Podes adicionar outras views do WISDM aqui\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134abae-b040-4982-87e1-4c8e06d002b7",
   "metadata": {},
   "source": [
    "O código abaixo processa as views (às padroniza) e gera na pasta de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d11b917-3a12-43f8-b312-85c70afc5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed KuHar\n",
      "Processed CHARM\n",
      "Processed ExtraSensory\n",
      "Processed MotionSense\n",
      "Processed UCI-HAR\n",
      "Processed WISDM\n"
     ]
    }
   ],
   "source": [
    "backslash = \"\\n\"\n",
    "\n",
    "for dataset_name, values_list in views.items():\n",
    "    split_counts = {}\n",
    "    root_output_path = output_dir / dataset_name\n",
    "    for values in values_list:\n",
    "        for split in (\"train\", \"validation\", \"test\"):\n",
    "            if values[split] is None:\n",
    "                continue\n",
    "\n",
    "            path = root_views_dir / dataset_name / values[\"view\"] / values[split]\n",
    "            df = pd.read_csv(path)\n",
    "            df = df.loc[df[\"activity code\"].isin(values[\"select activities\"])]\n",
    "            df[\"standard activity code\"] = df[\"activity code\"].replace(values[\"standard activity code map\"])\n",
    "            if \"normalized activity code\" in df.columns:\n",
    "                df = df.drop(columns=\"normalized activity code\")\n",
    "                \n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            df = df.dropna()\n",
    "            \n",
    "            path = root_output_path / values[\"output\"] / f\"{split}.csv\"\n",
    "            path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            df.to_csv(path, index=False)\n",
    "            \n",
    "            md5sum = hashlib.md5(path.open('rb').read()).hexdigest()\n",
    "            path = path.parent / (path.name + '.md5')\n",
    "            with path.open(\"w\") as f:\n",
    "                f.write(md5sum)\n",
    "\n",
    "            split_counts[split] = {\n",
    "                \"standard activity code\": df[\"standard activity code\"].value_counts(),\n",
    "                \"activity code\": df[\"activity code\"].value_counts()\n",
    "            }\n",
    "\n",
    "        readme = values[\"brief\"]\n",
    "        readme = readme + f\"\"\"## Activity codes\n",
    "- {f\"- \".join(f'{k}: {v} ({split_counts[\"train\"][\"activity code\"][k]} train, {split_counts[\"validation\"][\"activity code\"][k] if \"validation\" in split_counts else 0} validation, {split_counts[\"test\"][\"activity code\"][k] if \"test\" in split_counts else 0} test) {backslash}' for k, v in values['activity code'].items() if k in split_counts[\"train\"][\"activity code\"])} \n",
    "\n",
    "## Standartized activity codes\n",
    "- {f\"- \".join(f'{k}: {v} ({split_counts[\"train\"][\"standard activity code\"][k]} train, {split_counts[\"validation\"][\"standard activity code\"][k] if \"validation\" in split_counts else 0} validation, {split_counts[\"test\"][\"standard activity code\"][k] if \"test\" in split_counts else 0} test) {backslash}' for k, v in standartized_codes.items() if k in split_counts[\"train\"][\"standard activity code\"]  )    }      \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        readme_path = root_output_path / values[\"output\"] / \"README.md\"\n",
    "        with readme_path.open(\"w\") as f:\n",
    "            f.write(readme)\n",
    "        print(f\"Processed {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca388d-6264-4c3a-809f-9cc23465007c",
   "metadata": {},
   "source": [
    "Processamento especifico para o MotionSense. Troca o nome das colunas: `userAcceleration` para `accel` e `rotationRate` para `gyro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5d9d60-b45c-498c-90dd-ea831daf9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in Path(\"data/views/MotionSense/balanced_20Hz-v1\").glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    replace_map = {\n",
    "        f\"{c}-{i}\": f\"{new_c}-{i}\"\n",
    "        for c, new_c in [(\"userAcceleration.x\", \"accel-x\"), \n",
    "                         (\"userAcceleration.y\", \"accel-y\"), \n",
    "                         (\"userAcceleration.z\", \"accel-z\"),\n",
    "                         (\"rotationRate.x\", \"gyro-x\"), \n",
    "                         (\"rotationRate.y\", \"gyro-y\"),\n",
    "                         (\"rotationRate.z\", \"gyro-z\")]\n",
    "        for i in range(60)\n",
    "    }\n",
    "    df.rename(columns=replace_map, inplace=True)\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147586c4-ba68-410e-82f0-1d55c5a54c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/views/UCI-HAR/unbalanced_20Hz_train_test-v1/test.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/UCI-HAR/unbalanced_20Hz_train_test-v1/train.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/MotionSense/balanced_20Hz-v1/test.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/MotionSense/balanced_20Hz-v1/validation.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/MotionSense/balanced_20Hz-v1/train.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/KuHar/balanced_20Hz_motionsense_equivalent-v1/test.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/KuHar/balanced_20Hz_motionsense_equivalent-v1/validation.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/KuHar/balanced_20Hz_motionsense_equivalent-v1/train.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/WISDM/unbalanced_20Hz_train_test-v1/test.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/WISDM/unbalanced_20Hz_train_test-v1/train.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/ExtraSensory/unbalanced_20Hz_train-v1/train.csv ['accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8', 'accel-x-9']\n",
      "data/views/CHARM/balanced_20Hz_train_test-v1/test.csv ['index', 'accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8']\n",
      "data/views/CHARM/balanced_20Hz_train_test-v1/train.csv ['index', 'accel-x-0', 'accel-x-1', 'accel-x-2', 'accel-x-3', 'accel-x-4', 'accel-x-5', 'accel-x-6', 'accel-x-7', 'accel-x-8']\n"
     ]
    }
   ],
   "source": [
    "for path in Path(\"data/views/\").rglob(\"*.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    print(path, list(df.columns)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cdef164-4529-46db-9634-134d3fbd3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(standartized_codes.items(), columns=[\"standard code\", \"standard label\"]).to_csv(output_dir / \"standard_codes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
