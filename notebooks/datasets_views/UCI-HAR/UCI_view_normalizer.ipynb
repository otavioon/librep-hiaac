{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916bb3b8-d6b2-4f4a-ad6e-a57b35ce0738",
   "metadata": {},
   "source": [
    "# Padronizador de views de HAR\n",
    "\n",
    "Este notebook auxilia a padronizar as views dos datasets de HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a8fc9c-ebed-44ee-943a-14823e75f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7215239d-b7e1-4d8f-9d52-bb26997360e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_views_dir = Path(\"../../../data_2/raw_data/\")    # Local onde as views de encontram (entrada)\n",
    "output_dir = Path(\"../../../data_2/views\")         # Local onde as views padronizadas serão colocadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b579c7eb-eb71-4928-9e10-af61d7de5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de atividades padronizado\n",
    "standartized_codes = {\n",
    "    0: \"sit\",\n",
    "    1: \"stand\",\n",
    "    2: \"walk\",\n",
    "    3: \"stair up\",\n",
    "    4: \"stair down\",\n",
    "    5: \"run\",\n",
    "    6: \"stair up and down\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77779a5-e5e9-4c4a-b87f-b59e12676e0e",
   "metadata": {},
   "source": [
    "## Descrição das views a serem processadas\n",
    "\n",
    "A variavel `views` é um dicionário, onde cada chave é o nome do dataset (nome da pasta do dataset raíz, onde possui as views dentro) e o valor é uma lista de dicionários com meta informações (pode ter várias meta-informações de processamento. Elas serão processadas em ordem).\n",
    "\n",
    "Cada meta-informação é um dicionário deve conter as seguintes informações:\n",
    "\n",
    "* **view**: nome da pasta com a view\n",
    "* **output**: nome da pasta de saída (será criada)\n",
    "* **train**: nome do arquivo csv de treino\n",
    "* **validation**: nome do arquivo csv de validação (None, se não houver)\n",
    "* **test**: nome do arquivo csv de teste (None, se não houver)\n",
    "* **activity code**: Dicionário com o mapeamento entre os nomes das atividades originais e seus respectivos códigos\n",
    "* **select activities**: Lista com quais serão as atividades selecionadas (em relação ao activity code)\n",
    "* **standard activity code map**: mapeamento do código das atividades originais (chave) para o código de atividade padronizado (valor) \n",
    "* **brief**: resumo para o README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eb9ff9-f9e7-4344-a5d2-b07d5de097c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "views ={\n",
    "        \"UCI-HAR\": [\n",
    "        {\n",
    "            \"view\": \"unbalanced_view_filtered_acc_9.81_train_test-v1\",\n",
    "            \"output\": \"unbalanced_20Hz_train_test_9.81_acc_filtered\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                1: \"walking\",\n",
    "                2: \"walking upstairs\",\n",
    "                3: \"walking downstairs\",\n",
    "                4: \"sitting\",\n",
    "                5: \"standing\",\n",
    "                6: \"laying\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                1: 2,\n",
    "                2: 3,\n",
    "                3: 4,\n",
    "                4: 0,\n",
    "                5: 1\n",
    "            },\n",
    "            \"brief\": \"\"\"# Unbalanced UCI-HAR View Resampled to 20Hz without gravity. \n",
    "            \n",
    "The data used was the samples with gravity by autors.\n",
    "\n",
    "The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used and the signal filtered was subtracted from the original signal.\n",
    "\n",
    "This view contain only the train and test files for [UCI-HAR dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones#) (70% samples train and 30% test). The data was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). The accelerometer meansure is in m/s² and without gravity.\n",
    "\n",
    "\"\"\"\n",
    "        },\n",
    "        # Podes adicionar outras views do UCI-HAR aqui\n",
    "        {\n",
    "            \"view\": \"unbalanced_view_gravity_acc_9.81_train_test-v1\",\n",
    "            \"output\": \"unbalanced_20Hz_train_test_with_gravity_9.81_acc\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                1: \"walking\",\n",
    "                2: \"walking upstairs\",\n",
    "                3: \"walking downstairs\",\n",
    "                4: \"sitting\",\n",
    "                5: \"standing\",\n",
    "                6: \"laying\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                1: 2,\n",
    "                2: 3,\n",
    "                3: 4,\n",
    "                4: 0,\n",
    "                5: 1\n",
    "            },\n",
    "            \"brief\": \"\"\"# Unbalanced UCI-HAR View Resampled to 20Hz without gravity\n",
    "\n",
    "The data used was the samples with gravity by autors.\n",
    "\n",
    "This view contain only the train and test files for [UCI-HAR dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones#) (70% samples train and 30% test). The data was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). The accelerometer meansure is in m/s² and with gravity.\n",
    "\n",
    "\"\"\"\n",
    "           \n",
    "        },\n",
    "            \n",
    "        {\n",
    "            \"view\": \"unbalanced_view_without_gravity_acc_9.81_train_test-v1\",\n",
    "            \"output\": \"unbalanced_20Hz_train_test_9.81_acc\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": None,\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                1: \"walking\",\n",
    "                2: \"walking upstairs\",\n",
    "                3: \"walking downstairs\",\n",
    "                4: \"sitting\",\n",
    "                5: \"standing\",\n",
    "                6: \"laying\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                1: 2,\n",
    "                2: 3,\n",
    "                3: 4,\n",
    "                4: 0,\n",
    "                5: 1\n",
    "            },\n",
    "            \"brief\": \"\"\"# Unbalanced UCI-HAR View Resampled to 20Hz with gravity\n",
    "\n",
    "The data used was the samples without gravity by autors.\n",
    "\n",
    "This view contain only the train and test files for [UCI-HAR dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones#) (70% samples train and 30% test). The data was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). The accelerometer meansure is in m/s² and with gravity.\n",
    "\n",
    "\"\"\"\n",
    "           \n",
    "        }\n",
    "    ] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134abae-b040-4982-87e1-4c8e06d002b7",
   "metadata": {},
   "source": [
    "O código abaixo processa as views (às padroniza) e gera na pasta de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d11b917-3a12-43f8-b312-85c70afc5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed UCI-HAR\n",
      "Processed UCI-HAR\n",
      "Processed UCI-HAR\n"
     ]
    }
   ],
   "source": [
    "backslash = \"\\n\"\n",
    "\n",
    "for dataset_name, values_list in views.items():\n",
    "    split_counts = {}\n",
    "    root_output_path = output_dir / dataset_name\n",
    "    for values in values_list:\n",
    "        for split in (\"train\", \"validation\", \"test\"):\n",
    "            if values[split] is None:\n",
    "                continue\n",
    "\n",
    "            path = root_views_dir / dataset_name / values[\"view\"] / values[split]\n",
    "            df = pd.read_csv(path)\n",
    "            df = df.loc[df[\"activity code\"].isin(values[\"select activities\"])]\n",
    "            df[\"standard activity code\"] = df[\"activity code\"].replace(values[\"standard activity code map\"])\n",
    "            if \"normalized activity code\" in df.columns:\n",
    "                df = df.drop(columns=\"normalized activity code\")\n",
    "                \n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            df = df.dropna()\n",
    "            \n",
    "            path = root_output_path / values[\"output\"] / f\"{split}.csv\"\n",
    "            path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            df.to_csv(path, index=False)\n",
    "            \n",
    "            md5sum = hashlib.md5(path.open('rb').read()).hexdigest()\n",
    "            path = path.parent / (path.name + '.md5')\n",
    "            with path.open(\"w\") as f:\n",
    "                f.write(md5sum)\n",
    "\n",
    "            split_counts[split] = {\n",
    "                \"standard activity code\": df[\"standard activity code\"].value_counts(),\n",
    "                \"activity code\": df[\"activity code\"].value_counts()\n",
    "            }\n",
    "\n",
    "        readme = values[\"brief\"]\n",
    "        readme = readme + f\"\"\"## Activity codes\n",
    "- {f\"- \".join(f'{k}: {v} ({split_counts[\"train\"][\"activity code\"][k]} train, {split_counts[\"validation\"][\"activity code\"][k] if \"validation\" in split_counts else 0} validation, {split_counts[\"test\"][\"activity code\"][k] if \"test\" in split_counts else 0} test) {backslash}' for k, v in values['activity code'].items() if k in split_counts[\"train\"][\"activity code\"])} \n",
    "\n",
    "## Standartized activity codes\n",
    "- {f\"- \".join(f'{k}: {v} ({split_counts[\"train\"][\"standard activity code\"][k]} train, {split_counts[\"validation\"][\"standard activity code\"][k] if \"validation\" in split_counts else 0} validation, {split_counts[\"test\"][\"standard activity code\"][k] if \"test\" in split_counts else 0} test) {backslash}' for k, v in standartized_codes.items() if k in split_counts[\"train\"][\"standard activity code\"]  )    }      \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        readme_path = root_output_path / values[\"output\"] / \"README.md\"\n",
    "        with readme_path.open(\"w\") as f:\n",
    "            f.write(readme)\n",
    "        print(f\"Processed {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147586c4-ba68-410e-82f0-1d55c5a54c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in Path(\"../../../data_2/views/UCI-HAR\").rglob(\"*.csv\"):\n",
    "#     df = pd.read_csv(path)\n",
    "#     print(path, list(df.columns)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdef164-4529-46db-9634-134d3fbd3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(standartized_codes.items(), columns=[\"standard code\", \"standard label\"]).to_csv(output_dir / \"standard_codes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507843b-b41d-42ae-ae26-645cd65e130e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
