{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916bb3b8-d6b2-4f4a-ad6e-a57b35ce0738",
   "metadata": {},
   "source": [
    "# Padronizador de views de HAR\n",
    "\n",
    "Este notebook auxilia a padronizar as views dos datasets de HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a8fc9c-ebed-44ee-943a-14823e75f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7215239d-b7e1-4d8f-9d52-bb26997360e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_views_dir = Path(\"../../../data_2/views/\")    # Local onde as views de encontram (entrada)\n",
    "output_dir = Path(\"../../../data_2/views\")             # Local onde as views padronizadas serão colocadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b579c7eb-eb71-4928-9e10-af61d7de5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de atividades padronizado\n",
    "standartized_codes = {\n",
    "    0: \"sit\",\n",
    "    1: \"stand\",\n",
    "    2: \"walk\",\n",
    "    3: \"stair up\",\n",
    "    4: \"stair down\",\n",
    "    5: \"run\",\n",
    "    6: \"stair up and down\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77779a5-e5e9-4c4a-b87f-b59e12676e0e",
   "metadata": {},
   "source": [
    "## Descrição das views a serem processadas\n",
    "\n",
    "A variavel `views` é um dicionário, onde cada chave é o nome do dataset (nome da pasta do dataset raíz, onde possui as views dentro) e o valor é uma lista de dicionários com meta informações (pode ter várias meta-informações de processamento. Elas serão processadas em ordem).\n",
    "\n",
    "Cada meta-informação é um dicionário deve conter as seguintes informações:\n",
    "\n",
    "* **view**: nome da pasta com a view\n",
    "* **output**: nome da pasta de saída (será criada)\n",
    "* **train**: nome do arquivo csv de treino\n",
    "* **validation**: nome do arquivo csv de validação (None, se não houver)\n",
    "* **test**: nome do arquivo csv de teste (None, se não houver)\n",
    "* **activity code**: Dicionário com o mapeamento entre os nomes das atividades originais e seus respectivos códigos\n",
    "* **select activities**: Lista com quais serão as atividades selecionadas (em relação ao activity code)\n",
    "* **standard activity code map**: mapeamento do código das atividades originais (chave) para o código de atividade padronizado (valor) \n",
    "* **brief**: resumo para o README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eb9ff9-f9e7-4344-a5d2-b07d5de097c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "views = {\n",
    "\n",
    "    \"MotionSense\": [\n",
    "        {\n",
    "            \"view\": \"resampled_view_20Hz_9.81_acc\",\n",
    "            \"output\": \"balanced_20Hz_9.81_acc\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": \"validation.csv\",\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                0: \"downstairs\",\n",
    "                1: \"upstairs\",\n",
    "                2: \"sitting\",\n",
    "                3: \"standing\",\n",
    "                4: \"walking\",\n",
    "                5: \"jogging\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 4,\n",
    "                1: 3,\n",
    "                2: 0,\n",
    "                3: 1,\n",
    "                4: 2,\n",
    "                5: 5\n",
    "            },\n",
    "            \"brief\": \"\"\"# Balanced MotionSense View Resampled to 20Hz - Multiplied acc by 9.81m/s²\n",
    "\n",
    "This is a view from [MotionSense] that was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). \n",
    "\n",
    "The data was first splitted in three sets: train, validation and test. Each one with the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "        },\n",
    "        \n",
    "        # Podes adicionar outras views do MotionSense aqui        \n",
    "\n",
    "        {\n",
    "            \"view\": \"resampled_view_20Hz_with_gravity_9.81_acc\",\n",
    "            \"output\": \"balanced_20Hz_with_gravity_9.81_acc\",\n",
    "            \"train\": \"train.csv\",\n",
    "            \"validation\": \"validation.csv\",\n",
    "            \"test\": \"test.csv\",\n",
    "            \"activity code\": {\n",
    "                0: \"downstairs\",\n",
    "                1: \"upstairs\",\n",
    "                2: \"sitting\",\n",
    "                3: \"standing\",\n",
    "                4: \"walking\",\n",
    "                5: \"jogging\"\n",
    "            },\n",
    "            \"select activities\": [\n",
    "                0, 1, 2, 3, 4, 5\n",
    "            ],\n",
    "            \"standard activity code map\": {\n",
    "                0: 4,\n",
    "                1: 3,\n",
    "                2: 0,\n",
    "                3: 1,\n",
    "                4: 2,\n",
    "                5: 5\n",
    "            },\n",
    "            \"brief\": \"\"\"# Balanced MotionSense View Resampled to 20Hz with Gravity - Multiplied acc by 9.81m/s²\n",
    "\n",
    "This is a view from [MotionSense] that was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample). \n",
    "\n",
    "The data was first splitted in three sets: train, validation and test. Each one with the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "        },     \n",
    "        \n",
    "    ],\n",
    "\n",
    "#     \"UCI-HAR\": [\n",
    "#         {\n",
    "#             \"view\": \"unbalanced_view_train_test-resampled_20hz-v1\",\n",
    "#             \"output\": \"unbalanced_20Hz_train_test-v1\",\n",
    "#             \"train\": \"train.csv\",\n",
    "#             \"validation\": None,\n",
    "#             \"test\": \"test.csv\",\n",
    "#             \"activity code\": {\n",
    "#                 1: \"walking\",\n",
    "#                 2: \"walking upstairs\",\n",
    "#                 3: \"walking downstairs\",\n",
    "#                 4: \"sitting\",\n",
    "#                 5: \"standing\",\n",
    "#                 6: \"laying\"\n",
    "#             },\n",
    "#             \"select activities\": [\n",
    "#                 1, 2, 3, 4, 5\n",
    "#             ],\n",
    "#             \"standard activity code map\": {\n",
    "#                 1: 2,\n",
    "#                 2: 3,\n",
    "#                 3: 4,\n",
    "#                 4: 0,\n",
    "#                 5: 1\n",
    "#             },\n",
    "#             \"brief\": \"\"\"# Unbalanced UCI-HAR View Resampled to 20Hz\n",
    "\n",
    "# This view contain only the train and test files for [UCI-HAR dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones#) (70% samples train and 30% test). The data was spllited into 3s windows and was resampled to 20Hz using the [FFT method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html#scipy.signal.resample).\n",
    "\n",
    "# \"\"\"\n",
    "            \n",
    "#         }\n",
    "#         # Podes adicionar outras views do UCI-HAR aqui\n",
    "#     ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134abae-b040-4982-87e1-4c8e06d002b7",
   "metadata": {},
   "source": [
    "O código abaixo processa as views (às padroniza) e gera na pasta de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d11b917-3a12-43f8-b312-85c70afc5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed MotionSense\n",
      "Processed MotionSense\n"
     ]
    }
   ],
   "source": [
    "backslash = \"\\n\"\n",
    "\n",
    "for dataset_name, values_list in views.items():\n",
    "    split_counts = {}\n",
    "    root_output_path = output_dir / dataset_name\n",
    "    for values in values_list:\n",
    "        for split in (\"train\", \"validation\", \"test\"):\n",
    "            if values[split] is None:\n",
    "                continue\n",
    "\n",
    "            path = root_views_dir / dataset_name / values[\"view\"] / values[split]\n",
    "            df = pd.read_csv(path)\n",
    "            df = df.loc[df[\"activity code\"].isin(values[\"select activities\"])]\n",
    "            df[\"standard activity code\"] = df[\"activity code\"].replace(values[\"standard activity code map\"])\n",
    "            if \"normalized activity code\" in df.columns:\n",
    "                df = df.drop(columns=\"normalized activity code\")\n",
    "                \n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "            df = df.dropna()\n",
    "            \n",
    "            path = root_output_path / values[\"output\"] / f\"{split}.csv\"\n",
    "            path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            df.to_csv(path, index=False)\n",
    "            \n",
    "            md5sum = hashlib.md5(path.open('rb').read()).hexdigest()\n",
    "            path = path.parent / (path.name + '.md5')\n",
    "            with path.open(\"w\") as f:\n",
    "                f.write(md5sum)\n",
    "\n",
    "            split_counts[split] = {\n",
    "                \"standard activity code\": df[\"standard activity code\"].value_counts(),\n",
    "                \"activity code\": df[\"activity code\"].value_counts()\n",
    "            }\n",
    "\n",
    "        readme = values[\"brief\"]\n",
    "        readme = readme + f\"\"\"## Activity codes\n",
    "- {f\"- \".join(f'{k}: {v} ({split_counts[\"train\"][\"activity code\"][k]} train, {split_counts[\"validation\"][\"activity code\"][k] if \"validation\" in split_counts else 0} validation, {split_counts[\"test\"][\"activity code\"][k] if \"test\" in split_counts else 0} test) {backslash}' for k, v in values['activity code'].items() if k in split_counts[\"train\"][\"activity code\"])} \n",
    "\n",
    "## Standartized activity codes\n",
    "- {f\"- \".join(f'{k}: {v} ({split_counts[\"train\"][\"standard activity code\"][k]} train, {split_counts[\"validation\"][\"standard activity code\"][k] if \"validation\" in split_counts else 0} validation, {split_counts[\"test\"][\"standard activity code\"][k] if \"test\" in split_counts else 0} test) {backslash}' for k, v in standartized_codes.items() if k in split_counts[\"train\"][\"standard activity code\"]  )    }      \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        readme_path = root_output_path / values[\"output\"] / \"README.md\"\n",
    "        with readme_path.open(\"w\") as f:\n",
    "            f.write(readme)\n",
    "        print(f\"Processed {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca388d-6264-4c3a-809f-9cc23465007c",
   "metadata": {},
   "source": [
    "Processamento especifico para o MotionSense. Troca o nome das colunas: `userAcceleration` para `accel` e `rotationRate` para `gyro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5d9d60-b45c-498c-90dd-ea831daf9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in Path(\"../../../data_2/views/MotionSense/balanced_20Hz_9.81_acc\").glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    replace_map = {\n",
    "        f\"{c}-{i}\": f\"{new_c}-{i}\"\n",
    "        for c, new_c in [(\"userAcceleration.x\", \"accel-x\"), \n",
    "                         (\"userAcceleration.y\", \"accel-y\"), \n",
    "                         (\"userAcceleration.z\", \"accel-z\"),\n",
    "                         (\"rotationRate.x\", \"gyro-x\"), \n",
    "                         (\"rotationRate.y\", \"gyro-y\"),\n",
    "                         (\"rotationRate.z\", \"gyro-z\")]\n",
    "        for i in range(60)\n",
    "    }\n",
    "    df.rename(columns=replace_map, inplace=True)\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f2e6e1-d488-427d-aa8f-4b5c6872a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in Path(\"../../../data_2/views/MotionSense/balanced_20Hz_with_gravity_9.81_acc\").glob(\"*.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    replace_map = {\n",
    "        f\"{c}-{i}\": f\"{new_c}-{i}\"\n",
    "        for c, new_c in [(\"userAcceleration.x\", \"accel-x\"), \n",
    "                         (\"userAcceleration.y\", \"accel-y\"), \n",
    "                         (\"userAcceleration.z\", \"accel-z\"),\n",
    "                         (\"rotationRate.x\", \"gyro-x\"), \n",
    "                         (\"rotationRate.y\", \"gyro-y\"),\n",
    "                         (\"rotationRate.z\", \"gyro-z\")]\n",
    "        for i in range(60)\n",
    "    }\n",
    "    df.rename(columns=replace_map, inplace=True)\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147586c4-ba68-410e-82f0-1d55c5a54c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in Path(\"data/views/\").rglob(\"*.csv\"):\n",
    "#     df = pd.read_csv(path)\n",
    "#     print(path, list(df.columns)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cdef164-4529-46db-9634-134d3fbd3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(standartized_codes.items(), columns=[\"standard code\", \"standard label\"]).to_csv(output_dir / \"standard_codes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507843b-b41d-42ae-ae26-645cd65e130e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
