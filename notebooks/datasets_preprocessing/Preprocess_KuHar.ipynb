{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0c0e3e-a130-465c-8aec-671bdd27bf3f",
   "metadata": {},
   "source": [
    "# Pre-processing KuHar Dataset and Generate Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498254b0-ea10-4f02-b718-d26ce855b77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad53baa-1190-4969-9ae9-489321c5966e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from librep.datasets.har.kuhar import (\n",
    "    RawKuHar,\n",
    "    RawKuHarIterator,\n",
    "    KuHarDatasetGenerator\n",
    ")\n",
    "\n",
    "from librep.utils.dataset import PandasDatasetsIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bf855c-9947-4174-980c-5942527eaf04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KuHar Dataset at: '../../data/datasets/KuHar/1.Raw_time_domain_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = Path(\"../../data/datasets/KuHar/1.Raw_time_domain_data\")\n",
    "kuhar_dataset = RawKuHar(dataset_dir, download=False)\n",
    "kuhar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366c2abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stand',\n",
       " 'Sit',\n",
       " 'Talk-sit',\n",
       " 'Talk-stand',\n",
       " 'Stand-sit',\n",
       " 'Lay',\n",
       " 'Lay-stand',\n",
       " 'Pick',\n",
       " 'Jump',\n",
       " 'Push-up',\n",
       " 'Sit-up',\n",
       " 'Walk',\n",
       " 'Walk-backwards',\n",
       " 'Walk-circle',\n",
       " 'Run',\n",
       " 'Stair-up',\n",
       " 'Stair-down',\n",
       " 'Table-tennis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_names = [kuhar_dataset.activity_names[i] for i in range(18)]\n",
    "act_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a73f33-547b-444e-b513-e80f50f2eb5d",
   "metadata": {},
   "source": [
    "## Creating a KuHar Balanced View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ffda3f-7686-49d1-a02d-576e4207b6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kuhar Iterator: users=89, activities=18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = RawKuHarIterator(kuhar_dataset)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75a8cb6-5083-44f9-bfbd-50f55836bb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset generator: time_window=300, overlap=0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=300, window_overlap=0)\n",
    "kuhar_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add044d7-6666-4f31-93e5-d4af57e01e56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 1945it [01:39, 19.54it/s]\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=True,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0dcb11-f07e-4e60-a859-ea209900beb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce08f8a1038ab48c890211a6d03233ea1c936c3d\n",
      "8abd24b492d8cb93bae3055d57720ed7726c562b\n",
      "7bffb5001651ab21c44b38cba2ed57703c0d3c41\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e8443-4f7b-4925-afc8-63f7d32b69fb",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc048fa4-d6a9-46f0-9698-ba21d04c7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {\n",
    "    1: 0,\n",
    "    0: 1,\n",
    "    11: 2,\n",
    "    15: 3,\n",
    "    16: 4,\n",
    "    14: 5,\n",
    "    2: 6,\n",
    "    3: 7,\n",
    "    4: 8,\n",
    "    5: 9,\n",
    "    6: 10,\n",
    "    7: 11,\n",
    "    8: 12,\n",
    "    9: 13,\n",
    "    10: 14,\n",
    "    12: 15,\n",
    "    13: 16,\n",
    "    17: 17\n",
    "}\n",
    "\n",
    "def apply(row, labels):\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(labels,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train, new_labels)\n",
    "validation = apply(validation, new_labels)\n",
    "test = apply(test, new_labels)\n",
    "normalized_activity_names = {new_key: kuhar_dataset.activity_names[old_key] for old_key,new_key in new_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff24e8b-056a-415c-8511-823d7fc4597f",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a9cda8-f111-4715-94c2-e474574149ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Balanced KuHar View\n",
      "\n",
      "This view contains train, validation and test subsets in the following proportions:\n",
      "- Train: 70% of samples\n",
      "- Validation: 10% of samples\n",
      "- Test: 20% of samples\n",
      "\n",
      "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
      "\n",
      "## Activities:\n",
      "- 0: Sit (185 train, 6 validation, 21 test)\n",
      "- 1: Stand (185 train, 6 validation, 21 test)\n",
      "- 2: Walk (185 train, 6 validation, 21 test)\n",
      "- 3: Stair-up (185 train, 6 validation, 21 test)\n",
      "- 4: Stair-down (185 train, 6 validation, 21 test)\n",
      "- 5: Run (185 train, 6 validation, 21 test)\n",
      "- 6: Talk-sit (185 train, 6 validation, 21 test)\n",
      "- 7: Talk-stand (185 train, 6 validation, 21 test)\n",
      "- 8: Stand-sit (185 train, 6 validation, 21 test)\n",
      "- 9: Lay (185 train, 6 validation, 21 test)\n",
      "- 10: Lay-stand (185 train, 6 validation, 21 test)\n",
      "- 11: Pick (185 train, 6 validation, 21 test)\n",
      "- 12: Jump (185 train, 6 validation, 21 test)\n",
      "- 13: Push-up (185 train, 6 validation, 21 test)\n",
      "- 14: Sit-up (185 train, 6 validation, 21 test)\n",
      "- 15: Walk-backwards (185 train, 6 validation, 21 test)\n",
      "- 16: Walk-circle (185 train, 6 validation, 21 test)\n",
      "- 17: Table-tennis (185 train, 6 validation, 21 test)\n",
      "\n",
      "## Users\n",
      "- 62 users train dataset: 1003 (29 samples), 1004 (58 samples), 1005 (25 samples), 1008 (71 samples), 1011 (24 samples), 1013 (54 samples), 1014 (120 samples), 1015 (56 samples), 1016 (39 samples), 1017 (24 samples), 1018 (35 samples), 1020 (32 samples), 1021 (39 samples), 1022 (102 samples), 1023 (63 samples), 1024 (117 samples), 1025 (39 samples), 1026 (89 samples), 1027 (64 samples), 1029 (39 samples), 1031 (42 samples), 1032 (21 samples), 1033 (18 samples), 1034 (138 samples), 1035 (7 samples), 1037 (67 samples), 1038 (48 samples), 1039 (103 samples), 1040 (92 samples), 1041 (96 samples), 1042 (85 samples), 1043 (87 samples), 1046 (82 samples), 1047 (37 samples), 1048 (38 samples), 1049 (36 samples), 1051 (28 samples), 1053 (29 samples), 1054 (8 samples), 1055 (36 samples), 1058 (29 samples), 1060 (31 samples), 1061 (33 samples), 1063 (27 samples), 1064 (19 samples), 1067 (16 samples), 1068 (32 samples), 1069 (25 samples), 1070 (33 samples), 1073 (15 samples), 1074 (14 samples), 1075 (17 samples), 1076 (31 samples), 1078 (20 samples), 1079 (26 samples), 1081 (51 samples), 1083 (30 samples), 1084 (29 samples), 1085 (29 samples), 1087 (32 samples), 1090 (42 samples), 1101 (532 samples).\n",
      "- 9 users validation dataset: 1002 (58 samples), 1006 (5 samples), 1019 (6 samples), 1062 (6 samples), 1065 (3 samples), 1071 (13 samples), 1072 (1 samples), 1082 (10 samples), 1086 (6 samples).\n",
      "- 18 users test dataset: 1001 (12 samples), 1007 (19 samples), 1009 (8 samples), 1010 (6 samples), 1028 (10 samples), 1030 (29 samples), 1036 (45 samples), 1044 (66 samples), 1045 (58 samples), 1050 (10 samples), 1052 (14 samples), 1056 (22 samples), 1057 (10 samples), 1066 (15 samples), 1077 (23 samples), 1080 (10 samples), 1088 (10 samples), 1089 (11 samples).\n",
      "\n",
      "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/balanced_view\")\n",
    "\n",
    "train_act_samples = train[\"normalized activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"normalized activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"normalized activity code\"].value_counts().to_dict()\n",
    "activities = [f\"- {name}: {code} ({train_act_samples[name]} train, {validation_act_samples[name]} validation, {test_act_samples[name]} test)\" for name, code in normalized_activity_names.items()]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "train_users = ', '.join(train_users)\n",
    "validation_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "validation_users = ', '.join(validation_users)\n",
    "test_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(test[\"user\"].value_counts().items(), key=lambda x: x[0])]\n",
    "test_users = ', '.join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Balanced KuHar View\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "## Activities:\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f4a9c1b-beca-4c22-a84a-319fc341e709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fd8d5-7db8-4e59-ad87-fe3b9aef7ce1",
   "metadata": {},
   "source": [
    "## Creating a Non-Balanced KuHar Balanced View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb1a94c-594b-4703-86ee-ec3d73611216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 1945it [01:36, 20.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=False,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6954d3b8-2aed-49d0-b79a-5882b3688f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31751c896807dc969d23b5b663b0081591977cac\n",
      "3891f7989d3769fa0577834a4e51034bade10aaa\n",
      "d1e70e186d0721a8ea1154733184b507222e9926\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9479f-3e4c-4233-b7a3-c84479cb4917",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0c0278-eadb-4a4e-8cff-d691cc6cded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {\n",
    "    1: 0,\n",
    "    0: 1,\n",
    "    11: 2,\n",
    "    15: 3,\n",
    "    16: 4,\n",
    "    14: 5,\n",
    "    2: 6,\n",
    "    3: 7,\n",
    "    4: 8,\n",
    "    5: 9,\n",
    "    6: 10,\n",
    "    7: 11,\n",
    "    8: 12,\n",
    "    9: 13,\n",
    "    10: 14,\n",
    "    12: 15,\n",
    "    13: 16,\n",
    "    17: 17\n",
    "}\n",
    "\n",
    "def apply(row, labels):\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(labels,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train, new_labels)\n",
    "validation = apply(validation, new_labels)\n",
    "test = apply(test, new_labels)\n",
    "normalized_activity_names = {new_key: kuhar_dataset.activity_names[old_key] for old_key,new_key in new_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4add39d-9281-49e9-874e-e65f45a80e76",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17174f0d-d729-47cc-9f74-e6bd1abc65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-Balanced KuHar View\n",
      "\n",
      "This view contains train, validation and test subsets in the following proportions:\n",
      "- Train: 70% of samples\n",
      "- Validation: 10% of samples\n",
      "- Test: 20% of samples\n",
      "\n",
      "## Activities:\n",
      "- 0: Sit (1328 train, 160 validation, 324 test)\n",
      "- 1: Stand (1373 train, 183 validation, 274 test)\n",
      "- 2: Walk (627 train, 27 validation, 137 test)\n",
      "- 3: Stair-up (750 train, 18 validation, 46 test)\n",
      "- 4: Stair-down (730 train, 18 validation, 45 test)\n",
      "- 5: Run (488 train, 16 validation, 56 test)\n",
      "- 6: Talk-sit (1321 train, 128 validation, 301 test)\n",
      "- 7: Talk-stand (1344 train, 166 validation, 310 test)\n",
      "- 8: Stand-sit (1550 train, 141 validation, 337 test)\n",
      "- 9: Lay (1287 train, 190 validation, 305 test)\n",
      "- 10: Lay-stand (1277 train, 168 validation, 242 test)\n",
      "- 11: Pick (992 train, 131 validation, 158 test)\n",
      "- 12: Jump (537 train, 56 validation, 63 test)\n",
      "- 13: Push-up (219 train, 229 validation, 21 test)\n",
      "- 14: Sit-up (823 train, 123 validation, 47 test)\n",
      "- 15: Walk-backwards (217 train, 8 validation, 65 test)\n",
      "- 16: Walk-circle (185 train, 6 validation, 50 test)\n",
      "- 17: Table-tennis (256 train, 102 validation, 82 test)\n",
      "\n",
      "## Users\n",
      "- 62 users train dataset: 1003 (199 samples), 1004 (270 samples), 1005 (200 samples), 1008 (393 samples), 1011 (165 samples), 1013 (351 samples), 1014 (567 samples), 1015 (388 samples), 1016 (195 samples), 1017 (189 samples), 1018 (207 samples), 1020 (180 samples), 1021 (219 samples), 1022 (574 samples), 1023 (271 samples), 1024 (371 samples), 1025 (198 samples), 1026 (502 samples), 1027 (266 samples), 1029 (180 samples), 1031 (214 samples), 1032 (156 samples), 1033 (134 samples), 1034 (540 samples), 1035 (22 samples), 1037 (281 samples), 1038 (229 samples), 1039 (480 samples), 1040 (422 samples), 1041 (406 samples), 1042 (317 samples), 1043 (319 samples), 1046 (280 samples), 1047 (159 samples), 1048 (170 samples), 1049 (172 samples), 1051 (118 samples), 1053 (148 samples), 1054 (80 samples), 1055 (193 samples), 1058 (180 samples), 1060 (189 samples), 1061 (194 samples), 1063 (224 samples), 1064 (160 samples), 1067 (113 samples), 1068 (165 samples), 1069 (188 samples), 1070 (175 samples), 1073 (81 samples), 1074 (111 samples), 1075 (110 samples), 1076 (188 samples), 1078 (142 samples), 1079 (149 samples), 1081 (83 samples), 1083 (40 samples), 1084 (45 samples), 1085 (40 samples), 1087 (40 samples), 1090 (57 samples), 1101 (1905 samples).\n",
      "- 9 users validation dataset: 1002 (486 samples), 1006 (174 samples), 1019 (188 samples), 1062 (127 samples), 1065 (138 samples), 1071 (260 samples), 1072 (138 samples), 1082 (300 samples), 1086 (59 samples).\n",
      "- 18 users test dataset: 1001 (177 samples), 1007 (211 samples), 1009 (118 samples), 1010 (122 samples), 1028 (155 samples), 1030 (213 samples), 1036 (249 samples), 1044 (298 samples), 1045 (260 samples), 1050 (154 samples), 1052 (177 samples), 1056 (166 samples), 1057 (146 samples), 1066 (129 samples), 1077 (164 samples), 1080 (42 samples), 1088 (40 samples), 1089 (42 samples).\n",
      "\n",
      "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/non_balanced_view\")\n",
    "\n",
    "train_act_samples = train[\"normalized activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"normalized activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"normalized activity code\"].value_counts().to_dict()\n",
    "activities = [f\"- {name}: {code} ({train_act_samples[name]} train, {validation_act_samples[name]} validation, {test_act_samples[name]} test)\" for name, code in normalized_activity_names.items()]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "train_users = ', '.join(train_users)\n",
    "validation_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "validation_users = ', '.join(validation_users)\n",
    "test_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(test[\"user\"].value_counts().items(), key=lambda x: x[0])]\n",
    "test_users = ', '.join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Non-Balanced KuHar View\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "## Activities:\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61b795e-de42-498f-a57d-5aebf81c27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5414e2-1a75-4f51-86aa-0b6606628915",
   "metadata": {},
   "source": [
    "## Creating a Balanced Kuhar with Only MotionSense activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67f96cfd-8a22-4c09-a4bc-841e6eb66b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MotionSense equivalent activity codes: [16, 15, 1, 0, 11, 14]\n",
      "The codes will be remaped as motionsense: 16 will become 0, 15 will become 1, 1 will become 2, 0 will become 3, 11 will become 4, 14 will become 5\n"
     ]
    }
   ],
   "source": [
    "activities_to_select = [\n",
    "    \"Stair-down\",\n",
    "    \"Stair-up\",\n",
    "    \"Sit\",\n",
    "    \"Stand\",\n",
    "    \"Walk\",\n",
    "    \"Run\"\n",
    "]\n",
    "\n",
    "activity_codes = [\n",
    "    kuhar_dataset.activity_codes[act_name]\n",
    "    for act_name in activities_to_select\n",
    "]\n",
    "\n",
    "print(f\"MotionSense equivalent activity codes: {activity_codes}\")\n",
    "\n",
    "activity_remap = {\n",
    "    code: i\n",
    "    for i, code in enumerate(activity_codes)\n",
    "}\n",
    "print(f\"The codes will be remaped as motionsense: {', '.join(f'{old} will become {new}' for old, new in activity_remap.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c6a470-3954-41ac-abb0-d5d04b5fcbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kuhar Iterator: users=89, activities=6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = RawKuHarIterator(kuhar_dataset, activities=activity_codes)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "225e66fd-d440-4fd6-b40f-5a9c513d6c89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset generator: time_window=300, overlap=0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=300, window_overlap=0)\n",
    "kuhar_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d98151c7-7b23-4e09-812a-a3e30cc7bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 625it [00:31, 20.12it/s]\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:577: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.replace({\"activity code\": activities_remap}, inplace=True)\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:578: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation.replace({\"activity code\": activities_remap}, inplace=True)\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:579: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.replace({\"activity code\": activities_remap}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=True,\n",
    "    activities_remap=activity_remap,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c89103e-0285-4e3f-b8e0-119f7942e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d1dc2828f22204cd42a8988ab6ef542be8a7164\n",
      "89224f59afa7a355f17f90c60cd5ee8d3038661d\n",
      "2965d7c5682e64ba232262766cc17149a1b8095d\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0943c45-de6d-4a9c-be66-c41efd4e59a1",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f5d0920-ab6c-4b71-88a3-b9464565f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "    1: 3,\n",
    "    0: 4,\n",
    "    5: 5,\n",
    "}\n",
    "\n",
    "def apply(row, labels):\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(labels,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train, new_labels)\n",
    "validation = apply(validation, new_labels)\n",
    "test = apply(test, new_labels)\n",
    "normalized_activity_names = {new_key: kuhar_dataset.activity_names[old_key] for old_key,new_key in new_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7473e9-527b-43c0-94f6-bd9c200995df",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd98e09-d7fa-4991-a62c-17e4488c9e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Talk-sit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m validation_act_samples \u001b[38;5;241m=\u001b[39m validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized activity code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m      5\u001b[0m test_act_samples \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized activity code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m----> 6\u001b[0m activities \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkuhar_dataset\u001b[38;5;241m.\u001b[39mactivity_names[old]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_act_samples[new]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_act_samples[new]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m validation, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_act_samples[new]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m old, new \u001b[38;5;129;01min\u001b[39;00m normalized_activity_names\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     10\u001b[0m activities \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(activities)\n\u001b[1;32m     12\u001b[0m train_users \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user, no_samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     15\u001b[0m         train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msort_values()\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m ]\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m validation_act_samples \u001b[38;5;241m=\u001b[39m validation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized activity code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m      5\u001b[0m test_act_samples \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized activity code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m      6\u001b[0m activities \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkuhar_dataset\u001b[38;5;241m.\u001b[39mactivity_names[old]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_act_samples[new]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_act_samples[new]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m validation, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_act_samples[new]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m old, new \u001b[38;5;129;01min\u001b[39;00m normalized_activity_names\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     10\u001b[0m activities \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(activities)\n\u001b[1;32m     12\u001b[0m train_users \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user, no_samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     15\u001b[0m         train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msort_values()\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Talk-sit'"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/balanced_motionsense_equivalent_view\")\n",
    "\n",
    "train_act_samples = train[\"normalized activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"normalized activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"normalized activity code\"].value_counts().to_dict()\n",
    "activities = [\n",
    "    f\"- {new}: {kuhar_dataset.activity_names[old]} ({train_act_samples[new]} train, {validation_act_samples[new]} validation, {test_act_samples[new]} test)\"\n",
    "    for old, new in normalized_activity_names.items()\n",
    "]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "train_users = \", \".join(train_users)\n",
    "validation_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "validation_users = \", \".join(validation_users)\n",
    "test_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        test[\"user\"].value_counts().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "test_users = \", \".join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Balanced MotionSense equivalent KuHar Dataset\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "## Activities:\n",
    "\n",
    "This view contains only samples with activities codes equivalent to MotionSense.\n",
    "In this way, only activities: {', '.join(activities_to_select)}, were selected.\n",
    "To each activity were assigned the same MotionSense activity code, thus: {', '.join(f'{old} ({kuhar_dataset.activity_names[old]} in KuHar) became {new} (in MotionSense)' for old, new in activity_remap.items())}\n",
    "\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa79ba-58f2-4b2f-800d-774dc72e10ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627170e-d694-49de-8e22-54bf237980d7",
   "metadata": {},
   "source": [
    "## Creating a Non-Balanced Kuhar with Only MotionSense activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c243c2-1217-431f-81d2-89c8da98702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=False,\n",
    "    activities_remap=activity_remap,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea13cb9-0edf-4009-b766-1059a7f38ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a8e5c-6d52-494a-abae-2ef3df472582",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a88c7-f9d5-412d-8bfe-498291a84b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "    1: 3,\n",
    "    0: 4,\n",
    "    5: 5,\n",
    "}\n",
    "\n",
    "def apply(row, labels):\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(labels,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train, new_labels)\n",
    "validation = apply(validation, new_labels)\n",
    "test = apply(test, new_labels)\n",
    "normalized_activity_names = {new_key: kuhar_dataset.activity_names[old_key] for old_key,new_key in new_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b903d14-0896-4cca-9098-929dbe49a1bb",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345fc75-dc42-4a2b-9910-e1079b5a85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/non_balanced_motionsense_equivalent_view\")\n",
    "\n",
    "train_act_samples = train[\"normalized activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"normalized activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"normalized activity code\"].value_counts().to_dict()\n",
    "activities = [\n",
    "    f\"- {new}: {kuhar_dataset.activity_names[old]} ({train_act_samples[new]} train, {validation_act_samples[new]} validation, {test_act_samples[new]} test)\"\n",
    "    for old, new in normalized_activity_names.items()\n",
    "]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "train_users = \", \".join(train_users)\n",
    "validation_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "validation_users = \", \".join(validation_users)\n",
    "test_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        test[\"user\"].value_counts().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "test_users = \", \".join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Non-Balanced MotionSense equivalent KuHar Dataset View\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "## Activities:\n",
    "\n",
    "This view contains only samples with activities codes equivalent to MotionSense.\n",
    "In this way, only activities: {', '.join(activities_to_select)}, were selected.\n",
    "To each activity were assigned the same MotionSense activity code, thus: {', '.join(f'{old} ({kuhar_dataset.activity_names[old]} in KuHar) became {new} (in MotionSense)' for old, new in activity_remap.items())}\n",
    "\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0cb2d-1ba4-44cc-9e19-a679cc9c5d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
