{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0c0e3e-a130-465c-8aec-671bdd27bf3f",
   "metadata": {},
   "source": [
    "# Pre-processing KuHar Dataset and Generate Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498254b0-ea10-4f02-b718-d26ce855b77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad53baa-1190-4969-9ae9-489321c5966e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 18:45:59.591266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-06 18:45:59.591288: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from librep.datasets.har.kuhar import (\n",
    "    RawKuHar,\n",
    "    RawKuHarIterator,\n",
    "    KuHarDatasetGenerator\n",
    ")\n",
    "\n",
    "from librep.utils.dataset import PandasDatasetsIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bf855c-9947-4174-980c-5942527eaf04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KuHar Dataset at: '../../data/datasets/KuHar/1.Raw_time_domain_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = Path(\"../../data/datasets/KuHar/1.Raw_time_domain_data\")\n",
    "kuhar_dataset = RawKuHar(dataset_dir, download=False)\n",
    "kuhar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366c2abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stand',\n",
       " 'Sit',\n",
       " 'Talk-sit',\n",
       " 'Talk-stand',\n",
       " 'Stand-sit',\n",
       " 'Lay',\n",
       " 'Lay-stand',\n",
       " 'Pick',\n",
       " 'Jump',\n",
       " 'Push-up',\n",
       " 'Sit-up',\n",
       " 'Walk',\n",
       " 'Walk-backwards',\n",
       " 'Walk-circle',\n",
       " 'Run',\n",
       " 'Stair-up',\n",
       " 'Stair-down',\n",
       " 'Table-tennis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_names = [kuhar_dataset.activity_names[i] for i in range(18)]\n",
    "act_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a73f33-547b-444e-b513-e80f50f2eb5d",
   "metadata": {},
   "source": [
    "## Creating a KuHar Balanced View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ffda3f-7686-49d1-a02d-576e4207b6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kuhar Iterator: users=89, activities=18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = RawKuHarIterator(kuhar_dataset)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75a8cb6-5083-44f9-bfbd-50f55836bb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset generator: time_window=300, overlap=0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=300, window_overlap=0)\n",
    "kuhar_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add044d7-6666-4f31-93e5-d4af57e01e56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 1945it [01:41, 19.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=True,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0dcb11-f07e-4e60-a859-ea209900beb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce08f8a1038ab48c890211a6d03233ea1c936c3d\n",
      "8abd24b492d8cb93bae3055d57720ed7726c562b\n",
      "7bffb5001651ab21c44b38cba2ed57703c0d3c41\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e8443-4f7b-4925-afc8-63f7d32b69fb",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc048fa4-d6a9-46f0-9698-ba21d04c7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(row):\n",
    "    a = {\n",
    "        1: 0,\n",
    "        0: 1,\n",
    "        11: 2,\n",
    "        15: 3,\n",
    "        16: 4,\n",
    "        14: 5,\n",
    "        2: 6,\n",
    "        3: 7,\n",
    "        4: 8,\n",
    "        5: 9,\n",
    "        6: 10,\n",
    "        7: 11,\n",
    "        8: 12,\n",
    "        9: 13,\n",
    "        10: 14,\n",
    "        12: 15,\n",
    "        13: 16,\n",
    "        17: 17,\n",
    "        18: 18\n",
    "    }\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(a,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train)\n",
    "validation = apply(validation)\n",
    "test = apply(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff24e8b-056a-415c-8511-823d7fc4597f",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a9cda8-f111-4715-94c2-e474574149ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Balanced KuHar View\n",
      "\n",
      "This view contains train, validation and test subsets in the following proportions:\n",
      "- Train: 70% of samples\n",
      "- Validation: 10% of samples\n",
      "- Test: 20% of samples\n",
      "\n",
      "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
      "\n",
      "## Activities:\n",
      "- 0: Stand (185 train, 6 validation, 21 test)\n",
      "- 1: Sit (185 train, 6 validation, 21 test)\n",
      "- 2: Talk-sit (185 train, 6 validation, 21 test)\n",
      "- 3: Talk-stand (185 train, 6 validation, 21 test)\n",
      "- 4: Stand-sit (185 train, 6 validation, 21 test)\n",
      "- 5: Lay (185 train, 6 validation, 21 test)\n",
      "- 6: Lay-stand (185 train, 6 validation, 21 test)\n",
      "- 7: Pick (185 train, 6 validation, 21 test)\n",
      "- 8: Jump (185 train, 6 validation, 21 test)\n",
      "- 9: Push-up (185 train, 6 validation, 21 test)\n",
      "- 10: Sit-up (185 train, 6 validation, 21 test)\n",
      "- 11: Walk (185 train, 6 validation, 21 test)\n",
      "- 12: Walk-backwards (185 train, 6 validation, 21 test)\n",
      "- 13: Walk-circle (185 train, 6 validation, 21 test)\n",
      "- 14: Run (185 train, 6 validation, 21 test)\n",
      "- 15: Stair-up (185 train, 6 validation, 21 test)\n",
      "- 16: Stair-down (185 train, 6 validation, 21 test)\n",
      "- 17: Table-tennis (185 train, 6 validation, 21 test)\n",
      "\n",
      "## Users\n",
      "- 62 users train dataset: 1003 (29 samples), 1004 (58 samples), 1005 (25 samples), 1008 (71 samples), 1011 (24 samples), 1013 (54 samples), 1014 (120 samples), 1015 (56 samples), 1016 (39 samples), 1017 (24 samples), 1018 (35 samples), 1020 (32 samples), 1021 (39 samples), 1022 (102 samples), 1023 (63 samples), 1024 (117 samples), 1025 (39 samples), 1026 (89 samples), 1027 (64 samples), 1029 (39 samples), 1031 (42 samples), 1032 (21 samples), 1033 (18 samples), 1034 (138 samples), 1035 (7 samples), 1037 (67 samples), 1038 (48 samples), 1039 (103 samples), 1040 (92 samples), 1041 (96 samples), 1042 (85 samples), 1043 (87 samples), 1046 (82 samples), 1047 (37 samples), 1048 (38 samples), 1049 (36 samples), 1051 (28 samples), 1053 (29 samples), 1054 (8 samples), 1055 (36 samples), 1058 (29 samples), 1060 (31 samples), 1061 (33 samples), 1063 (27 samples), 1064 (19 samples), 1067 (16 samples), 1068 (32 samples), 1069 (25 samples), 1070 (33 samples), 1073 (15 samples), 1074 (14 samples), 1075 (17 samples), 1076 (31 samples), 1078 (20 samples), 1079 (26 samples), 1081 (51 samples), 1083 (30 samples), 1084 (29 samples), 1085 (29 samples), 1087 (32 samples), 1090 (42 samples), 1101 (532 samples).\n",
      "- 9 users validation dataset: 1002 (58 samples), 1006 (5 samples), 1019 (6 samples), 1062 (6 samples), 1065 (3 samples), 1071 (13 samples), 1072 (1 samples), 1082 (10 samples), 1086 (6 samples).\n",
      "- 18 users test dataset: 1001 (12 samples), 1007 (19 samples), 1009 (8 samples), 1010 (6 samples), 1028 (10 samples), 1030 (29 samples), 1036 (45 samples), 1044 (66 samples), 1045 (58 samples), 1050 (10 samples), 1052 (14 samples), 1056 (22 samples), 1057 (10 samples), 1066 (15 samples), 1077 (23 samples), 1080 (10 samples), 1088 (10 samples), 1089 (11 samples).\n",
      "\n",
      "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/balanced_view\")\n",
    "\n",
    "train_act_samples = train[\"normalized activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"normalized activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"normalized activity code\"].value_counts().to_dict()\n",
    "activities = [f\"- {name}: {code} ({train_act_samples[name]} train, {validation_act_samples[name]} validation, {test_act_samples[name]} test)\" for name, code in kuhar_dataset.activity_names.items()]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "train_users = ', '.join(train_users)\n",
    "validation_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "validation_users = ', '.join(validation_users)\n",
    "test_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(test[\"user\"].value_counts().items(), key=lambda x: x[0])]\n",
    "test_users = ', '.join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Balanced KuHar View\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "## Activities:\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4a9c1b-beca-4c22-a84a-319fc341e709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fd8d5-7db8-4e59-ad87-fe3b9aef7ce1",
   "metadata": {},
   "source": [
    "## Creating a Non-Balanced KuHar Balanced View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cb1a94c-594b-4703-86ee-ec3d73611216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 1945it [01:35, 20.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=False,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6954d3b8-2aed-49d0-b79a-5882b3688f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31751c896807dc969d23b5b663b0081591977cac\n",
      "3891f7989d3769fa0577834a4e51034bade10aaa\n",
      "d1e70e186d0721a8ea1154733184b507222e9926\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9479f-3e4c-4233-b7a3-c84479cb4917",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0c0278-eadb-4a4e-8cff-d691cc6cded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(row):\n",
    "    a = {\n",
    "        1: 0,\n",
    "        0: 1,\n",
    "        11: 2,\n",
    "        15: 3,\n",
    "        16: 4,\n",
    "        14: 5,\n",
    "        2: 6,\n",
    "        3: 7,\n",
    "        4: 8,\n",
    "        5: 9,\n",
    "        6: 10,\n",
    "        7: 11,\n",
    "        8: 12,\n",
    "        9: 13,\n",
    "        10: 14,\n",
    "        12: 15,\n",
    "        13: 16,\n",
    "        17: 17,\n",
    "        18: 18\n",
    "    }\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(a,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train)\n",
    "validation = apply(validation)\n",
    "test = apply(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4add39d-9281-49e9-874e-e65f45a80e76",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17174f0d-d729-47cc-9f74-e6bd1abc65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-Balanced KuHar View\n",
      "\n",
      "This view contains train, validation and test subsets in the following proportions:\n",
      "- Train: 70% of samples\n",
      "- Validation: 10% of samples\n",
      "- Test: 20% of samples\n",
      "\n",
      "## Activities:\n",
      "- 0: Stand (1373 train, 183 validation, 274 test)\n",
      "- 1: Sit (1328 train, 160 validation, 324 test)\n",
      "- 2: Talk-sit (1321 train, 128 validation, 301 test)\n",
      "- 3: Talk-stand (1344 train, 166 validation, 310 test)\n",
      "- 4: Stand-sit (1550 train, 141 validation, 337 test)\n",
      "- 5: Lay (1287 train, 190 validation, 305 test)\n",
      "- 6: Lay-stand (1277 train, 168 validation, 242 test)\n",
      "- 7: Pick (992 train, 131 validation, 158 test)\n",
      "- 8: Jump (537 train, 56 validation, 63 test)\n",
      "- 9: Push-up (219 train, 229 validation, 21 test)\n",
      "- 10: Sit-up (823 train, 123 validation, 47 test)\n",
      "- 11: Walk (627 train, 27 validation, 137 test)\n",
      "- 12: Walk-backwards (217 train, 8 validation, 65 test)\n",
      "- 13: Walk-circle (185 train, 6 validation, 50 test)\n",
      "- 14: Run (488 train, 16 validation, 56 test)\n",
      "- 15: Stair-up (750 train, 18 validation, 46 test)\n",
      "- 16: Stair-down (730 train, 18 validation, 45 test)\n",
      "- 17: Table-tennis (256 train, 102 validation, 82 test)\n",
      "\n",
      "## Users\n",
      "- 62 users train dataset: 1003 (199 samples), 1004 (270 samples), 1005 (200 samples), 1008 (393 samples), 1011 (165 samples), 1013 (351 samples), 1014 (567 samples), 1015 (388 samples), 1016 (195 samples), 1017 (189 samples), 1018 (207 samples), 1020 (180 samples), 1021 (219 samples), 1022 (574 samples), 1023 (271 samples), 1024 (371 samples), 1025 (198 samples), 1026 (502 samples), 1027 (266 samples), 1029 (180 samples), 1031 (214 samples), 1032 (156 samples), 1033 (134 samples), 1034 (540 samples), 1035 (22 samples), 1037 (281 samples), 1038 (229 samples), 1039 (480 samples), 1040 (422 samples), 1041 (406 samples), 1042 (317 samples), 1043 (319 samples), 1046 (280 samples), 1047 (159 samples), 1048 (170 samples), 1049 (172 samples), 1051 (118 samples), 1053 (148 samples), 1054 (80 samples), 1055 (193 samples), 1058 (180 samples), 1060 (189 samples), 1061 (194 samples), 1063 (224 samples), 1064 (160 samples), 1067 (113 samples), 1068 (165 samples), 1069 (188 samples), 1070 (175 samples), 1073 (81 samples), 1074 (111 samples), 1075 (110 samples), 1076 (188 samples), 1078 (142 samples), 1079 (149 samples), 1081 (83 samples), 1083 (40 samples), 1084 (45 samples), 1085 (40 samples), 1087 (40 samples), 1090 (57 samples), 1101 (1905 samples).\n",
      "- 9 users validation dataset: 1002 (486 samples), 1006 (174 samples), 1019 (188 samples), 1062 (127 samples), 1065 (138 samples), 1071 (260 samples), 1072 (138 samples), 1082 (300 samples), 1086 (59 samples).\n",
      "- 18 users test dataset: 1001 (177 samples), 1007 (211 samples), 1009 (118 samples), 1010 (122 samples), 1028 (155 samples), 1030 (213 samples), 1036 (249 samples), 1044 (298 samples), 1045 (260 samples), 1050 (154 samples), 1052 (177 samples), 1056 (166 samples), 1057 (146 samples), 1066 (129 samples), 1077 (164 samples), 1080 (42 samples), 1088 (40 samples), 1089 (42 samples).\n",
      "\n",
      "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/non_balanced_view\")\n",
    "\n",
    "train_act_samples = train[\"activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"activity code\"].value_counts().to_dict()\n",
    "activities = [f\"- {name}: {code} ({train_act_samples[name]} train, {validation_act_samples[name]} validation, {test_act_samples[name]} test)\" for name, code in kuhar_dataset.activity_names.items()]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "train_users = ', '.join(train_users)\n",
    "validation_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0])]\n",
    "validation_users = ', '.join(validation_users)\n",
    "test_users = [f\"{user} ({no_samples} samples)\" for user, no_samples in sorted(test[\"user\"].value_counts().items(), key=lambda x: x[0])]\n",
    "test_users = ', '.join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Non-Balanced KuHar View\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "## Activities:\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61b795e-de42-498f-a57d-5aebf81c27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5414e2-1a75-4f51-86aa-0b6606628915",
   "metadata": {},
   "source": [
    "## Creating a Balanced Kuhar with Only MotionSense activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f96cfd-8a22-4c09-a4bc-841e6eb66b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MotionSense equivalent activity codes: [16, 15, 1, 0, 11, 14]\n",
      "The codes will be remaped as motionsense: 16 will become 0, 15 will become 1, 1 will become 2, 0 will become 3, 11 will become 4, 14 will become 5\n"
     ]
    }
   ],
   "source": [
    "activities_to_select = [\n",
    "    \"Stair-down\",\n",
    "    \"Stair-up\",\n",
    "    \"Sit\",\n",
    "    \"Stand\",\n",
    "    \"Walk\",\n",
    "    \"Run\"\n",
    "]\n",
    "\n",
    "activity_codes = [\n",
    "    kuhar_dataset.activity_codes[act_name]\n",
    "    for act_name in activities_to_select\n",
    "]\n",
    "\n",
    "print(f\"MotionSense equivalent activity codes: {activity_codes}\")\n",
    "\n",
    "activity_remap = {\n",
    "    code: i\n",
    "    for i, code in enumerate(activity_codes)\n",
    "}\n",
    "print(f\"The codes will be remaped as motionsense: {', '.join(f'{old} will become {new}' for old, new in activity_remap.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c6a470-3954-41ac-abb0-d5d04b5fcbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kuhar Iterator: users=89, activities=6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = RawKuHarIterator(kuhar_dataset, activities=activity_codes)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225e66fd-d440-4fd6-b40f-5a9c513d6c89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset generator: time_window=300, overlap=0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kuhar_generator = KuHarDatasetGenerator(iterator, time_window=300, window_overlap=0)\n",
    "kuhar_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d98151c7-7b23-4e09-812a-a3e30cc7bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 625it [00:31, 19.90it/s]\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:577: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.replace({\"activity code\": activities_remap}, inplace=True)\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:578: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation.replace({\"activity code\": activities_remap}, inplace=True)\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:579: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.replace({\"activity code\": activities_remap}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=True,\n",
    "    activities_remap=activity_remap,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c89103e-0285-4e3f-b8e0-119f7942e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d1dc2828f22204cd42a8988ab6ef542be8a7164\n",
      "89224f59afa7a355f17f90c60cd5ee8d3038661d\n",
      "2965d7c5682e64ba232262766cc17149a1b8095d\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0943c45-de6d-4a9c-be66-c41efd4e59a1",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5d0920-ab6c-4b71-88a3-b9464565f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(row):\n",
    "    a = {\n",
    "        2: 0,\n",
    "        3: 1,\n",
    "        4: 2,\n",
    "        1: 3,\n",
    "        0: 4,\n",
    "        5: 5,\n",
    "    }\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(a,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train)\n",
    "validation = apply(validation)\n",
    "test = apply(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7473e9-527b-43c0-94f6-bd9c200995df",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd98e09-d7fa-4991-a62c-17e4488c9e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Balanced MotionSense equivalent KuHar Dataset\n",
      "\n",
      "This view contains train, validation and test subsets in the following proportions:\n",
      "- Train: 70% of samples\n",
      "- Validation: 10% of samples\n",
      "- Test: 20% of samples\n",
      "\n",
      "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
      "\n",
      "## Activities:\n",
      "\n",
      "This view contains only samples with activities codes equivalent to MotionSense.\n",
      "In this way, only activities: Stair-down, Stair-up, Sit, Stand, Walk, Run, were selected.\n",
      "To each activity were assigned the same MotionSense activity code, thus: 16 (Stair-down in KuHar) became 0 (in MotionSense), 15 (Stair-up in KuHar) became 1 (in MotionSense), 1 (Sit in KuHar) became 2 (in MotionSense), 0 (Stand in KuHar) became 3 (in MotionSense), 11 (Walk in KuHar) became 4 (in MotionSense), 14 (Run in KuHar) became 5 (in MotionSense)\n",
      "\n",
      "- 0: Stair-down (485 train, 34 validation, 41 test)\n",
      "- 1: Stair-up (485 train, 34 validation, 41 test)\n",
      "- 2: Sit (485 train, 34 validation, 41 test)\n",
      "- 3: Stand (485 train, 34 validation, 41 test)\n",
      "- 4: Walk (485 train, 34 validation, 41 test)\n",
      "- 5: Run (485 train, 34 validation, 41 test)\n",
      "\n",
      "## Users\n",
      "- 56 users train dataset: 1001 (11 samples), 1002 (104 samples), 1003 (13 samples), 1004 (48 samples), 1006 (21 samples), 1007 (18 samples), 1008 (29 samples), 1009 (20 samples), 1013 (25 samples), 1014 (65 samples), 1015 (27 samples), 1016 (20 samples), 1017 (12 samples), 1018 (17 samples), 1019 (17 samples), 1020 (11 samples), 1022 (58 samples), 1024 (122 samples), 1025 (14 samples), 1027 (63 samples), 1028 (16 samples), 1029 (17 samples), 1031 (33 samples), 1034 (128 samples), 1035 (17 samples), 1037 (66 samples), 1038 (46 samples), 1039 (119 samples), 1041 (78 samples), 1043 (98 samples), 1044 (119 samples), 1045 (62 samples), 1048 (26 samples), 1049 (19 samples), 1051 (18 samples), 1052 (24 samples), 1053 (16 samples), 1055 (12 samples), 1056 (18 samples), 1058 (14 samples), 1060 (14 samples), 1062 (19 samples), 1063 (27 samples), 1064 (20 samples), 1066 (13 samples), 1069 (16 samples), 1071 (21 samples), 1072 (13 samples), 1073 (14 samples), 1074 (18 samples), 1076 (12 samples), 1077 (15 samples), 1078 (16 samples), 1080 (24 samples), 1081 (19 samples), 1101 (988 samples).\n",
      "- 7 users validation dataset: 1032 (10 samples), 1042 (98 samples), 1046 (56 samples), 1054 (6 samples), 1065 (7 samples), 1070 (12 samples), 1075 (15 samples).\n",
      "- 17 users test dataset: 1005 (4 samples), 1010 (7 samples), 1011 (5 samples), 1021 (7 samples), 1023 (40 samples), 1026 (53 samples), 1030 (3 samples), 1033 (2 samples), 1036 (36 samples), 1040 (52 samples), 1047 (9 samples), 1050 (8 samples), 1057 (3 samples), 1061 (3 samples), 1067 (4 samples), 1068 (8 samples), 1079 (2 samples).\n",
      "\n",
      "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/balanced_motionsense_equivalent_view\")\n",
    "\n",
    "train_act_samples = train[\"activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"activity code\"].value_counts().to_dict()\n",
    "activities = [\n",
    "    f\"- {new}: {kuhar_dataset.activity_names[old]} ({train_act_samples[new]} train, {validation_act_samples[new]} validation, {test_act_samples[new]} test)\"\n",
    "    for old, new in activity_remap.items()\n",
    "]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "train_users = \", \".join(train_users)\n",
    "validation_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "validation_users = \", \".join(validation_users)\n",
    "test_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        test[\"user\"].value_counts().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "test_users = \", \".join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Balanced MotionSense equivalent KuHar Dataset\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "After splits, the datasets were balanced in relation to the activity code column, that is, each subset have the same number of activitiy samples.\n",
    "\n",
    "## Activities:\n",
    "\n",
    "This view contains only samples with activities codes equivalent to MotionSense.\n",
    "In this way, only activities: {', '.join(activities_to_select)}, were selected.\n",
    "To each activity were assigned the same MotionSense activity code, thus: {', '.join(f'{old} ({kuhar_dataset.activity_names[old]} in KuHar) became {new} (in MotionSense)' for old, new in activity_remap.items())}\n",
    "\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dffa79ba-58f2-4b2f-800d-774dc72e10ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627170e-d694-49de-8e22-54bf237980d7",
   "metadata": {},
   "source": [
    "## Creating a Non-Balanced Kuhar with Only MotionSense activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56c243c2-1217-431f-81d2-89c8da98702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full df over KuHar View: 625it [00:27, 22.52it/s]\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:577: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.replace({\"activity code\": activities_remap}, inplace=True)\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:578: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation.replace({\"activity code\": activities_remap}, inplace=True)\n",
      "/home/joao/librep-hiaac/notebooks/datasets_preprocessing/../../librep/datasets/har/kuhar.py:579: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.replace({\"activity code\": activities_remap}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = kuhar_generator.create_datasets(\n",
    "    train_size=0.7,\n",
    "    validation_size=0.1,\n",
    "    test_size=0.2,\n",
    "    ensure_distinct_users_per_dataset=True,\n",
    "    balance_samples=False,\n",
    "    activities_remap=activity_remap,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eea13cb9-0edf-4009-b766-1059a7f38ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739318d8ef43c5126e478ef88d3171ea8ff362d5\n",
      "67e119c0cef043f6cb29f432e2e6ee63751e9fc7\n",
      "af713ad97427feb4864e935857f1c519f3e43c15\n"
     ]
    }
   ],
   "source": [
    "print(hashlib.sha1(pd.util.hash_pandas_object(train).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(validation).values).hexdigest())\n",
    "print(hashlib.sha1(pd.util.hash_pandas_object(test).values).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a8e5c-6d52-494a-abae-2ef3df472582",
   "metadata": {},
   "source": [
    "## Normalize the label's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48a88c7-f9d5-412d-8bfe-498291a84b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(row):\n",
    "    a = {\n",
    "        2: 0,\n",
    "        3: 1,\n",
    "        4: 2,\n",
    "        1: 3,\n",
    "        0: 4,\n",
    "        5: 5,\n",
    "    }\n",
    "    row[\"normalized activity code\"] = row[\"activity code\"].map(a,na_action=None)\n",
    "    return row\n",
    "\n",
    "train = apply(train)\n",
    "validation = apply(validation)\n",
    "test = apply(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b903d14-0896-4cca-9098-929dbe49a1bb",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1345fc75-dc42-4a2b-9910-e1079b5a85a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-Balanced MotionSense equivalent KuHar Dataset View\n",
      "\n",
      "This view contains train, validation and test subsets in the following proportions:\n",
      "- Train: 70% of samples\n",
      "- Validation: 10% of samples\n",
      "- Test: 20% of samples\n",
      "\n",
      "## Activities:\n",
      "\n",
      "This view contains only samples with activities codes equivalent to MotionSense.\n",
      "In this way, only activities: Stair-down, Stair-up, Sit, Stand, Walk, Run, were selected.\n",
      "To each activity were assigned the same MotionSense activity code, thus: 16 (Stair-down in KuHar) became 0 (in MotionSense), 15 (Stair-up in KuHar) became 1 (in MotionSense), 1 (Sit in KuHar) became 2 (in MotionSense), 0 (Stand in KuHar) became 3 (in MotionSense), 11 (Walk in KuHar) became 4 (in MotionSense), 14 (Run in KuHar) became 5 (in MotionSense)\n",
      "\n",
      "- 0: Stair-down (693 train, 43 validation, 57 test)\n",
      "- 1: Stair-up (706 train, 49 validation, 59 test)\n",
      "- 2: Sit (1280 train, 138 validation, 394 test)\n",
      "- 3: Stand (1314 train, 141 validation, 375 test)\n",
      "- 4: Walk (586 train, 73 validation, 132 test)\n",
      "- 5: Run (485 train, 34 validation, 41 test)\n",
      "\n",
      "## Users\n",
      "- 56 users train dataset: 1001 (42 samples), 1002 (164 samples), 1003 (43 samples), 1004 (94 samples), 1006 (41 samples), 1007 (40 samples), 1008 (80 samples), 1009 (40 samples), 1013 (77 samples), 1014 (148 samples), 1015 (79 samples), 1016 (42 samples), 1017 (40 samples), 1018 (40 samples), 1019 (40 samples), 1020 (42 samples), 1022 (145 samples), 1024 (172 samples), 1025 (39 samples), 1027 (99 samples), 1028 (40 samples), 1029 (40 samples), 1031 (63 samples), 1034 (182 samples), 1035 (22 samples), 1037 (110 samples), 1038 (85 samples), 1039 (187 samples), 1041 (146 samples), 1043 (152 samples), 1044 (158 samples), 1045 (101 samples), 1048 (46 samples), 1049 (51 samples), 1051 (50 samples), 1052 (52 samples), 1053 (40 samples), 1055 (40 samples), 1056 (40 samples), 1058 (40 samples), 1060 (39 samples), 1062 (41 samples), 1063 (78 samples), 1064 (44 samples), 1066 (38 samples), 1069 (40 samples), 1071 (58 samples), 1072 (39 samples), 1073 (40 samples), 1074 (43 samples), 1076 (41 samples), 1077 (41 samples), 1078 (40 samples), 1080 (26 samples), 1081 (25 samples), 1101 (1279 samples).\n",
      "- 7 users validation dataset: 1032 (40 samples), 1042 (163 samples), 1046 (115 samples), 1054 (40 samples), 1065 (39 samples), 1070 (40 samples), 1075 (41 samples).\n",
      "- 17 users test dataset: 1005 (39 samples), 1010 (39 samples), 1011 (40 samples), 1021 (42 samples), 1023 (102 samples), 1026 (152 samples), 1030 (41 samples), 1033 (40 samples), 1036 (94 samples), 1040 (142 samples), 1047 (49 samples), 1050 (45 samples), 1057 (45 samples), 1061 (48 samples), 1067 (41 samples), 1068 (58 samples), 1079 (41 samples).\n",
      "\n",
      "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../../data/views/KuHar/non_balanced_motionsense_equivalent_view\")\n",
    "\n",
    "train_act_samples = train[\"activity code\"].value_counts().to_dict()\n",
    "validation_act_samples = validation[\"activity code\"].value_counts().to_dict()\n",
    "test_act_samples = test[\"activity code\"].value_counts().to_dict()\n",
    "activities = [\n",
    "    f\"- {new}: {kuhar_dataset.activity_names[old]} ({train_act_samples[new]} train, {validation_act_samples[new]} validation, {test_act_samples[new]} test)\"\n",
    "    for old, new in activity_remap.items()\n",
    "]\n",
    "activities = \"\\n\".join(activities)\n",
    "\n",
    "train_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        train[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "train_users = \", \".join(train_users)\n",
    "validation_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        validation[\"user\"].value_counts().sort_values().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "validation_users = \", \".join(validation_users)\n",
    "test_users = [\n",
    "    f\"{user} ({no_samples} samples)\"\n",
    "    for user, no_samples in sorted(\n",
    "        test[\"user\"].value_counts().items(), key=lambda x: x[0]\n",
    "    )\n",
    "]\n",
    "test_users = \", \".join(test_users)\n",
    "\n",
    "\n",
    "description = f\"\"\"# Non-Balanced MotionSense equivalent KuHar Dataset View\n",
    "\n",
    "This view contains train, validation and test subsets in the following proportions:\n",
    "- Train: 70% of samples\n",
    "- Validation: 10% of samples\n",
    "- Test: 20% of samples\n",
    "\n",
    "## Activities:\n",
    "\n",
    "This view contains only samples with activities codes equivalent to MotionSense.\n",
    "In this way, only activities: {', '.join(activities_to_select)}, were selected.\n",
    "To each activity were assigned the same MotionSense activity code, thus: {', '.join(f'{old} ({kuhar_dataset.activity_names[old]} in KuHar) became {new} (in MotionSense)' for old, new in activity_remap.items())}\n",
    "\n",
    "{activities}\n",
    "\n",
    "## Users\n",
    "- {len(train.user.unique())} users train dataset: {train_users}.\n",
    "- {len(validation.user.unique())} users validation dataset: {validation_users}.\n",
    "- {len(test.user.unique())} users test dataset: {test_users}.\n",
    "\n",
    "**NOTE**: Each subset contain samples from distinct users, that is, samples of one user belongs exclusivelly to one of three subsets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(description)\n",
    "pandas_io = PandasDatasetsIO(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84a0cb2d-1ba4-44cc-9e19-a679cc9c5d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_io.save(train=train, validation=validation, test=test, description=description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
